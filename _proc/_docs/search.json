[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "analytics2",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "analytics2",
    "section": "Install",
    "text": "Install\npip install analytics2"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "analytics2",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "10forecast.html",
    "href": "10forecast.html",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "",
    "text": "#default_exp forecast\n# hide\n# hide_input\nfrom IPython.display import Image, YouTubeVideo\n\nYouTubeVideo(\"23VJTLk1twM\", width=200, height=150)\n# hide_input\nYouTubeVideo(\"LfbGEpZ1PeI\", width=200, height=150)"
  },
  {
    "objectID": "10forecast.html#prophetとは",
    "href": "10forecast.html#prophetとは",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "Prophetとは",
    "text": "Prophetとは\n\nProphet https://facebook.github.io/prophet/ は需要予測のためのパッケージである． ここでは，Prophetを用いた需要予測の方法について述べる． また，需要予測の基本原理と， Prophetの基礎になるベイズ推論をPyMCパッケージを用いて解説する．\n\n#hide\n# インストールされていない場合には、以下を生かす。\n# !pip install -U prophet\n# !pip install -U vega_datasets"
  },
  {
    "objectID": "10forecast.html#需要予測",
    "href": "10forecast.html#需要予測",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "需要予測",
    "text": "需要予測\n筆者は，以前は最適化の仕事は引き受けても予測の仕事は引き受けないことにしていた．予測は現場で長年働いている人の経験を加味して行うべきものであり，門外漢がいくらテクニックを駆使してもそれを超えることは難しいかと考えていたからだ．\nしかし最近になって，需要予測は当たらないといけないという考えを捨てて，誤差の管理を行うことだと割り切って考えることにして，予測に積極的に関与するようになった．多くの最適化モデルは，予測がある程度合っているという前提で構築される．予測をいいかげんにされると，最適化モデル自体が役に立たないものになる．ゴミを入れればゴミが出てくるからだ．\n誤差を管理することによって，需要予測を「点」で行うのではなく，「範囲」で行うことが可能になる．また，需要の分布も特定できるようになる．範囲内での最適化はロバスト最適化，確率分布を仮定した最適化は確率最適化という枠組みで解決可能になる．\n以下では，サプライ・チェイン最適化に関連した需要予測の基本と重要なモデルについて解説する．\n\n予測の公理\n最近，サプライ・チェインの現場において，予測に関する多くの誤りが浸透していることに気づいた．ここでは，このような誤用を減らして正しい予測手法を適用するための，予測の公理について述べる．\n\n予測は予測のためならず\n\nしばしば，予測を目的として仕事をしている人たちを見かける．予測は，ほかの重要な意思決定を行うための基礎となる手段であり，予測そのものを目的としてはならない．実際には，予測よりもその誤差を評価することの方が重要である．誤差が増えているのか，減っているのか，その理由は何かを考えることが，需要予測の真の目的なのである．\nたとえば，小売りの現場で需要予測を行うことは，在庫費用の削減や品切れ損出の回避などを目的としたものであり，予測の精度だけを問題にするのではなく，どの程度外れているのかという誤差の管理と，外れた場合の影響や，緊急発注などの回避手段とあわせて考える必要がある．\nまた，予測するだけでなく，なぜそのような値になったのかを究明することも重要である．需要が０という日が続いた場合には，それが，本当に需要がなかったのか，それとも在庫がないために売れなかったのか，陳列場所が悪かったために売れなかったのか，などをあわせて原因を分析する必要がある．\n多くのメーカーでは，需要予測をするためだけの部署を設けているが，これもナンセンスなのでできるだけ早くほかの部署と連携をとるように改めるべきである．需要は当てるものではなくコントロールするものであり，需要予測を当てることだけを目標としている部署は，廃止すべきである．\n\n予測は外れるもの\n\nしばしば予測が当たったとか外れたとかいう言葉を現場の人から聞くが，経営はギャンブルではないので的中というのはありえない．この人なら当たるとかいうのは迷信であり，たまたま当たったときに声を張り上げて宣伝しているか，誤差が大きいにもかかわらず当たったと宣伝しているかの何れかである．サプライ・チェインからはちょっと外れるが，地震の予測（予知ともいう）も似たようなものであり，日本中のどこかで地震が発生すると予測し，そのうち1つが当たると的中と宣伝していたりする．ましてや，株や競馬の予想的中などの宣伝は，たまたま当たったときの結果だけを掲載し，外れたときのものを消去して，予想的中の証拠として提出していたりする．いまだに，こんな宣伝にだまされる人がいるのかと感心するが，社内で需要予測が的中する人がいるという会社も似たような詐欺に遭っていると言える．\n重要なことは，どの程度外れたのかを時系列的に管理することである．誤差が増えている際には，その原因を追求し，予測手法を改善するなり，在庫を増やして品切れを回避するなりの行動をとるのが正しい方法である．\n\n集約すれば精度が上がる\n\n往々にして，個々のものの予測は難しいが，それをまとめたものの予測は容易になる．たとえば，特定の場所で特定のマグニチュードの地震が明日発生することを予測するのは難しいが，日本のどこかでマグニチュード4以上の地震が来年発生することは容易に予測できる．前者はほぼ\\(0\\)％であるが，後者はほぼ\\(１００\\)%の精度で予測できる．これが集約の力である．\nサプライ・チェインでも同様であり，商品を集約して商品群にすれば精度があがり，個々の店舗での売上でなく，地域内のすべての店舗の売上を集約すれば精度が上がる． 時間軸でも同様であり，１時間以内の需要を予測精度は，日，週，月，年単位と集約していくにしたがってあがっていく．\n予測精度だけを議論するのであれば，どんどん集約した方が得であるが，もちろんどんどん役に立たなくなる．前述したように，重要なことは，その予測を何に使うかであり，使用法にあわせて「適切に」集約を行うことである．\nまた，製品設計や在庫地点を考慮することによって，物理的に集約を行うこともできる．たとえば，製品のモジュール化や遅延差別化やリスク共同管理がこれに相当する．これらはモダンなサプライ・チェインの基本戦略であり，そのすべてがこの単純な公理（集約した方が予測精度が上がる）に基づくものであることは興味深い．\n\n目先の需要は当たりやすく，遠い未来の需要は予測しにくい\n\n明日の天気はある程度予測できるが，1年後の天気は予測しにくい．不確実性は時間が経過するにしたがって増大するからである．需要予測も同様である．たとえば，カップラーメンなどは一部の定番品を除いて，来年店頭に並んでいるかどうかも怪しい．\n近い未来の予測は，短期のオペレーショナルな意思決定に用いるので，比較的正確性が必要であるが，遠い未来の予測は長期のストラテジックな意思決定に用いるので，おおよそで構わない．さらに，長期の意思決定の際には，データは集約して行われるので，予測精度も上がる． 要は，目的のために適切な精度で管理できるように，時間軸を集約することが推奨される．たとえば，近い未来は予測精度がよいので，集約をせずに日単位で予測し，未来に行くに従って時間軸の集約を行い，週単位，月単位，年単位としていく訳である．このテクニックはテレスコーピングと呼ばれ，時間軸を含んだ実際問題を解くときによく用いられる．\n\n\n予測手法と使い分け\n古典的な予測手法は statsmodelsに入っている。種々の指数平滑法の拡張や、ARIMAなどは簡単にできる。 いずれも高速なので、補助的なデータがない時系列データに対して、簡易的な予測をしたい場合には便利だが、予測精度は期待すべきではない。\n機械（深層）学習を用いた予測は、 scikit-learn（最近ではpycaret）やfastaiのTabularモデルやLSTMを用いることによって容易にできる。 補助的なデータが豊富な場合には、これらの手法が推奨される。\n補助的なデータが少ない時系列データの場合には、prophetを用いたベイズ推論が推奨される。ベイズ推論だと、予測を点でするのではなく、不確実性の範囲まで得られるので、 サプライ・チェインのモデルと相性が良い。例えば、在庫モデルにおいては、不確実性の情報が不可欠だからだ。\n\n# hide_input\nfrom IPython.display import Image\n\nImage(\"../figure/how_to_select.PNG\", width=700, height=400)"
  },
  {
    "objectID": "10forecast.html#ベイズ推論",
    "href": "10forecast.html#ベイズ推論",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "ベイズ推論",
    "text": "ベイズ推論\nここでは， ベイズ推論 (Bayesian inference) をPyMCパッケージ https://www.pymc.io/ を用いて解説する． PyMCはGoogle Colabにプレインストールされている．\n\nベイズの公式\nベイズ推論は，高校で学習するベイズの公式を利用する．\n\n\\(P(A | B)\\) ： \\(B\\) という事象が発生したきに \\(A\\) が起こる条件付き確率\n\\(P( A \\cap B)\\): 事象 \\(A\\) と \\(B\\) が同時に発生する確率\n\n\\[\nP(A|B) = \\frac{P( A \\cap B)}{P(B)}\n\\]\n同様に， \\[\nP(B|A) = \\frac{P( A \\cap B)}{P(A)}\n\\]\nベン図を使うと簡単に理解できる．\n\n#hide\n#Image(\"../figure/bayes1.PNG\", width=700, height=400)\n\n\n\n事前分布と事後分布と尤度関数\n\n\\(P(\\bar{B})\\): 事象 \\(B\\) が発生しない確率\n\\(P(B) + P(\\bar{B}) =1\\)\n\nベイズの公式から， \\[\nP(B|A) = \\frac{P(A|B) P(B) }{P(A)} =  \\frac{P( A|B) p(B) }{P(A|B) P(B) + P(A|\\bar{B}) P(\\bar{B})  }\n\\]\n\\(B\\) をモデルのパラメータ \\(\\theta\\)， \\(A\\) を（観測された）データとすると， \\[\nP(\\theta| data) = \\frac{P( data|\\theta) P(\\theta) }{P(data)}\n\\]\n\n\\(P(\\theta)\\): 事前分布 (prior)\n\\(P( data|\\theta)\\) : パラメータ \\(\\theta\\) に対する尤度関数 \\(L(\\theta)\\) (likelihood)\n\\(P(\\theta| data)\\) : 事後分布 (posterior)\n\n事後分布は，尤度と事前分布の積に比例する．\n\\[\nP(\\theta| data) \\propto P( data|\\theta) P(\\theta) = Likelyhood \\times Prior\n\\]\n\n\nベイズ線形回帰\n例として， 通常の線形回帰をベイズ推論を用いて行う． 以下の2変数の線形モデルを仮定し，データを生成する．\n\\[\n\\begin{array}{l l}\nY  &\\sim N(\\mu, \\sigma^2) \\\\\n\\mu &= \\alpha + \\beta_1 X_1 + \\beta_2 X_2\n\\end{array}\n\\]\n\nimport arviz as az\nimport numpy as np\nimport pymc as pm\n\nalpha, sigma = 1, 1\nbeta = [1, 2.5]\nsize = 100\n\nX1 = np.random.randn(size)\nX2 = np.random.randn(size) * 0.2\n\nY = alpha + beta[0] * X1 + beta[1] * X2 + np.random.normal(size=size) * sigma\n\n\n# hide\n#Image(\"../figure/bayes2.PNG\", width=700, height=400)\n\n\n\nベイズ推論\nベイズ推論は， 事前分布と尤度関数によって定義された生成モデルがあれば，ベイズの公式を用いて，データが与えられた条件下での事後分布の推定が可能であることを利用する．\n線形回帰の例では，事前分布は \\(\\alpha, \\beta\\) は正規分布， \\(\\sigma\\) は負の部分を除いた半正規分布とし， 生成モデルは \\(\\mu = \\alpha + \\beta_1 X_1 + \\beta_2 X_2\\)， 尤度関数は \\(Y \\sim N(\\mu, \\sigma^2)\\) とする．\n\n# hide_input\nImage(\"../figure/bayes3.PNG\", width=700, height=400)\n\n\n\n\n\nmodel = pm.Model()\nwith model:\n    # 事前分布\n    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n    beta = pm.Normal(\"beta\", mu=0, sigma=10, shape=2)\n    sigma = pm.HalfNormal(\"sigma\", sigma=1)\n\n    # 生成モデル\n    mu = alpha + beta[0] * X1 + beta[1] * X2\n\n    # 尤度関数\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=Y)\n\n\n\nMCMC (Markov chain Monte Carlo)法\n実際の分布の推定には， MCMC (Markov chain Monte Carlo)法を利用する． \nMCMC法は，以下に示すように改悪も許した確率的な探索を行うことによって，分布のサンプリングを行う．\n\n# hide_input\nImage(\"../figure/mcmc.PNG\", width=800, height=500)\n\n\n\n\nベイズ線形回帰の事後分布をサンプリングによって生成する．\n\nwith model:\n    # 事後分布を 1000 個サンプル（時間がかかるのでしばらく待つ）\n    idata = pm.sample(draws=1000)\n\n\n\n\n\n\n    \n      \n      100.00% [2000/2000 00:02&lt;00:00 Sampling chain 0, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [2000/2000 00:01&lt;00:00 Sampling chain 1, 0 divergences]\n    \n    \n\n\n\n\n結果の表示\n\naz.plot_trace(idata, combined=True, figsize=(10,10));\n\n\n\n\n\naz.summary(idata, round_to=2)\n\n\n  \n    \n      \n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.03\n0.09\n0.86\n1.21\n0.00\n0.00\n3101.07\n1585.09\n1.0\n\n\nbeta[0]\n1.06\n0.09\n0.89\n1.22\n0.00\n0.00\n2642.38\n1633.52\n1.0\n\n\nbeta[1]\n2.44\n0.45\n1.64\n3.31\n0.01\n0.01\n3164.36\n1788.72\n1.0\n\n\nsigma\n0.94\n0.07\n0.81\n1.07\n0.00\n0.00\n2338.74\n1457.89\n1.0\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n元のデータは，以下のコードによって生成していたので，良い近似になっていることが確認できる．\n\nalpha, sigma = 1, 1\nbeta = [1, 2.5]"
  },
  {
    "objectID": "10forecast.html#諸パッケージのインポート",
    "href": "10forecast.html#諸パッケージのインポート",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "諸パッケージのインポート",
    "text": "諸パッケージのインポート\nProphetで予測するために必要なパッケージをインポートしておく． vega_datasetsのデータを用いるので，インストールしておく．\nhttps://github.com/altair-viz/vega_datasets\n\n# Google Colabの場合\n#import plotly.io as pio\n#pio.renderers.default = \"colab\"\n#!pip install prophet\n#!pip install -U vega_datasets\n\nimport pandas as pd\nfrom prophet import Prophet\nfrom vega_datasets import data\nimport plotly.express as px\nimport prophet.plot as fp\nimport plotly\n\n\n# export\nimport pandas as pd\nfrom prophet import Prophet\nfrom vega_datasets import data\nimport plotly.express as px\nimport prophet.plot as fp\nimport plotly"
  },
  {
    "objectID": "10forecast.html#prophetの基本",
    "href": "10forecast.html#prophetの基本",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "Prophetの基本",
    "text": "Prophetの基本\nProphetをPythonから呼び出して使う方法は，機械学習パッケージscikit-learnと同じである。\n\nProphetクラスのインスタンスmodelを生成\nfitメソッドで学習（引数はデータフレーム）\npredictメソッドで予測（引数は予測したい期間を含んだデータフレーム）\n\n\n例題：Wikiアクセス数\n例としてアメリカンフットボールプレーヤのPayton ManningのWikiアクセス数のデータを用いる。\n\ndf = pd.read_csv(\"http://logopt.com/data/peyton_manning.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2007-12-10\n9.590761\n\n\n1\n2007-12-11\n8.519590\n\n\n2\n2007-12-12\n8.183677\n\n\n3\n2007-12-13\n8.072467\n\n\n4\n2007-12-14\n7.893572\n\n\n\n\n\n\n\nProphetモデルのインスタンスを生成し，fitメソッドで学習（パラメータの最適化）を行う．fitメソッドに渡すのは，上で作成したデータフレームである．このとき、ds(datestamp)列に日付（時刻）を、y列に予測したい数値を入れておく必要がある （この例題では，あらかじめそのように変更されている）．\n\nmodel = Prophet()\nmodel.fit(df)\n\n09:28:44 - cmdstanpy - INFO - Chain [1] start processing\n09:28:45 - cmdstanpy - INFO - Chain [1] done processing\n\n\n&lt;prophet.forecaster.Prophet at 0x7ff1c82f31f0&gt;\n\n\nmake_future_dataframeメソッドで未来の時刻を表すデータフレームを生成する。既定値では、予測で用いた過去の時刻も含む。 引数は予測をしたい期間数periodsであり，ここでは、１年後（365日分）まで予測することにする。\n\nfuture = model.make_future_dataframe(periods=365)\nfuture.tail()\n\n\n\n\n\n\n\n\nds\n\n\n\n\n3265\n2017-01-15\n\n\n3266\n2017-01-16\n\n\n3267\n2017-01-17\n\n\n3268\n2017-01-18\n\n\n3269\n2017-01-19\n\n\n\n\n\n\n\npredict メソッドに予測したい時刻を含んだデータフレームfuture を渡すと、予測値を入れたデータフレームforecastを返す。このデータフレームは、予測値yhatの他に、予測の幅などの情報をもった列を含む。以下では，予測値yhatの他に，予測の上限と下限（yhat_lowerとyhat_upper）を表示している．\n\nforecast = model.predict(future)\nforecast[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]].tail()\n\n\n\n\n\n\n\n\nds\nyhat\nyhat_lower\nyhat_upper\n\n\n\n\n3265\n2017-01-15\n8.212625\n7.490936\n8.952181\n\n\n3266\n2017-01-16\n8.537635\n7.801412\n9.285417\n\n\n3267\n2017-01-17\n8.325071\n7.604013\n9.018835\n\n\n3268\n2017-01-18\n8.157723\n7.458736\n8.901977\n\n\n3269\n2017-01-19\n8.169677\n7.469157\n8.876939\n\n\n\n\n\n\n\nmatplotlibを用いた描画は，plotメソッドで行う．\n\nmodel.plot(forecast)\n\n\n\n\n\n\n\n\n\n一般化加法モデル\nProphetにおける予測は一般化加法モデルを用いて行われる．これは，傾向変動，季節変動，イベント情報などの様々な因子の和として予測を行う方法である．\n\\[\ny_t =g_t + s_t + h_t + \\epsilon_t\n\\]\n\n\\(y_t\\) : 予測値\n\\(g_t\\) : 傾向変動(trend)；傾向変化点ありの線形もしくはロジスティック曲線\n\\(s_t\\) : 季節変動；年次，週次，日次の季節変動をsin, cosの組み合わせ（フーリエ級数）で表現\n\\(h_t\\) : 休日などのイベント項\n\\(\\epsilon_t\\) : 誤差項\n\n因子ごとに予測値の描画を行うには，plot_componentsメソッドを用いる．既定では，以下のように，上から順に傾向変動，週次の季節変動，年次の季節変動が描画される．また，傾向変動の図（一番上）には，予測の誤差範囲が示される．季節変動の誤差範囲を得る方法については，後述する．\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n\n対話形式に，拡大縮小や範囲指定ができる動的な図も，Plotlyライブラリを用いて得ることができる．\n\nfig = fp.plot_plotly(model, forecast) \nplotly.offline.plot(fig);\n\n\n# hide_input\nImage(\"../figure/prophet1.PNG\", width=700, height=400)\n\n\n\n\n\n\n例題： \\(CO_2\\) 排出量のデータ\nデータライブラリから二酸化炭素排出量のデータを読み込み，Plotly Expressで描画する．\n\nco2 = data.co2_concentration()\nco2.head()\n\n\n\n\n\n\n\n\nDate\nCO2\n\n\n\n\n0\n1958-03-01\n315.70\n\n\n1\n1958-04-01\n317.46\n\n\n2\n1958-05-01\n317.51\n\n\n3\n1958-07-01\n315.86\n\n\n4\n1958-08-01\n314.93\n\n\n\n\n\n\n\n\nfig = px.line(co2,x=\"Date\",y=\"CO2\")\nplotly.offline.plot(fig);\n\n\n                                                \n\n\n\n# hide_input\nImage(\"../figure/prophet2.PNG\", width=700, height=400)\n\n\n\n\n列名の変更には，データフレームのrenameメソッドを用いる．引数はcolumnsで，元の列名をキーとし，変更後の列名を値とした辞書を与える．また，元のデータフレームに上書きするために，inplace引数をTrueに設定しておく．\n\nco2.rename(columns={\"Date\":\"ds\",\"CO2\":\"y\"},inplace=True)\nco2.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1958-03-01\n315.70\n\n\n1\n1958-04-01\n317.46\n\n\n2\n1958-05-01\n317.51\n\n\n3\n1958-07-01\n315.86\n\n\n4\n1958-08-01\n314.93\n\n\n\n\n\n\n\nmake_future_dataframeメソッドで未来の時刻を表すデータフレームを生成する。既定値では、（予測で用いた）過去の時刻も含む。 ここでは、200ヶ月先まで予測することにする。\nそのために，引数 periods を200に，頻度を表す引数 freq をMonthを表す M に設定しておく\npredict メソッドに予測したい時刻を含んだデータフレームfuture を渡すと、予測値を入れたデータフレームforecastを返す。このデータフレームは、予測値yhatの他に、予測の幅などの列を含む。\n最後にplotメソッドで表示する．\n\nmodel = Prophet()\nmodel.fit(co2)\nfuture = model.make_future_dataframe(periods=200, freq=`M`)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n09:49:04 - cmdstanpy - INFO - Chain [1] start processing\n09:49:04 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n予測は一般化加法モデルを用いて行われる．\nこれは，傾向変動，季節変動，イベント情報などの様々な因子の和として予測を行う方法である．\n上に表示されているように，週次と日次の季節変動は無視され，年次の季節変動のみ考慮して予測している．\n因子ごとに予測値の描画を行うには，plot_componentsメソッドを用いる．既定では，以下のように，上から順に傾向変動，週次の季節変動，年次の季節変動が描画される．また，傾向変動の図（一番上）には，予測の誤差範囲が示される．季節変動の誤差範囲を得る方法については，後述する．\n\nmodel.plot_components(forecast);\n\n\n\n\nPlotlyで描画すると， 一部を拡大，期の選択などが可能になる．\n\nfig = fp.plot_plotly(model, forecast)\nplotly.offline.plot(fig);\n\n\n# hide_input\nImage(\"../figure/prophet3.PNG\", width=700, height=400)\n\n\n\n\n\n\n例題：航空機乗客数のデータ\nProphetの既定値では季節変動は加法的モデルであるが、問題によっては乗法的季節変動の方が良い場合もある。 例として、航空機の乗客数を予測してみよう。最初に既定値の加法的季節変動モデルで予測し，次いで乗法的モデルで予測する．\n\npassengers = pd.read_csv(\"http://logopt.com/data/AirPassengers.csv\")\npassengers.head()\n\n\n\n\n\n\n\n\nMonth\n#Passengers\n\n\n\n\n0\n1949-01\n112\n\n\n1\n1949-02\n118\n\n\n2\n1949-03\n132\n\n\n3\n1949-04\n129\n\n\n4\n1949-05\n121\n\n\n\n\n\n\n\n\nfig = px.line(passengers,x=\"Month\",y=\"#Passengers\")\nplotly.offline.plot(fig);\n\n\n# hide_input\nImage(\"../figure/prophet4.PNG\", width=700, height=400)\n\n\n\n\n\npassengers.rename(inplace=True,columns={\"Month\":\"ds\",\"#Passengers\":\"y\"})\npassengers.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1949-01\n112\n\n\n1\n1949-02\n118\n\n\n2\n1949-03\n132\n\n\n3\n1949-04\n129\n\n\n4\n1949-05\n121\n\n\n\n\n\n\n\n季節変動を乗法的に変更するには， モデルの seasonality_mode 引数を乗法的を表す multiplicative に設定する．\nなお，以下のデータは月次のデータであるので，make_future_dataframeの freq 引数を M (Month)に設定する．\n\nmodel = Prophet().fit(passengers)\nfuture = model.make_future_dataframe(periods=20, freq=\"M\")\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n09:58:45 - cmdstanpy - INFO - Chain [1] start processing\n09:58:45 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\nmodel = Prophet(seasonality_mode=\"multiplicative\").fit(passengers)\nfuture = model.make_future_dataframe(periods=20, freq=\"M\")\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n09:56:17 - cmdstanpy - INFO - Chain [1] start processing\n09:56:17 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n結果から，乗法的季節変動の方が，良い予測になっていることが確認できる．\n\n#hide\n#model.plot_components(forecast);\n\n\n\n問題（小売りの需要データ）\n以下の，小売りの需要データを描画し，予測を行え． ただし，モデルは乗法的季節変動で，月次で予測せよ．\n\nretail = pd.read_csv(`http://logopt.com/data/retail_sales.csv`)\nretail.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1992-01-01\n146376\n\n\n1\n1992-02-01\n147079\n\n\n2\n1992-03-01\n159336\n\n\n3\n1992-04-01\n163669\n\n\n4\n1992-05-01\n170068\n\n\n\n\n\n\n\n\n#export\n# retail = pd.read_csv(`http://logopt.com/data/retail_sales.csv`)\n# model = Prophet(seasonality_mode=`multiplicative`).fit(retail)\n# future = model.make_future_dataframe(periods=20, freq=`M`)\n# forecast = model.predict(future)\n# model.plot(forecast);\n# #model.plot_components(forecast);\n\n\n\n例題： 1時間ごとの気温データ\nここではシアトルの気温の予測を行う．\n\nclimate = data.seattle_temps()\nclimate.head()\n\n\n\n\n\n\n\n\ndate\ntemp\n\n\n\n\n0\n2010-01-01 00:00:00\n39.4\n\n\n1\n2010-01-01 01:00:00\n39.2\n\n\n2\n2010-01-01 02:00:00\n39.0\n\n\n3\n2010-01-01 03:00:00\n38.9\n\n\n4\n2010-01-01 04:00:00\n38.8\n\n\n\n\n\n\n\nこのデータは， date 列に日付と1時間ごとの時刻が， temp 列に気温データが入っている．\nProphetは， 日別でないデータも扱うことができる。 date列のデータ形式は、日付を表すYYYY-MM-DDの後に時刻を表すHH:MM:SSが追加されている。 未来の時刻を表すデータフレームは、make_future_dataframeメソッドで生成するが、このとき引数freqで時間の刻みを指定する。 ここでは1時間を表す H を指定する。\n\nclimate[\"Date\"] = pd.to_datetime(climate.date)\n\n\nclimate.rename(columns={\"Date\":\"ds\",\"temp\":\"y\"},inplace=True)\n\n\nmodel = Prophet().fit(climate)\nfuture = model.make_future_dataframe(periods=200, freq=\"H\")\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n10:06:08 - cmdstanpy - INFO - Chain [1] start processing\n10:06:11 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n因子ごとに予測値を描画すると，傾向変動と週次の季節変動の他に，日次の季節変動（1日の気温の変化）も出力される．\n\nmodel.plot_components(forecast);\n\n\n\n\n\n\n問題（サンフランシスコの気温データ）\n以下のサンフランシスコの気温データを描画し，時間単位で予測を行え．\n\nsf = data.sf_temps()\nsf.head()\n\n\n\n\n\n\n\n\ntemp\ndate\n\n\n\n\n0\n47.8\n2010-01-01 00:00:00\n\n\n1\n47.4\n2010-01-01 01:00:00\n\n\n2\n46.9\n2010-01-01 02:00:00\n\n\n3\n46.5\n2010-01-01 03:00:00\n\n\n4\n46.0\n2010-01-01 04:00:00\n\n\n\n\n\n\n\n\n#export\n# sf = data.sf_temps()\n# sf[\"Date\"] = pd.to_datetime(sf.date)\n# sf.rename(columns={\"Date\":\"ds\",\"temp\":\"y\"},inplace=True)\n# model = Prophet().fit(sf)\n# future = model.make_future_dataframe(periods=200, freq=`H`)\n# forecast = model.predict(future)\n# model.plot(forecast);\n\n#hide \n\n#hide\ngithub = data.github()\ngithub.tail()\n\n\n\n\n\n\n\n\ntime\ncount\n\n\n\n\n950\n2015-05-29 17:00:00\n1\n\n\n951\n2015-05-29 19:00:00\n1\n\n\n952\n2015-05-30 00:00:00\n10\n\n\n953\n2015-05-30 09:00:00\n1\n\n\n954\n2015-05-30 11:00:00\n2\n\n\n\n\n\n\n\n\n#hide\n# fig = px.line(github,x=\"time\",y=\"count\")\n# plotly.offline.plot(fig);\n\n#hide\n\n\n#hide\n#github[\"cumsum\"] = np.log(github[\"count\"]+0.1)\ngithub[\"cumsum\"] = github[\"count\"].cumsum()\ngithub.rename(inplace=True,columns={\"time\":\"ds\",\"cumsum\":\"y\"})\ngithub.head()\n\n\n\n\n\n\n\n\nds\ncount\ny\n\n\n\n\n0\n2015-01-01 01:00:00\n2\n2\n\n\n1\n2015-01-01 04:00:00\n3\n5\n\n\n2\n2015-01-01 05:00:00\n1\n6\n\n\n3\n2015-01-01 08:00:00\n1\n7\n\n\n4\n2015-01-01 09:00:00\n3\n10\n\n\n\n\n\n\n\n\n#hide\nmodel = Prophet().fit(github)\nfuture = model.make_future_dataframe(periods=200, freq=\"H\")\nforecast = model.predict(future)\nmodel.plot(forecast);\nmodel.plot_components(forecast);\n\n11:20:22 - cmdstanpy - INFO - Chain [1] start processing\n11:20:22 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n#hide\n#forecast[\"error\"] = np.exp(forecast.yhat)-np.exp(github.y)\n# forecast[\"error\"] = forecast.yhat - github.y\nforecast[\"error\"].plot();\n\n\n\n\n\n\n傾向変化点\n「上昇トレンドの株価が，下降トレンドに移った」というニュースをよく耳にするだろう．このように，傾向変動は，時々変化すると仮定した方が自然なのだ．Prophetでは，これを傾向の変化点として処理する．再び，Peyton Manningのデータを使う．\nadd_changepoints_to_plotを使うと、変化した点（日次）と傾向変動を図に追加して描画できる。引数は軸(axis)，モデル(model)，予測データフレーム(forecast)であり， 軸は図オブジェクトのgca(get current axis)メソッドで得る．\n\ndf = pd.read_csv(`http://logopt.com/data/peyton_manning.csv`)\nmodel = Prophet().fit(df)\nfuture = model.make_future_dataframe(periods=366)\nforecast = model.predict(future)\nfig = model.plot(forecast)\na = fp.add_changepoints_to_plot(fig.gca(),model,forecast);\n\n11:27:07 - cmdstanpy - INFO - Chain [1] start processing\n11:27:08 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n変化点の数を制御するための引数は changepoint_prior_scale であり、既定値は \\(0.05\\) である。これを増やすと変化点が増え、予測の自由度が増すため予測幅が大きくなる。\n\nmodel = Prophet(changepoint_prior_scale=0.5).fit(df)\nfuture = model.make_future_dataframe(periods=366)\nforecast = model.predict(future)\nfig = model.plot(forecast)\nfp.add_changepoints_to_plot(fig.gca(), model, forecast);\n\n11:28:49 - cmdstanpy - INFO - Chain [1] start processing\n11:28:51 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n傾向変化点のリストをchangepoints引数で与えることもできる。以下の例では、1つの日だけで変化するように設定している。\n\nmodel = Prophet(changepoints=[`2014-01-01`]).fit(df)\nfuture = model.make_future_dataframe(periods=366)\nforecast = model.predict(future)\nfig = model.plot(forecast)\nfp.add_changepoints_to_plot(fig.gca(), model, forecast);\n\n11:28:59 - cmdstanpy - INFO - Chain [1] start processing\n11:28:59 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n例題 SP500データ\n株価の予測を行う．\n傾向変化点の候補は自動的に設定される。既定値では時系列の最初の80%の部分に均等に設定される。これは、モデルのchangepoint_range引数で設定する． この例では，期間の終わりで変化点を設定したいので，0.95に変更する．\n年次の季節変動の変化の度合いは、yearly_seasonality（既定値は \\(10\\)) で制御できる。この例では，このパラメータを \\(5\\) に変更することによって年間の季節変動を抑制して予測を行う．\n\nsp500 = data.sp500()\nsp500.tail()\n\n\n\n\n\n\n\n\ndate\nprice\n\n\n\n\n118\n2009-11-01\n1095.63\n\n\n119\n2009-12-01\n1115.10\n\n\n120\n2010-01-01\n1073.87\n\n\n121\n2010-02-01\n1104.49\n\n\n122\n2010-03-01\n1140.45\n\n\n\n\n\n\n\n\n#hide\n# fig = px.line(sp500,x=\"date\",y=\"price\") \n# plotly.offline.plot(fig);\n\n\nsp500.rename(inplace=True,columns={\"date\":\"ds\",\"price\":\"y\"})\n\n\nmodel = Prophet(changepoint_prior_scale=0.5, changepoint_range=0.95,yearly_seasonality=5).fit(sp500)\nfuture = model.make_future_dataframe(periods=200, freq=`D`)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:30:30 - cmdstanpy - INFO - Chain [1] start processing\n11:30:30 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\nmodel.plot_components(forecast);\n\n\n\n\n\nfrom prophet.plot import add_changepoints_to_plot\nfig = model.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), model, forecast)\n\n\n\n\n\n\n例題： 個別銘柄の株価の予測\nstocksデータでは，symbol列に企業コードが入っている．\n\nAAPL アップル\nAMZN アマゾン\nIBM IBM\nGOOG グーグル\nMSFT マイクロソフト\n\nまずは可視化を行う。\n\nstocks = data.stocks()\nstocks.tail()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n555\nAAPL\n2009-11-01\n199.91\n\n\n556\nAAPL\n2009-12-01\n210.73\n\n\n557\nAAPL\n2010-01-01\n192.06\n\n\n558\nAAPL\n2010-02-01\n204.62\n\n\n559\nAAPL\n2010-03-01\n223.02\n\n\n\n\n\n\n\n\nfig = px.line(stocks,x=\"date\",y=\"price\",color=\"symbol\")\nplotly.offline.plot(fig);\n\n\n                                                \n\n\n\n# hide_input\nImage(\"../figure/prophet5.PNG\", width=700, height=400)\n\n\n\n\n以下では，マイクロソフトの株価を予測してみる．\n\nmsft = stocks[ stocks.symbol == \"MSFT\"]\nmsft.head()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n0\nMSFT\n2000-01-01\n39.81\n\n\n1\nMSFT\n2000-02-01\n36.35\n\n\n2\nMSFT\n2000-03-01\n43.22\n\n\n3\nMSFT\n2000-04-01\n28.37\n\n\n4\nMSFT\n2000-05-01\n25.45\n\n\n\n\n\n\n\n\nmsft = msft.rename(columns={\"date\":\"ds\",\"price\":\"y\"})\nmsft.head()\n\n\n\n\n\n\n\n\nsymbol\nds\ny\n\n\n\n\n0\nMSFT\n2000-01-01\n39.81\n\n\n1\nMSFT\n2000-02-01\n36.35\n\n\n2\nMSFT\n2000-03-01\n43.22\n\n\n3\nMSFT\n2000-04-01\n28.37\n\n\n4\nMSFT\n2000-05-01\n25.45\n\n\n\n\n\n\n\n\nmodel = Prophet(changepoint_prior_scale=0.5, changepoint_range=0.95,yearly_seasonality=5).fit(msft)\nfuture = model.make_future_dataframe(periods=200, freq=`D`)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:33:31 - cmdstanpy - INFO - Chain [1] start processing\n11:33:31 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\nmodel.plot_components(forecast);\n\n\n\n\n\n\n問題（株価）\n上の株価データのマイクロソフト以外の銘柄を1つ選択し，予測を行え．\n\nstocks = data.stocks()\nstocks.head()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n0\nMSFT\n2000-01-01\n39.81\n\n\n1\nMSFT\n2000-02-01\n36.35\n\n\n2\nMSFT\n2000-03-01\n43.22\n\n\n3\nMSFT\n2000-04-01\n28.37\n\n\n4\nMSFT\n2000-05-01\n25.45\n\n\n\n\n\n\n\n\n#export\n# stocks = data.stocks()\n# amzn = stocks[ stocks.symbol == \"AMZN\"]\n# amzn = amzn.rename(columns={\"date\":\"ds\",\"price\":\"y\"})\n# model = Prophet(changepoint_prior_scale=0.5, changepoint_range=0.95, yearly_seasonality=5).fit(amzn)\n# future = model.make_future_dataframe(periods=200, freq=`D`)\n# forecast = model.predict(future)\n# model.plot(forecast);"
  },
  {
    "objectID": "10forecast.html#発展編",
    "href": "10forecast.html#発展編",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "発展編",
    "text": "発展編\n以下では，Prophetの高度な使用法を解説する．\n\nロジスティック曲線による予測\nProphetによる予測の既定値は線形モデルであるが、ロジスティック曲線を用いることもできる。これによって，上限や下限に漸近する時系列データの予測を行うことができる．\n上限を規定するためには、データフレームのcap列に上限値（容量(capacity)の略でcap）を入力する。(下限値を設定する場合には、floor列に下限値を入力する.) これは行(データ）ごとに設定しなければならない．\n次いで、引数growthをlogisticに設定してProphetモデルを生成すると、ロジスティック曲線に当てはめを行う。\n\nlogistic = pd.read_csv(\"http://logopt.com/data/logistic.csv\")\n\n\n#hide\nfig = px.line(logistic,x=\"ds\",y=\"y\")\nplotly.offline.plot(fig);\n\n\n                                                \n\n\n\nmodel = Prophet(growth=\"logistic\") \nlogistic[\"cap\"] = 8.5 \nmodel.fit(logistic)    \nfuture = model.make_future_dataframe(periods=1826)\nfuture[`cap`] = 8.5\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:34:53 - cmdstanpy - INFO - Chain [1] start processing\n11:34:53 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n外れ値の影響\n外れ値(outlier)を除去すると予測の精度が向上する場合がある。以下の例では、2010年あたりに大きな変化があるため、予測の幅が広がっている。\n\noutliers1 = pd.read_csv(\"http://logopt.com/data/outliers1.csv\")\n\n\n#hide\nfig = px.line(outliers1,x=\"ds\",y=\"y\")\nplotly.offline.plot(fig);\n\n\n                                                \n\n\n\nmodel = Prophet()\nmodel.fit(outliers1)\nfuture = model.make_future_dataframe(periods=1096)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:35:45 - cmdstanpy - INFO - Chain [1] start processing\n11:35:47 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n2010年のデータを除外することによって、予測が改善される。\n\noutliers1.loc[(outliers1[`ds`] &gt; `2010-01-01`) & (outliers1[`ds`] &lt; `2011-01-01`), `y`] = None\nmodel =Prophet()\nmodel.fit(outliers1)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:35:52 - cmdstanpy - INFO - Chain [1] start processing\n11:35:52 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n上では、外れ値を除外することによって予測が改善されたが、これがいつでも成立するとは限らない。以下の例では2015年6月に外れ値が観察される。　\n\noutliers2 = pd.read_csv(\"http://logopt.com/data/outliers2.csv\")\n\n\n#hide\nfig = px.line(outliers2,x=\"ds\",y=\"y\")\nplotly.offline.plot(fig);\n\n\n                                                \n\n\n\nmodel = Prophet()\nmodel.fit(outliers2)\nfuture = model.make_future_dataframe(periods=1096)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:36:21 - cmdstanpy - INFO - Chain [1] start processing\n11:36:21 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n上の予測では2015年6月のデータを予測に用いず，外れ値として処理しているので，外れ値を除外すると予測の幅が広がる。\n\noutliers2.loc[(outliers2[`ds`] &gt; `2015-06-01`) & (outliers2[`ds`] &lt; `2015-06-30`), `y`] = None\nmodel = Prophet()\nmodel.fit(outliers2)\nfuture = model.make_future_dataframe(periods=1096)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:36:26 - cmdstanpy - INFO - Chain [1] start processing\n11:36:27 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n休日（特別なイベント）を考慮した予測\n休日や特別なイベントをモデルに追加することを考える。そのためには、holiday と ds(datestamp)を列名としたデータフレームを準備する必要がある。holiday列にはイベント名を、dsにはそのイベントが発生する日時を入力する。\n以下では、holiday 列に superbowl と playoff の2種類を入れる。\nまた、イベントの影響が指定した日時の前後何日まで影響を与えるかを示す2つの列lower_windowと upper_windowを追加することができる。\n例としてPeyton Manningの例題のデータを用いる．\n\ndf = pd.read_csv(`http://logopt.com/data/peyton_manning.csv`)\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2007-12-10\n9.590761\n\n\n1\n2007-12-11\n8.519590\n\n\n2\n2007-12-12\n8.183677\n\n\n3\n2007-12-13\n8.072467\n\n\n4\n2007-12-14\n7.893572\n\n\n\n\n\n\n\n\nplayoffs = pd.DataFrame({\n  `holiday`: `playoff`,\n  `ds`: pd.to_datetime([`2008-01-13`, `2009-01-03`, `2010-01-16`,\n                        `2010-01-24`, `2010-02-07`, `2011-01-08`,\n                        `2013-01-12`, `2014-01-12`, `2014-01-19`,\n                        `2014-02-02`, `2015-01-11`, `2016-01-17`,\n                        `2016-01-24`, `2016-02-07`]),\n  `lower_window`: 0,\n  `upper_window`: 1,\n})\nsuperbowls = pd.DataFrame({\n  `holiday`: `superbowl`,\n  `ds`: pd.to_datetime([`2010-02-07`, `2014-02-02`, `2016-02-07`]),\n  `lower_window`: 0,\n  `upper_window`: 1,\n})\nholidays = pd.concat((playoffs, superbowls))\nholidays.head()\n\n\n\n\n\n\n\n\nholiday\nds\nlower_window\nupper_window\n\n\n\n\n0\nplayoff\n2008-01-13\n0\n1\n\n\n1\nplayoff\n2009-01-03\n0\n1\n\n\n2\nplayoff\n2010-01-16\n0\n1\n\n\n3\nplayoff\n2010-01-24\n0\n1\n\n\n4\nplayoff\n2010-02-07\n0\n1\n\n\n\n\n\n\n\n引数holidaysで休日を表すデータフレームを与えることによって、特別なイベントを考慮した予測を行うことができる。\n\nmodel= Prophet(holidays=holidays)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=365)\nforecast = model.predict(future)\n\n11:37:41 - cmdstanpy - INFO - Chain [1] start processing\n11:37:42 - cmdstanpy - INFO - Chain [1] done processing\n\n\nプレーオフやスーパーボールなどのイベント効果がある日だけ抜き出してデータフレームを表示する．\n\nforecast[(forecast[`playoff`] + forecast[`superbowl`]).abs() &gt; 0][\n        [`ds`, `playoff`, `superbowl`]][-10:]\n\n\n\n\n\n\n\n\nds\nplayoff\nsuperbowl\n\n\n\n\n2190\n2014-02-02\n1.231269\n1.189638\n\n\n2191\n2014-02-03\n1.900381\n1.461279\n\n\n2532\n2015-01-11\n1.231269\n0.000000\n\n\n2533\n2015-01-12\n1.900381\n0.000000\n\n\n2901\n2016-01-17\n1.231269\n0.000000\n\n\n2902\n2016-01-18\n1.900381\n0.000000\n\n\n2908\n2016-01-24\n1.231269\n0.000000\n\n\n2909\n2016-01-25\n1.900381\n0.000000\n\n\n2922\n2016-02-07\n1.231269\n1.189638\n\n\n2923\n2016-02-08\n1.900381\n1.461279\n\n\n\n\n\n\n\n因子別に描画を行うと，イベントによって変化した量が描画される（上から2番目）．\n\nmodel.plot_components(forecast);\n\n\n\n\n\n\n国（州）別の休日\nadd_country_holidaysを用いて，各国（州）の休日データを追加することができる。日本のデータもあるが、天皇誕生日がずれていたりするので、注意を要する。\n\nmodel = Prophet(holidays=holidays)\nmodel.add_country_holidays(country_name=`US`)\nmodel.fit(df)\n\n11:38:05 - cmdstanpy - INFO - Chain [1] start processing\n11:38:05 - cmdstanpy - INFO - Chain [1] done processing\n\n\n&lt;prophet.forecaster.Prophet at 0x7f8ee9460580&gt;\n\n\n追加された休日名をtrain_holiday_names属性で確認しておく．\n\nmodel.train_holiday_names\n\n0                         playoff\n1                       superbowl\n2                  New Year's Day\n3      Martin Luther King Jr. Day\n4           Washington's Birthday\n5                    Memorial Day\n6                Independence Day\n7                       Labor Day\n8                    Columbus Day\n9                    Veterans Day\n10                   Thanksgiving\n11                  Christmas Day\n12       Christmas Day (Observed)\n13        Veterans Day (Observed)\n14    Independence Day (Observed)\n15      New Year's Day (Observed)\ndtype: object\n\n\n米国の休日を考慮して予測を行い，因子別に描画してみる．上から2番目が，休日に対する影響を表している．\n\nforecast = model.predict(future)\nmodel.plot_components(forecast);\n\n\n\n\n\n\n予測因子の追加\nadd_regressorメソッドを用いると、モデルに因子を追加できる。以下の例では、オンシーズンの日曜日にだけ影響がでる因子を追加している。\n\ndef nfl_sunday(ds):\n   date = pd.to_datetime(ds)\n   if date.weekday() == 6 and (date.month &gt; 8 or date.month &lt; 2):\n     return 1\n   else:\n     return 0\ndf = pd.read_csv(`http://logopt.com/data/peyton_manning.csv`)\ndf[`nfl_sunday`] = df[`ds`].apply(nfl_sunday)\nmodel = Prophet()\nmodel.add_regressor(`nfl_sunday`)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=365)\nfuture[`nfl_sunday`] = future[`ds`].apply(nfl_sunday)\nforecast = model.predict(future)\nmodel.plot_components(forecast);\n\n11:38:22 - cmdstanpy - INFO - Chain [1] start processing\n11:38:22 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\nユーザーが設定した季節変動\nProphetでは既定値の年次や週次の季節変動だけでなく、ユーザー自身で季節変動を定義・追加できる。以下では、週次の季節変動を除き，かわりに周期が30.5日の月次変動をフーリエ次数（seasonalityの別名）5として追加している。\n\nmodel = Prophet(weekly_seasonality=False)\nmodel.add_seasonality(name=`monthly`, period=30.5, fourier_order=5)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=365)\nforecast = model.predict(future)\nmodel.plot_components(forecast);\n\n11:38:38 - cmdstanpy - INFO - Chain [1] start processing\n11:38:38 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n他の要因に依存した季節変動\n他の要因に依存した季節変動も定義・追加することができる。以下の例では、オンシーズンとオフシーズンごと週次変動を定義し、追加してみる。\n\ndef is_nfl_season(ds):\n    date = pd.to_datetime(ds)\n    return (date.month &gt; 8 or date.month &lt; 2)\ndf[`on_season`] = df[`ds`].apply(is_nfl_season)\ndf[`off_season`] = ~df[`ds`].apply(is_nfl_season)\n\n\nmodel = Prophet(weekly_seasonality=False)\nmodel.add_seasonality(name=`weekly_on_season`, period=7, fourier_order=3, condition_name=`on_season`)\nmodel.add_seasonality(name=`weekly_off_season`, period=7, fourier_order=3, condition_name=`off_season`)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=365)\nfuture[`on_season`] = future[`ds`].apply(is_nfl_season)\nfuture[`off_season`] = ~future[`ds`].apply(is_nfl_season)\nforecast =model.predict(future)\nmodel.plot_components(forecast);\n\n11:38:48 - cmdstanpy - INFO - Chain [1] start processing\n11:38:49 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n休日と季節変動の効果の調整法\n休日の影響を抑制するためには、holidays_prior_scaleを小さくすれば良い。このパラメータの既定値は \\(10\\) であり、これはほとんど正則化を行わないことを意味する。 一般に， prior_scale を大きくするとそのパラメータの柔軟性が増し，小さくすると柔軟性が減る．以下では，holidays_prior_scaleを \\(0.05\\) に設定して予測を行う．\n\ndf = pd.read_csv(`http://logopt.com/data/peyton_manning.csv`)\nmodel= Prophet(holidays=holidays, holidays_prior_scale=0.05)\nmodel.fit(df)\nfuture = model.make_future_dataframe(periods=365)\nforecast = model.predict(future)\n\nforecast[(forecast[`playoff`] + forecast[`superbowl`]).abs() &gt; 0][\n    [`ds`, `playoff`, `superbowl`]][-10:]\n\n11:39:23 - cmdstanpy - INFO - Chain [1] start processing\n11:39:24 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n\n\nds\nplayoff\nsuperbowl\n\n\n\n\n2190\n2014-02-02\n1.203527\n0.970955\n\n\n2191\n2014-02-03\n1.851203\n0.993308\n\n\n2532\n2015-01-11\n1.203527\n0.000000\n\n\n2533\n2015-01-12\n1.851203\n0.000000\n\n\n2901\n2016-01-17\n1.203527\n0.000000\n\n\n2902\n2016-01-18\n1.851203\n0.000000\n\n\n2908\n2016-01-24\n1.203527\n0.000000\n\n\n2909\n2016-01-25\n1.851203\n0.000000\n\n\n2922\n2016-02-07\n1.203527\n0.970955\n\n\n2923\n2016-02-08\n1.851203\n0.993308\n\n\n\n\n\n\n\nスーパーボール（superbowl）の効果が抑制されていることが見てとれる． 同様に，季節変動の影響はseasonality_prior_scaleを小さくすることによって抑制できる。\n\n\n不確実性の幅\nProphetは既定では傾向変動に対する不確実性の幅を予測する。このとき、引数interval_widthで予測の幅を設定できる。既定値は \\(0.8\\) である。このパラメータを大きくすると幅が広がり、小さくすると幅が狭くなることが確認できる。\n例として \\(CO_2\\) 排出量のデータを用いる．\n\nco2 = data.co2_concentration()\nco2.rename(columns={\"Date\":\"ds\",\"CO2\":\"y\"},inplace=True)\nco2.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1958-03-01\n315.70\n\n\n1\n1958-04-01\n317.46\n\n\n2\n1958-05-01\n317.51\n\n\n3\n1958-07-01\n315.86\n\n\n4\n1958-08-01\n314.93\n\n\n\n\n\n\n\n\nmodel = Prophet(interval_width=0.95)\nmodel.fit(co2)\nfuture = model.make_future_dataframe(periods=200, freq=`M`)\nforecast = model.predict(future)\nmodel.plot(forecast);\n\n11:39:35 - cmdstanpy - INFO - Chain [1] start processing\n11:39:35 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\nforecast = Prophet(interval_width=0.5).fit(co2).predict(future)\nmodel.plot(forecast);\n\n11:39:37 - cmdstanpy - INFO - Chain [1] start processing\n11:39:37 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n季節変動に対する不確実性を予測するためには、マルコフ連鎖モンテカルロ法を行う必要がある、そのためには、引数 mcmc_samples をシミュレーションの反復回数に設定する。 このパラメータの既定値は \\(0\\) である。\nこれによって、既定値の最大事後確率（MAP）推定の代わりにマルコフ連鎖モンテカルロ法によるサンプリングが行われる。これは、非常に時間がかかることもある。 要因別に図を描画してみると、季節変動に対しても不確実性の幅が示されていることが確認できる。\n\nmodel = Prophet(mcmc_samples=100)\nforecast = model.fit(co2).predict(future)\nmodel.plot_components(forecast);\n\n11:41:11 - cmdstanpy - INFO - CmdStan installation /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics-v-sH3Dza-py3.8/lib/python3.8/site-packages/prophet/stan_model/cmdstan-2.26.1 missing makefile, cannot get version.\n11:41:11 - cmdstanpy - INFO - Cannot determine whether version is before 2.28.\n11:41:11 - cmdstanpy - INFO - CmdStan start processing\n11:41:18 - cmdstanpy - INFO - CmdStan done processing.\n11:41:18 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\nException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\nException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\nException: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Matrix of independent variables is inf, but must be finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\n    Exception: normal_id_glm_lpdf: Scale vector is 0, but must be positive finite! (in '/Users/runner/work/prophet/prophet/python/stan/prophet.stan', line 137, column 2 to line 142, column 4)\nConsider re-running with show_console=True if the above output is unclear!\n11:41:18 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 49 divergent transitions (98.0%)\n    Chain 2 had 44 divergent transitions (88.0%)\n    Chain 2 had 6 iterations at max treedepth (12.0%)\n    Chain 3 had 5 divergent transitions (10.0%)\n    Chain 3 had 45 iterations at max treedepth (90.0%)\n    Chain 4 had 46 divergent transitions (92.0%)\n    Use function \"diagnose()\" to see further information.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                                                                                                                                                                                                                                                                \n\n\n\n\n\n\n\n検証と誤差の評価\nProphetでは、予測の精度を検証するための仕組みが組み込まれている。例として、Peyton Manningのデータセットを用いる。 このデータセットは、全部で \\(2905\\) 日分のデータで構成されている。\n交差検証のためにはcross_validationを用いる。\n引数は以下の通り．\n\nmodel: 予測を行うモデル；事前にfitメソッドで学習しておく必要がある．\nhorizon : 計画期間（予測を行う期間）\nperiod : 予測の間隔；省略するとhorizonの半分が代入される．\ninitial : 交差検証を開始する最初の期；省略するとhorizonの3倍が代入される．\n\n以下の例では、initialが \\(730\\) 日なので、\\(729\\) 日までの情報を用いて、その後の \\(365\\)(horizon)日の予測を行い、本当の値との誤差を評価し、 次いで \\(730+180\\)(period)日までの情報を用いて、その後の \\(365\\) 日の予測を行い評価し、という手順を最後の日まで繰り返す。 \\((2905-730-365)/180 = 10.05\\) であるので、 \\(11\\) 回の予測を行い評価することになる。cross_validationは、交差検証用のデータフレームを返す。\n最初の検証は \\(730\\) 日後である 2010-2-15(cutoff)までのデータを用いて，2010-2-16から \\(365\\) (horizon)日分の予測で行われ、次の検証はその \\(180\\)(period)日後である2010-08-14日から行われる。最後の検証は2015-01-20日までのデータを用いて2016-01-20日まで行われる。\n\ndf = pd.read_csv(`http://logopt.com/data/peyton_manning.csv`)\nmodel = Prophet()\nmodel.fit(df);\n\n11:43:07 - cmdstanpy - INFO - Chain [1] start processing\n11:43:08 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\nfrom prophet.diagnostics import cross_validation\ndf_cv = cross_validation(model, initial=`730 days`, period=`180 days`, horizon = `365 days`)\ndf_cv.head()\n\n\n\n\n11:43:17 - cmdstanpy - INFO - Chain [1] start processing\n11:43:17 - cmdstanpy - INFO - Chain [1] done processing\n11:43:17 - cmdstanpy - INFO - Chain [1] start processing\n11:43:17 - cmdstanpy - INFO - Chain [1] done processing\n11:43:18 - cmdstanpy - INFO - Chain [1] start processing\n11:43:18 - cmdstanpy - INFO - Chain [1] done processing\n11:43:19 - cmdstanpy - INFO - Chain [1] start processing\n11:43:19 - cmdstanpy - INFO - Chain [1] done processing\n11:43:19 - cmdstanpy - INFO - Chain [1] start processing\n11:43:19 - cmdstanpy - INFO - Chain [1] done processing\n11:43:20 - cmdstanpy - INFO - Chain [1] start processing\n11:43:20 - cmdstanpy - INFO - Chain [1] done processing\n11:43:20 - cmdstanpy - INFO - Chain [1] start processing\n11:43:21 - cmdstanpy - INFO - Chain [1] done processing\n11:43:21 - cmdstanpy - INFO - Chain [1] start processing\n11:43:21 - cmdstanpy - INFO - Chain [1] done processing\n11:43:22 - cmdstanpy - INFO - Chain [1] start processing\n11:43:22 - cmdstanpy - INFO - Chain [1] done processing\n11:43:23 - cmdstanpy - INFO - Chain [1] start processing\n11:43:23 - cmdstanpy - INFO - Chain [1] done processing\n11:43:24 - cmdstanpy - INFO - Chain [1] start processing\n11:43:24 - cmdstanpy - INFO - Chain [1] done processing\n\n\n\n\n\n\n\n\n\nds\nyhat\nyhat_lower\nyhat_upper\ny\ncutoff\n\n\n\n\n0\n2010-02-16\n8.959074\n8.490492\n9.469220\n8.242493\n2010-02-15\n\n\n1\n2010-02-17\n8.725548\n8.253267\n9.210082\n8.008033\n2010-02-15\n\n\n2\n2010-02-18\n8.609390\n8.144968\n9.107764\n8.045268\n2010-02-15\n\n\n3\n2010-02-19\n8.531294\n8.014229\n9.048185\n7.928766\n2010-02-15\n\n\n4\n2010-02-20\n8.273357\n7.775097\n8.779778\n7.745003\n2010-02-15\n\n\n\n\n\n\n\nperformance_metrics を用いてメトリクス（評価尺度）を計算する。評価尺度は、 平均平方誤差(mean squared error: MSE), 平均平方誤差の平方根 (root mean squared error: RMSE), 平均絶対誤差 (mean absolute error: MAE), 平均絶対パーセント誤差 (mean absolute percent error : MAPE), yhat_lower とyhat_upper の間に入っている割合（被覆率: coverage) である。\n既定値では予測期間の最初の\\(10\\)%は除外して示される。これは、引数rolling_window によって変更できる。\n\nfrom prophet.diagnostics import performance_metrics\ndf_p = performance_metrics(df_cv, rolling_window=0.1)\ndf_p.head()\n\n\n\n\n\n\n\n\nhorizon\nmse\nrmse\nmae\nmape\nmdape\nsmape\ncoverage\n\n\n\n\n0\n37 days\n0.494752\n0.703386\n0.505215\n0.058538\n0.049584\n0.058826\n0.677935\n\n\n1\n38 days\n0.500521\n0.707475\n0.510201\n0.059115\n0.049373\n0.059463\n0.675423\n\n\n2\n39 days\n0.522712\n0.722988\n0.516284\n0.059713\n0.049505\n0.060187\n0.672682\n\n\n3\n40 days\n0.529990\n0.728004\n0.519131\n0.060018\n0.049231\n0.060561\n0.673824\n\n\n4\n41 days\n0.537478\n0.733129\n0.520118\n0.060096\n0.049373\n0.060702\n0.681361\n\n\n\n\n\n\n\n評価尺度は plot_cross_validation_metricで可視化できる。以下では平均絶対パーセント誤差(MAPE)を描画している．\n\nfrom prophet.plot import plot_cross_validation_metric\nplot_cross_validation_metric(df_cv, metric=`mape`);"
  },
  {
    "objectID": "10forecast.html#主なパラメータと既定値",
    "href": "10forecast.html#主なパラメータと既定値",
    "title": "PyMCによるベイズ推論とProphetによる時系列データの予測",
    "section": "主なパラメータと既定値",
    "text": "主なパラメータと既定値\n以下にProphetの主要なパラメータ（引数）とその既定値を示す．\n\ngrowth=linear :傾向変動の関数．既定値は線形．ロジスティック曲線にするにはlogisticに設定\nchangepoints=None : 傾向変更点のリスト\nchangepoint_range = \\(0.8\\) : 傾向変化点の候補の幅（先頭から何割を候補とするか）\nn_changepoints=25 : 傾向変更点の数\nyearly_seasonality=auto : 年次の季節変動を考慮するか否か\nweekly_seasonality=auto : 週次の季節変動を考慮するか否か\ndaily_seasonality=auto : 日次の季節変動を考慮するか否か\nholidays=None : 休日のリスト\nseasonality_prior_scale= \\(10.0\\) : 季節変動の事前分布のスケール値（パラメータの柔軟性を表す）\nholidays_prior_scale= \\(10.0\\) : 休日のの事前分布のスケール値（パラメータの柔軟性を表す）\nchangepoint_prior_scale= \\(0.05\\) : 傾向変更点の事前分布のスケール値（パラメータの柔軟性を表す）\nmcmc_samples= \\(0\\) : MCMC法のサンプル数\ninterval_width= \\(0.8\\) : 不確実性の幅\nuncertainty_samples= \\(1000\\) : 不確実性の幅を計算する際のサンプル数"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "foo\n\n foo ()"
  },
  {
    "objectID": "11networkx.html",
    "href": "11networkx.html",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "",
    "text": "#default_exp networkx\n# hide\n# %reload_ext autoreload\n# %autoreload 2\n# %load_ext lab_black\n# hide_input\nfrom IPython.display import Image, YouTubeVideo\n\nYouTubeVideo(\"YrkfcVlr_bA\", width=200, height=150)\n# hide_input\nYouTubeVideo(\"9XMJVu0Y9LY\", width=200, height=150)\nNetwrokX https://networkx.org/ はグラフ・ネットワーク解析のためのパッケージである．\nここでは実務で用いる機能を中心に解説する．\nimport networkx as nx  # networkxパッケージを nx という別名で読み込み\nimport matplotlib.pyplot as plt  # 描画用パッケージの読み込み\n\n# 図の表示用のマジックコマンド\n# export\nimport networkx as nx  # networkxパッケージを nx という別名で読み込み\nimport matplotlib.pyplot as plt  # 描画用パッケージの読み込み"
  },
  {
    "objectID": "11networkx.html#グラフ理論",
    "href": "11networkx.html#グラフ理論",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "グラフ理論",
    "text": "グラフ理論\nグラフ \\(G=(V,E)\\) とは，点集合 \\(V\\) と枝集合 \\(E\\) から構成される概念である． 点集合の要素を点(vertex, node)とよび， \\(u, v (\\in V)\\) などの記号で表す． 枝集合の要素を枝(edge, arc)とよび， \\(e (\\in E)\\) と表す． 2点間に複数の枝がない場合には，両端点 \\(u,v\\) を決めれば一意に枝が定まるので，枝を両端にある点の組として \\((u,v)\\) もしくは \\(uv\\) と表すことができる．\n枝に「向き」をつけたグラフを有向グラフ(directed graph, digraph)とよび，有向グラフの枝を有向枝(directed edge， arc)とよぶ． 一方，通常の（枝に向きをつけない）グラフであることを強調したいときには，グラフを無向グラフ(undirected graph)とよぶ．\nネットワーク(network)とは，有向グラフに枝上を流れる「もの」（フロー）を付加した概念である． ネットワーク上の最適化理論は 1950年代にはじまり，その実務的な重要性と理論的な美しさから，急速に発展した分野である．\nNetworkXでは，点をnode，枝をedgeとよんでいる．\n\nグラフの生成法\nグラフクラス Graph もしくは有向グラフクラス DiGraph から生成する．\nimport networkx as nx\n\nG = nx.Graph()     #（無向）グラフ G の生成\n\nD = nx.DiGraph()   #有向グラフ D の生成\n\nG = nx.Graph()  # （無向）グラフ G の生成\nG\n\n&lt;networkx.classes.graph.Graph&gt;\n\n\n\n\n点と枝の追加方法\n\n点の追加\n\nG.add_node(n)\nで，グラフGに点nを追加する． n は不変オブジェクトなら何でも良い．\n\n枝の追加\n\nG.add_edge(u,v)\nで，グラフGに枝(u,v)を追加する． 枝を追加すると点は自動的に追加される．\n\nG.add_node(\"Tokyo\")\nG.add_edge(1, 2)\nprint(G)\n\nGraph with 3 nodes and 1 edges\n\n\n\n\nグラフの情報\nG.nodesで点の情報，G.edgesで枝の情報を得ることができる．\n\nprint(G.nodes)\nprint(G.edges)\n\n['Tokyo', 1, 2]\n[(1, 2)]\n\n\n\n\n点，枝に属性を付与\nG.add_node(n,attr_dict)\nで，第2引数 attr_dict に任意の属性を名前付き引数として付加することもできる．以下に例を示す．\nG.add_node(1)\nG.add_node(\"Tokyo\")\nG.add_node(5, demand=500)\nG.add_node(6, product=[\"A\",\"F\",\"D\"])\nG.add_edge(u,v,attr_dict)\nで，第3引数attr_dictに任意の属性を名前付き引数として付加することもできる．以下に例を示す．\nG.add_edge(1,2)\nG.add_edge(1,3)\nG.add_edge(2,3, weight=7, capacity=15.0)\nG.add_edge(1,4, cost=1000)\n\n\n一度にたくさん追加\n\n複数の点を一度に追加\n\nG.add_nodes_from(L)\nはリストL内の各要素を点としてグラフGに追加する．引数はリストLのかわりに集合，辞書，文字列，グラフオブジェクトなども可能である．\n\n複数の枝を一度に追加\n\nG.add_edges_from(L)\nは長さ2のタプル(u,v)を要素としたリストL内の要素を枝(u,v)として追加する． 以下に例を示す．\nG.add_edges_from([(1,2),(1,3),(2,3),(1,4)]\nG.add_weighted_edges_from(L)は長さ3のタプル(u,v,w)を要素としたリストL内の要素を， 枝(u,v)ならびに重みを表す属性wとして追加する．重みの属性名の既定値はweightである． 以下に例を示す．\nG.add_weighted_edges_from([(\"s\",1,5),(\"s\",2,8),(2,1,2),(1,\"t\",8),(2,3,5),(3,\"t\",6)])"
  },
  {
    "objectID": "11networkx.html#グラフの生成と描画",
    "href": "11networkx.html#グラフの生成と描画",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "グラフの生成と描画",
    "text": "グラフの生成と描画\n3点からなる完全グラフ(complete graph: すべての点の間に枝がある無向グラフ）を生成して，描画する．\n以下の3通りの方法を示す．\n\n一番簡単で単純な方法（これが基本）\nforループを使う方法（点の数が増えてきたらこれを使う）\n関数を使って一発\n\nG=nx.complete_graph(3)\n描画はdraw関数を用いる．引数はグラフのインスタンスである．\nJupyter環境で %matplotlib inline と宣言している場合にはmatplotlibの描画関数 plt.show() は省略できる．\n\nG = nx.Graph()  # グラフのインスタンスを生成\nG.add_edge(1, 2)  # 枝を追加\nG.add_edge(1, 3)  # 枝を追加\nG.add_edge(2, 3)  # 枝を追加\nnx.draw(G)  # グラフを描画\nprint(G.nodes)\nprint(G.edges)\n\n[1, 2, 3]\n[(1, 2), (1, 3), (2, 3)]\n\n\n\n\n\n\nG = nx.Graph()  # グラフのインスタンスを生成\nfor i in range(3):\n    for j in range(3):\n        if i &lt; j:  # 無向グラフなので，iより大きいjの場合だけ枝を生成\n            G.add_edge(i, j)\n# nx.draw(G)\n\n\nG = nx.complete_graph(3)  # 完全グラフを生成するcomplete_graph関数を利用\n# nx.draw(G)\n\n\npyvisで動くグラフを描画\npyvisパッケージ (https://pyvis.readthedocs.io/en/latest/index.html) を使うと，動かせるグラフを生成できる．\nGoogle Colabの場合は，\n!pip install pyvis\nでインストールし，\nfrom pyvis.network import Network\nnet = Network()\nとpyvisのグラフ netを生成する．\nJupyter Notebook (Lab.) の場合には，引数の notebookをTrueにして生成する．\nfrom pyvis.network import Network\nnet= Network(notebook=True)\nNetworkXのグラフはfrom_nxメソッドでpyvisのグラフに変換できる．\nGoogle Colabの場合には，その場で描画できないので，生成されたグラフ(graph.html)をダウンロードしてからブラウザで開く．\n\nfrom pyvis.network import Network\n\nnet = Network(notebook=True)\nnet.from_nx(G)\nnet.show(\"graph.html\")  # 画面に出したいときには，この行を生かす\n\n\n        \n        \n\n\n\n\n問題（グラフの生成と描画）\n\n5点の完全グラフを生成し描画せよ． ここで完全グラフとは，すべての点間に枝がある無向グラフである．\n\\(3 \\times 3\\) の格子グラフを生成し，描画せよ． ここで格子グラフ(grid graph)とは，2次元平面上に 座標 \\((i,j) (i=1,2,\\ldots,n; j=1,2,\\ldots,m)\\) をもつように \\(n m\\)個の点を配置し， 座標 \\((i,j)\\) の各点に対して，右の点 \\((i+1,j)\\) もしくは上の点 \\((i,j+1)\\) が存在するなら枝をはることによって得られるグラフであり， grid_2d_graph(n,m)関数で生成できる．\n\n\n# export\n# G=nx.complete_graph(5)\n# nx.draw(G)\n\n\n# export\n# Grid = nx.grid_2d_graph(3,3)\n# nx.draw(Grid)"
  },
  {
    "objectID": "11networkx.html#点枝の情報",
    "href": "11networkx.html#点枝の情報",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "点・枝の情報",
    "text": "点・枝の情報\nここでは，点と枝に関する情報にアクセスする方法について述べる．\n\nG.nodesメソッドはグラフGに含まれる点の集合（実際はViewと呼ばれるオブジェクト）を返す．\nG.nodes[n]は点nの属性の情報を辞書として返す．\nfor n in GはグラフGの点に対する反復を行う．\n\n\nD = nx.DiGraph()\nD.add_node(\"Customer\", demand=500)\nD.add_node(\"Plant\", product=[\"A\", \"F\", \"D\"])\nD.add_edge(\"Plant\", \"Customer\")\n\nprint(D.nodes)\nprint(D.nodes[\"Customer\"], D.nodes[\"Plant\"])\nfor n in D:\n    print(n)\n\n['Customer', 'Plant']\n{'demand': 500} {'product': ['A', 'F', 'D']}\nCustomer\nPlant\n\n\n\nG.edgesメソッドはグラフGに含まれるすべての枝の集合（実際はViewと呼ばれるオブジェクト）を返す．\nfor e in G.edges() でグラフGの枝に対する反復を行うことができる．\nG.neighbors(u)は点uに隣接する（有向グラフの場合には後続する）点のイテレータを返す．\n\n以下の例では，点 \\(1\\) に隣接する点は \\(2,3,4\\) であり，点 \\(2\\) に隣接する点は \\(1,3\\)， 点\\(3\\)に隣接する点は\\(1,2\\)， 点 \\(4\\) に隣接するのは点 \\(1\\) だけである．\n\nG = nx.Graph()\nG.add_edges_from([(1, 2), (1, 3), (2, 3), (1, 4)])\nfor n in G.neighbors(1):\n    print(n)\nfor n in G:\n    print(n, list(G.neighbors(n)))\n\n2\n3\n4\n1 [2, 3, 4]\n2 [1, 3]\n3 [1, 2]\n4 [1]\n\n\n\nG[u]は点uに隣接する点vをキーとし，枝(u,v)に付加された情報を値とした辞書を返す．\n\n以下の例では，点1に隣接する点は2,3,4であり，接続する枝の重みはそれぞれ100,200,50である．\n\nG[u][v]は枝(u,v)に付加された属性の情報を辞書として返す．\n\nつまり，枝(1,2)の重みは100である．\n\nG = nx.Graph()\nG.add_weighted_edges_from([(1, 2, 100), (1, 3, 200), (2, 3, 60), (1, 4, 50)])\nprint(G[1])\nprint(G[1][2])\n\n{2: {'weight': 100}, 3: {'weight': 200}, 4: {'weight': 50}}\n{'weight': 100}\n\n\n\nD.successors(u)は有向グラフDに対する点uの後続点のイテレータを返す．\nD.predecessors(u)は有向グラフDに対する点uの先行点のイテレータを返す．\n\n\nfor n in D.successors(\"Plant\"):\n    print(n)\n\nCustomer\n\n\n\n問題\n\\(3 \\times 3\\) の格子グラフを生成し，枝の重みをランダムに設定せよ．\n\n# export\n# import random\n# Grid = nx.grid_2d_graph(3,3)\n# for (u,v) in Grid.edges():\n#     Grid[u][v][\"weight\"] = random.random()"
  },
  {
    "objectID": "11networkx.html#描画の引数とレイアウト",
    "href": "11networkx.html#描画の引数とレイアウト",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "描画の引数とレイアウト",
    "text": "描画の引数とレイアウト\n関数 draw の代表的な引数は以下の通り．\n\npos：点をキー，座標（\\(x,y\\)のタプル）を値とした辞書を与える．これによって点の座標を指定できる． 省略された場合にはバネ法（後述）によって計算された座標に描画する．\nwith_labels：点の名称の表示の有無を指定できる．既定値はFalse．\nnodelist：描画する点のリストを指定できる．\nedgelist：描画する枝のリストを指定できる．\nnode_size：描画する点の大きさを指定できる．既定値は \\(300\\)．\nnode_color：描画する点の色を指定できる．既定値は “r”（赤）．\nwidth：描画する枝の幅を指定できる．既定値は \\(1.0\\)．\nedge_color：描画する枝の色を指定できる．既定値は “k” （黒）．\n\n描画の際の点の位置posを求めるための関数として，以下のものが準備されている．\n\nspring_layout(G)：隣接する点の間に反発するバネがあると仮定して得られるレイアウト（バネのレイアウト）の座標を返す． これが既定値であるので，引数posを省略して描画した場合には，バネのレイアウトになる．\ncircular_layout(G)：点を円上に配置したレイアウト（円上レイアウト）の座標を返す．\nrandom_layout(G)：点を正方形内にランダムに配置したレイアウト（ランダム・レイアウト）の座標を返す．\nshell_layout(G,nlist)：点を同心円状に配置したレイアウト（同心円レイアウト）の座標を返す． nlistは点のリストのリストであり，各リストは同心円に含まれる点集合を表す．\nspectral_layout(G)：Laplace行列（次数対角行列から隣接行列を減じたもの）の固有値を用いたレイアウト（スペクトル・レイアウト）の座標を返す．\nkamada_kawai_layout(G)：Kamada-Kawaiによる枝の重み（距離）を考慮したレイアウトの座標を返す．\n\n例として円上レイアウトでグラフを描画する．\n\nG = nx.Graph()\nG.add_edges_from([(1, 2), (1, 3), (2, 3), (1, 4), (1, 5)])\npos = nx.circular_layout(G)\nnx.draw(G, pos=pos, edge_color=\"r\", node_color=\"y\", with_labels=True)\n\n\n\n\n\n# hide\n# net.barnes_hut()\n# net.force_atlas_2based()\n# net.hrepulsion()\n# net.repulsion()\n\n\n# hide\n# net= Network(notebook=True)\n# net.from_nx(G)\n# net.show(\"graph.html\")\n\n\n問題\n以下のグラフ生成から好きなものを3つ生成し，描画せよ．\nG = nx.cycle_graph(6)\nG = nx.balanced_tree(2, 2)\nG = nx.complete_graph(5)\nG = nx.complete_bipartite_graph(3, 3)\nG = nx.grid_2d_graph(3, 3)\nG = nx.hypercube_graph(4)\nG = nx.chvatal_graph()\nG = nx.cubical_graph()\nG = nx.octahedral_graph()\nG = nx.dodecahedral_graph()\nG = nx.icosahedral_graph()\nG = nx.petersen_graph()\nG = nx.truncated_cube_graph()\nG = nx.truncated_tetrahedron_graph()\nG = nx.tutte_graph()\nG = nx.fast_gnp_random_graph(30, 0.1)\nG = nx.random_geometric_graph(10, 0.2)\nG = nx.bipartite.random_graph(10, 30, 0.3)\nG = nx.bipartite.gnmk_random_graph(10, 30, 50)\nまた， 各グラフを、円上レイアウト， バネのレイアウト， スペクトル・レイアウトのいずれかを1つずつ選び、描画せよ．\n\n# export\n# G=nx.cycle_graph(6)\n# pos=nx.spring_layout(G)\n# nx.draw(G,pos=pos,node_size=1000,with_labels=True,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.balanced_tree(2,2)\n# pos=nx.spring_layout(G)\n# nx.draw(G,pos=pos,node_size=1000,with_labels=True,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.complete_graph(5)\n# pos=nx.circular_layout(G)\n# nx.draw(G,pos=pos,node_size=1000,with_labels=True,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.hypercube_graph(4)\n# pos=nx.spring_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.chvatal_graph()\n# pos=nx.spring_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.cubical_graph()\n# pos=nx.spring_layout(G)\n# nx.draw(G,pos=pos,node_size=1000,with_labels=True,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.octahedral_graph()\n# #pos=nx.spring_layout(G)\n# pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.dodecahedral_graph()\n# pos=nx.spring_layout(G)\n# #pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.icosahedral_graph()\n# #pos=nx.spring_layout(G)\n# pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.petersen_graph()\n# pos=nx.spring_layout(G)\n# #pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.truncated_cube_graph()\n# #pos=nx.spring_layout(G)\n# pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.truncated_tetrahedron_graph()\n# pos=nx.spring_layout(G)\n# ###pos=nx.spectral_layout(G)\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.tutte_graph()\n# #pos=nx.spring_layout(G)\n# pos=nx.spectral_layout(G)\n# #pos=nx.shell_layout(G,[nodes[5:10],nodes[0:5]])\n# nx.draw(G,pos=pos,node_size=100,with_labels=False,node_color=\"w\",edge_color=\"g\",width=5)\n\n\n# export\n# G=nx.fast_gnp_random_graph(30,0.1)\n# #G=nx.gnm_random_graph(10,18)\n# #G=nx.random_regular_graph(3,10)\n# nx.draw(G)\n\n\n# export\n# G=nx.random_geometric_graph(100,0.2)\n# pos=nx.get_node_attributes(G,'pos')\n# nx.draw(G,pos=pos)"
  },
  {
    "objectID": "11networkx.html#グラフに対する基本操作",
    "href": "11networkx.html#グラフに対する基本操作",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "グラフに対する基本操作",
    "text": "グラフに対する基本操作\nここではグラフに対する基本的な操作を紹介する．\n\ncomplement(G): 補グラフ(complement)を返す． ここで補グラフ \\(G=(V,E)\\) のとは，点集合 \\(V\\) をもち，\\((u,v) \\not\\in E\\) のときに \\(u,v\\) 間に枝をはったグラフである．\nreverse(G): 有向グラフの枝を逆にしたものを返す．\n\n\nG = nx.Graph()\nG.add_edges_from([(0, 1), (0, 2), (0, 3)])\npos = nx.spring_layout(G)\nnx.draw(G, pos=pos, edge_color=\"y\", with_labels=True)\n\nC = nx.complement(G)\nprint(C.edges())\nnx.draw(C, pos=pos, edge_color=\"r\", with_labels=True)\n\n[(1, 2), (1, 3), (2, 3)]\n\n\n\n\n\n\ncompose(G, H): GとHの和グラフ(union graph)を返す．ただしGとHに共通部分があってもよい． ここで\\(G=(V_1,E_1)\\) と \\(H=(V_2,E_2)\\) の和グラフとは， 点集合 \\(V_1 \\cup V_2\\) と枝集合 \\(E_1 \\cup E_2\\) をもつグラフである．\nunion(G, H): グラフGとHの和グラフを返す． ただしGとHに共通部分があってはいけない（もし，共通部分があった場合には例外を返す）．\nintersection(G, H): 同じ点集合をもつグラフGとHに対して，両方に含まれている枝から成るグラフ（交差グラフ）を返す．\ndifference(G, H): 同じ点集合をもつグラフGとHに対して，Gには含まれているがHには含まれていない枝から成るグラフ（差グラフ）を返す．\nsymmetric_difference(G, H): 同じ点集合をもつグラフGとHに対して，GまたはHに含まれており，かつ両者に含まれていない枝から成るグラフ（対称差グラフ）を返す．\n\n\nG = nx.Graph()\nG.add_edges_from([(0, 1), (0, 2), (0, 3)])\npos = nx.spring_layout(G)\nnx.draw(G, pos=pos, edge_color=\"y\", with_labels=True)\n\n\n\n\n\nH = nx.cycle_graph(4)\nnx.draw(H, pos=pos, edge_color=\"r\", with_labels=True)\n\n\n\n\n\n# C = nx.compose(G,H)\n# C = nx.union(G,H)\n# C = nx.intersection(G,H)\n# C = nx.difference(G,H)\n# C = nx.difference(H,G)\nC = nx.symmetric_difference(G, H)\nprint(C.edges())\nnx.draw(C, pos=pos, edge_color=\"g\", with_labels=True)\n\n[(0, 2), (1, 2), (2, 3)]\n\n\n\n\n\n\ncartesian_product(G, H): グラフGとHに対する直積(Cartesian product)グラフを返す． ここで，グラフ \\(G=(V_1,E_1)\\) と \\(H=(V_2,E_2)\\) の直積グラフとは， 点集合 \\(V_1 \\times V_2 = \\{ (v_1,v_2) | v_1 \\in V_1, v_2 \\in V_2 \\}\\) （点集合 \\(V_1,V_2\\) の直積）と， 以下を満たす枝集合から構成されるグラフである．\n\n直積グラフの枝 \\(((u,x),(v,y))\\) が存在 \\(\\Leftrightarrow\\) 「\\(x=y\\) かつ \\((u,v) \\in E_1\\)」もしくは「\\(u=v\\) かつ \\((x,y) \\in E_2\\)」\n\nlexicographic_product(G, H): グラフGとHに対する辞書的積(lexicographic product)グラフを返す． ここで，グラフ \\(G=(V_1,E_1)\\) と \\(H=(V_2,E_2)\\) の辞書的積グラフとは， 点集合 \\(V_1 \\times V_2\\) と， 以下を満たす枝集合から構成されるグラフである．\n\n辞書的積グラフの枝 \\(((u,x),(v,y))\\) が存在 \\(\\Leftrightarrow\\) 「\\((u,v) \\in E_1\\)」もしくは「\\(u=v\\) かつ \\((x,y) \\in E_2\\)」\n\ntensor_product(G, H): グラフGとHに対するテンソル積(tensor product)グラフを返す． ここで，グラフ \\(G=(V_1,E_1)\\) と \\(H=(V_2,E_2)\\) のテンソル積グラフとは， 点集合 \\(V_1 \\times V_2\\) と， 以下を満たす枝集合から構成されるグラフである．\n\nテンソル積グラフの枝 \\(((u,x),(v,y))\\) が存在 \\(\\Leftrightarrow\\) 「\\((u,v) \\in E_1\\) かつ \\((x,y) \\in E_2\\)」\n\nstrong_product(G, H): グラフGとHに対する強積(strong product)グラフを返す． ここで，グラフ \\(G=(V_1,E_1)\\) と \\(H=(V_2,E_2)\\) の強積グラフとは， 点集合 \\(V_1 \\times V_2\\) と， 以下を満たす枝集合から構成されるグラフである．\n\n強積グラフの枝 \\(((u,x),(v,y))\\) が存在 \\(\\Leftrightarrow\\) 「\\(((u,x),(v,y))\\) が直積グラフの枝もしくはテンソル積グラフの枝」\n以下の例では，グラフ \\(G\\) が商品 \\(0,1,2\\) の関連， グラフ \\(H\\) が店舗 \\(A,B,C\\) 間の競合を表すものとする．\n直積グラフの点は，各店舗で売られている各商品を表しており， 同じ店で販売されている関連する商品，もしくは競合する店で販売されている同じ商品に 対して枝がはられていると解釈できる．\n\nG = nx.Graph()\nH = nx.Graph()\nG.add_edges_from([(0, 1), (0, 2)])\nH.add_edges_from([(\"A\", \"B\"), (\"A\", \"C\")])\nProduct = nx.cartesian_product(G, H)\nnx.draw(Product, with_labels=True, node_size=1000, node_color=\"y\")\n\n\n\n\n\n問題\n上の例題に対して辞書的積， テンソル積， 強積を計算し，描画せよ． それぞれ，どのような意味を持つか考察せよ．\n\n# export\n# G=nx.Graph()\n# G.add_edges_from([(0,1),(1,2)])\n# H=nx.Graph()\n# H.add_edges_from([('A','B'),('A','C')])\n# #Product = nx.cartesian_product(G,H)\n# #Product = nx.lexicographic_product(G,H)\n# #Product = nx.tensor_product(G,H)\n# Product = nx.strong_product(G,H)\n\n# pos={}\n# for i in range(3):\n#     for j,item in enumerate([\"B\",\"A\",\"C\"]):\n#         pos[(i,item)]=(i,j)\n\n# #nx.draw(Product,with_labels=True)\n# nx.draw(Product,with_labels=True,pos=pos,\n#         node_color=\"w\",node_size=1500,edge_color=\"g\",width=3)\n\n#hide ### 問題　（難）\n3つの工場 \\(0,1,2\\) で自動車を生産することを考える． 工場 \\(0,1\\) は部品工場であり，そこでは部品 \\(P1, P2, P3\\) を製造している． 工場 \\(2\\) は組み立て工場であり，そこでは部品を組み立てて完成品 \\(P4, P5\\) を製造している．\n部品と完成品の関係は，部品展開表とよばれるグラフによって与えられており， \\(P4\\) を製造するためには，部品 \\(P1, P2\\) が1つずつ必要であり， \\(P5\\) を製造するためには，部品 \\(P2, P3\\) が1つずつ必要であるものとする． 工場 \\(0\\) から工場 \\(2\\) への輸送と，工場 \\(1\\) から工場 \\(2\\) への輸送を表すグラフと，部品展開表を表すグラフの テンソル積をとることによって，各工場における製品の製造を点，可能な輸送経路を枝としたグラフを生成せよ．"
  },
  {
    "objectID": "11networkx.html#マッチングとeuler閉路",
    "href": "11networkx.html#マッチングとeuler閉路",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "マッチングとEuler閉路",
    "text": "マッチングとEuler閉路\n以下のサイト（もしく本）を参照されたい．\n\nマッチング： Pythonによる実務で役立つ最適化問題100+ (2) ―割当・施設配置・在庫最適化・巡回セールスマン― 13章\n\nhttps://scmopt.github.io/opt100/30matching.html\n\nEuler閉路： Pythonによる実務で役立つ最適化問題100+ (3) ―配送計画・パッキング・スケジューリング― 24章\n\nhttps://scmopt.github.io/opt100/64euler.html\n\n問題（マッチングとEuler閉路）\n以下のグラフは奇数の次数をもつ点があるので，Euler閉路（すべての枝をちょうど1回通過する閉路：すべての点の次数が偶数であるのが，Euler閉路をもつための必要十分条件である）をもたない． 奇数の次数をもつ点集合に対して，点間の最短距離を計算し，最小距離のマッチング（点の次数が1以下の部分グラフ)を求めよ． マッチングに含まれる枝をもとのグラフに加えるとEuler閉路をもつようになる（なぜか？理由を考えよ）． マッチングを加えたグラフに対するEuler閉路を求めよ．\n\nG = nx.grid_2d_graph(3, 4)\nnx.draw(G)\n\n\n\n\n\n# export\n# G = nx.grid_2d_graph(3,4)\n# NewG = nx.eulerize(G)\n# for (u,v) in nx.eulerian_circuit(NewG):\n#     print(u,v)"
  },
  {
    "objectID": "11networkx.html#最小木",
    "href": "11networkx.html#最小木",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "最小木",
    "text": "最小木\n最小木問題については，以下のサイト（もしく本）を参照されたい．\n\nPythonによる実務で役立つ最適化問題100+ (1) ―グラフ理論と組合せ最適化への招待― 第４章\n\nhttps://scmopt.github.io/opt100/05mst.html\n\n問題（最小木）\n\n\\(5 \\times 5\\) の格子グラフ（枝の重みはすべて \\(1\\)）の最小木（枝の重みの合計が最小の閉路を含まない連結グラフ）を求めよ．\n\\(5 \\times 5\\) の格子グラフの枝の重みをランダムに設定した上で，最小木を求め，最小木に含まれる枝を異なる色で描画せよ．\n枝上に距離が定義された無向グラフ \\(G=(V,E)\\) を考える． このグラフの点集合 \\(V\\) を \\(k\\)個に分割したとき，分割に含まれる点同士の最短距離を最大化するようにしたい．これは最小木に含まれる枝を距離の大きい順に \\(k-1\\) 本除くことによって得ることができる． ランダムに距離を設定した \\(5 \\times 5\\) の格子グラフに対して \\(k=5\\) の分割を求めよ．\n\n\n# export\n# G = nx.grid_2d_graph(5,5)\n# print(list(nx.minimum_spanning_edges(G)))\n\n# m, n = 5, 5\n# lb, ub = 1, 20\n# G = nx.grid_2d_graph(m, n)\n# for (i,j) in G.edges():\n#     G[i][j][\"weight\"] = random.randint(lb, ub)\n# pos ={(i,j):(i,j) for (i,j) in G.nodes() }\n# edges = list(nx.minimum_spanning_edges(G))\n# plt.figure()\n# nx.draw(G, pos=pos, node_size=100)\n# edge_labels ={}\n# for (i,j) in G.edges():\n#     edge_labels[i,j] = f\"{ G[i][j]['weight'] }\"\n# nx.draw_networkx_edge_labels(G,pos,edge_labels=edge_labels)\n# nx.draw(G, pos=pos, width=5, edgelist= edges, edge_color =\"orange\")\n# plt.show()\n\n# weight =[ ]\n# for (i,j,w) in edges:\n#     weight.append( (w[\"weight\"], i,j) )\n# weight.sort(reverse=True)\n# G1 = nx.Graph()\n# for (w,i,j) in weight[5:]:\n#     G1.add_edge(i,j)\n# nx.draw(G, pos=pos, node_size=100)\n# nx.draw_networkx_edge_labels(G,pos,edge_labels=edge_labels)\n# nx.draw(G1, pos=pos, node_size=100, width=10, edge_color=\"orange\")"
  },
  {
    "objectID": "11networkx.html#最短路",
    "href": "11networkx.html#最短路",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "最短路",
    "text": "最短路\n最短路問題の詳細については，以下のサイト（もしくは本）を参照されたい．\n\nPythonによる実務で役立つ最適化問題100+ (1) ―グラフ理論と組合せ最適化への招待― 第2章\n\nhttps://scmopt.github.io/opt100/03sp.html\n簡単な通勤（通学）の例を示そう．\n八千代緑が丘から越中島までの電車による経路を求めたい． 枝ごとの移動時間と移動費用を入力して，最短時間パスと最小費用パスを求めよ． 乗り換えの待ち時間は無視してよいが，徒歩の時間は考慮せよ．\n\nG = nx.Graph()\nG.add_edge(\"八千代緑が丘\", \"西船橋\", weight=15, cost=490)\nG.add_edge(\"西船橋\", \"門前仲町\", weight=20, cost=230)\nG.add_edge(\"門前仲町\", \"越中島\", weight=10, cost=0)\nG.add_edge(\"西船橋\", \"越中島\", weight=24, cost=380)\n\npath = nx.dijkstra_path(G, \"八千代緑が丘\", \"越中島\")\nprint(\"最短時間パス\", path)\n\npath = nx.dijkstra_path(G, \"八千代緑が丘\", \"越中島\", weight=\"cost\")\nprint(\"最小費用パス\", path)\n\n最短時間パス ['八千代緑が丘', '西船橋', '越中島']\n最小費用パス ['八千代緑が丘', '西船橋', '門前仲町', '越中島']\n\n\n\n問題\n自宅から大学（もしくは職場）までの最短時間と最小費用のパスを求めるためのネットワークを作成し，最短時間パスと最小費用パスを求めよ． ただし大学（職場）から徒歩圏の場合は，親戚の家からのパスを求めよ．\n\n# export\n# G = nx.Graph()\n# G.add_edge(\"八千代緑が丘\", \"西船橋\", weight=15, cost=490)\n# G.add_edge(\"西船橋\", \"門前仲町\", weight=20, cost=230)\n# G.add_edge(\"門前仲町\", \"越中島\", weight=10, cost=0)\n# G.add_edge(\"西船橋\", \"越中島\", weight=24, cost=380)\n\n# path = nx.dijkstra_path(G, \"八千代緑が丘\", \"越中島\")\n# print(\"最短時間パス\", path)\n\n# path = nx.dijkstra_path(G, \"八千代緑が丘\", \"越中島\", weight=\"cost\")\n# print(\"最小費用パス\", path)\n\n\n\n問題\n\\(3\\times 3\\) の格子グラフを生成するプログラムを作成し，枝の重みをランダムに設定した上で， 左上の点から右下の点までの最短路を求め，最短路を異なる色で描画せよ．\n\n# export\n# m, n = 3, 3\n# lb, ub = 1, 300\n# G = nx.grid_2d_graph(m, n)\n# for (i,j) in G.edges():\n#     G[i][j][\"weight\"] = random.randint(lb, ub)\n# path = nx.dijkstra_path(G, source=(0,0), target=(2,2))\n# edges =[]\n# for i in range(len(path)-1):\n#     edges.append( (path[i],path[i+1]) )\n# plt.figure()\n# nx.draw(G, pos=pos, node_size=100)\n# edge_labels ={}\n# for (i,j) in G.edges():\n#     edge_labels[i,j] = f\"{ G[i][j]['weight'] }\"\n# nx.draw_networkx_edge_labels(G,pos,edge_labels=edge_labels)\n# nx.draw(G, pos=pos, width=5, edgelist= edges, edge_color =\"orange\")\n# plt.show()\n\n\n\n問題 (PERT)\nあなたは航空機会社のコンサルタントだ．あなたの仕事は，着陸した航空機をなるべく早く離陸させるためのスケジュールをたてることだ． 航空機は，再び離陸する前に幾つかの作業をこなさなければならない． まず，乗客と荷物を降ろし，次に機内の掃除をし，最後に新しい乗客を搭乗させ，新しい荷物を積み込む． 当然のことであるが， 乗客を降ろす前に掃除はできず，掃除をした後でないと新しい乗客を入れることはできず， 荷物をすべて降ろし終わった後でないと，新しい荷物は積み込むことができない． また，この航空機会社では， 乗客用のゲートの都合で，荷物を降ろし終わった後でないと新しい乗客を搭乗させることができないのだ．\n作業時間は，乗客降ろし \\(13\\) 分，荷物降ろし \\(25\\) 分，機内清掃 \\(15\\) 分，新しい乗客の搭乗 \\(27\\) 分， 新しい荷物積み込み \\(22\\) 分とする． さて，最短で何分で離陸できるだろうか？ （ヒント： 最短離陸時間を出すにはグラフの最長路を求める必要がある． 枝の重みを負にして最短路を解けば良い． 枝の重みが負なので， Dijkstra法でなくBellman-Ford法を使う）\n\n# export\n# duration = {1: 13, 2: 25, 3: 15, 4: 27, 5: 22}\n# G = nx.DiGraph()\n# G.add_weighted_edges_from([(0,1,-13),(1,2,-15),(2,3,-27),(0,4,-25),(4,2,0),(4,3,-22)])\n# pred, distance = nx.bellman_ford_predecessor_and_distance(G,source=0)\n# distance\n\n#hide ### 問題 （難）\nDijkstra法を自分で実装せよ．\nNetworkXパッケージのDijkstra法と自分で作成したDijkstra法を大規模な格子グラフで実験し，計算時間を比較せよ．"
  },
  {
    "objectID": "11networkx.html#フロー問題",
    "href": "11networkx.html#フロー問題",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "フロー問題",
    "text": "フロー問題\n以下のサイト（もしく本）を参照されたい．\n\n最大流問題： Pythonによる実務で役立つ最適化問題100+ (1) ―グラフ理論と組合せ最適化への招待― 第8章\n\nhttps://scmopt.github.io/opt100/10maxflow.html\n\n割当問題： Pythonによる実務で役立つ最適化問題100+ (2) ―割当・施設配置・在庫最適化・巡回セールスマン― 14章\n\nhttps://scmopt.github.io/opt100/33ap.html\n\n最小費用流問題： Pythonによる実務で役立つ最適化問題100+ (1) ―グラフ理論と組合せ最適化への招待― 第7章\n\nhttps://scmopt.github.io/opt100/09mcf.html\n\n例題：最大流問題\nランダムな2部グラフを作成し，最大マッチングを最大流問題(maximum flow problem)を解くことによって求めよ．\nここで最大流問題とは，以下に定義される問題である．\n\\(n\\) 個の点から構成される点集合 \\(V\\) および \\(m\\) 本の枝から構成される枝集合 \\(E\\)， 有向グラフ \\(G=(V,E)\\)， 枝上に定義される非負の容量関数 \\(C: E \\rightarrow R_+\\)， 始点 \\(s \\in V\\) および終点 \\(t \\in V\\) が与えられたとき， 始点 \\(s\\) から終点 \\(t\\) までの「フロー」で， その量が最大になるものを求めよ．\nここでフロー(flow)とは枝上に定義された実数値関数 \\(x: E \\rightarrow R\\) で， 以下の性質を満たすものを指す．\n\nフロー整合条件: \\[\n\\sum_{v: vu \\in E} x_{vu} - \\sum_{v: uv \\in E} x_{uv} =0  \\ \\ \\ \\forall u \\in V \\setminus \\{s,t\\}\n\\]\n容量制約と非負制約: \\[\n0 \\leq x_{e} \\leq C_{e} \\ \\ \\  \\forall e \\in E\n\\]\n\nダミーの始点と終点を追加することによって，最大流問題に帰着する．\n\n# ランダムな２部グラフの生成例\nBG = nx.bipartite.random_graph(10, 5, 0.5)\ntop = nx.bipartite.sets(BG)[0]\nother = nx.bipartite.sets(BG)[1]\npos = nx.bipartite_layout(BG, top)\nnx.draw(BG, pos=pos)\n\n\n\n\n\nG = nx.DiGraph()\nG.add_nodes_from([\"source\",\"sink\"])\nG.add_edges_from([ (\"source\",j) for j in top])\nG.add_edges_from([ (i, \"sink\") for i in other])\nG.add_edges_from(BG.edges())\nfor (i,j) in G.edges():\n    G[i][j][\"capacity\"] = 1\nvalue, flow = nx.maximum_flow(G, _s=\"source\", _t=\"sink\")\nprint(\"value=\",value)\nprint(flow)\n\nvalue= 5\n{'source': {0: 0, 1: 0, 2: 0, 3: 1, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 1}, 'sink': {}, 0: {11: 0, 13: 0, 14: 0}, 1: {10: 0, 14: 0}, 2: {10: 0, 12: 0, 14: 0}, 3: {11: 0, 13: 1}, 4: {10: 0, 13: 0, 14: 0}, 5: {11: 1}, 6: {10: 0, 12: 1, 14: 0}, 7: {10: 0, 13: 0, 14: 1}, 8: {13: 0}, 9: {10: 1, 11: 0}, 10: {'sink': 1}, 11: {'sink': 1}, 12: {'sink': 1}, 13: {'sink': 1}, 14: {'sink': 1}}\n\n\n\n\n例題： 割当問題\n4人の作業員 A,B,C,D を4つの仕事 \\(0,1,2,3\\) を1つずつ割り当てることを考える． 作業員が仕事を割り当てられたときにかかる費用が，以下のようになっているとき，最小費用の割当を求めよ．\n\\[\n\\begin{array}{ l    l l l l}\n       & 0 & 1 & 2    &3    \\\\ \\hline\nA      & 25 & 20 & 30 & 27  \\\\\nB      & 17 & 15 & 12 & 16  \\\\\nC      & 25 & 21 & 23 & 19  \\\\\nD      & 16 & 26 & 21 & 22  \n\\end{array}\n\\]\nこの問題は，最小費用流問題(minimum cost flow problem)に帰着できる．\n最小費用流問題は，以下のように定義される問題である．\n有向グラフ \\(G=(V,E)\\)， 枝上に定義される重み（費用）関数 \\(w: E \\rightarrow R\\)， 枝上に定義される非負の容量関数 $C: E R_+ { } $， 点上に定義される流出量関数 \\(b: V \\rightarrow R\\) が与えられたとき， 「実行可能フロー」で，費用の合計が最小になるものを求めよ． ただし，\\(\\sum_{v \\in V} b_v =0\\) を満たすものとする．\n作業員を表す点から仕事を表す点へ \\(1\\) 単位のフローを最小費用で流すことによって求解する．\n\ncost = [[25,20,30,27],\n        [17,15,12,16],\n        [25,21,23,19],\n        [16,26,21,22]]\nG = nx.DiGraph()\nn = len(cost)\nfor i in range(n):\n    G.add_node(i, demand=-1)\n    G.add_node(n+i, demand=1)\nG.add_weighted_edges_from([(i,n+j,cost[i][j]) for i in range(n) for j in range(n)])\nval, flow = nx.algorithms.flow.network_simplex(G)\nprint(val,flow)\n\n67 {0: {4: 0, 5: 1, 6: 0, 7: 0}, 4: {}, 1: {4: 0, 5: 0, 6: 1, 7: 0}, 5: {}, 2: {4: 0, 5: 0, 6: 0, 7: 1}, 6: {}, 3: {4: 1, 5: 0, 6: 0, 7: 0}, 7: {}}\n\n\n\n\n問題（輸送問題）\nあなたは，スポーツ用品販売チェインのオーナーだ． あなたは，店舗展開をしている5つの顧客 （需要地点）に対して， 3つの自社工場で生産した製品を運ぶ必要がある． 調査の結果， 工場での生産可能量（容量）， 顧客への輸送費用，ならびに各顧客における需要量は， 以下のようになっていることが分かった． さて，どのような輸送経路を選択すれば，総費用が最小になるであろうか？\n顧客の需要量，工場から顧客までの輸送費用，ならびに工場の生産容量： \\[\n\\begin{array}{c  c c c c c   c  } \\hline\n顧客 & 1  &  2  & 3  & 4 & 5 &  \\\\  \\hline\n需要量   &80 & 270 & 250 & 160 & 180 &   \\\\ \\hline\n工場  &   輸送費用  &   &    &    &  & 容量  \\\\ \\hline\n1      & 4 & 5 & 6 & 8 & 10 &  500 \\\\\n2      & 6  &4 & 3 & 5 & 8 &  500 \\\\\n3      & 9  & 7 & 4 & 3 & 4 &  500 \\\\ \\hline\n\\end{array}\n\\]\n（ヒント： 最小費用流問題においては，需要（供給は負の需要とみなす）の合計が \\(0\\) でなくてはいけない． 仮想の点を追加することによって，最小費用流問題に帰着せよ）\n\n# export\n# d = {1:80, 2:270, 3:250 , 4:160, 5:180} # demand\n# M = {1:500, 2:500, 3:500}              # capacity\n# c = {(1,1):4,    (1,2):6,    (1,3):9,  # cost\n#      (2,1):5,    (2,2):4,    (2,3):7,\n#      (3,1):6,    (3,2):3,    (3,3):4,\n#      (4,1):8,    (4,2):5,    (4,3):3,\n#      (5,1):10,   (5,2):8,    (5,3):4,\n#      }\n# G = nx.DiGraph()\n# for i in M:\n#     G.add_node(f\"plant{i}\", demand=-M[i])\n# for j in d:\n#     G.add_node(f\"customer{j}\", demand=d[j])\n# total_demand = sum(d[j] for j in d)\n# total_supply = sum(M[i] for i in M)\n# G.add_node(\"dummy\", demand = total_supply-total_demand)\n# G.add_weighted_edges_from([(f\"plant{i}\",f\"customer{j}\",c[j,i]) for i in M for j in d] )\n# G.add_weighted_edges_from([ (f\"plant{i}\",\"dummy\",0) for i in M] )\n# val, flow = nx.algorithms.flow.network_simplex(G)\n# print(val,flow)\n\n\n\n問題（多期間生産計画問題）\n1つの製品の生産をしている工場を考える． 在庫費用は1日あたり，1トンあたり1万円とする． いま7日先までの需要が分かっていて，7日分の生産量と在庫量を決定したい． 各日の需要は，以下の表のようになっている． 工場の1日の稼働時間は \\(8\\)時間，製品1トンあたりの製造時間は\\(1\\)時間としたとき， 稼働時間上限を満たした最小費用の生産・在庫量を決定せよ．\n\n\n\n日\n1\n2\n3\n4\n5\n6\n7\n\n\n\n\n需要量\n5\n7\n8\n2\n9\n1\n3\n\n\n\n\n# export\ndemand = [5, 7, 8, 2, 9, 1, 3]  # 需要量\nT = len(demand)  # 計画期間\nh = 1  # 在庫費用\ncapacity = 8  # 最大稼働時間(=最大生産量；製造時間=1だから)\nG = nx.DiGraph()\nfor i in range(T):\n    G.add_node(f\"period{i}\", demand=demand[i])\nG.add_node(\"dummy\", demand=-sum(demand))\nG.add_weighted_edges_from([(\"dummy\", f\"period{i}\", 0) for i in range(T)])\nG.add_weighted_edges_from([(f\"period{i}\", f\"period{i+1}\", h) for i in range(T - 1)])\nfor i in range(T):\n    G[\"dummy\"][f\"period{i}\"][\"capacity\"] = capacity\nfor i in range(T - 1):\n    G[f\"period{i}\"][f\"period{i+1}\"][\"capacity\"] = sum(demand)\nval, flow = nx.algorithms.flow.network_simplex(G)\nprint(val, flow)\n\n1 {'period0': {'period1': 0}, 'period1': {'period2': 0}, 'period2': {'period3': 0}, 'period3': {'period4': 1}, 'period4': {'period5': 0}, 'period5': {'period6': 0}, 'period6': {}, 'dummy': {'period0': 5, 'period1': 7, 'period2': 8, 'period3': 3, 'period4': 8, 'period5': 1, 'period6': 3}}\n\n\n\n\n問題（下限制約）\n以下の図に示す最小費用流問題を考える．枝上の数値は「単位フローあたりの費用(容量)」であり，点 \\(0\\) から点 \\(4\\) に \\(10\\) 単位のものを最小費用で流したい．\nただし，点2から点3へ向かう枝のフロー量が \\(4\\)以上でなければならないものとする．\nこのフロー量の下限制約を取り除くことを考える． 下限 \\(4\\) を超過した量を新たなフロー量として \\(x'_{23}\\) と記す．元のフロー量 \\(x_{23}\\) とは \\(x_{23}= 4+x'_{23}\\) の関係がある． 変数 \\(x_{23}\\) を \\(x'_{23}\\) に置き換えることによって， 点2におけるフロー整合条件から点2の需要量は \\(4\\) 増え， 点3におけるフロー整合条件から点3の需要量は \\(4\\)減る． また，枝\\((2,3)\\) の容量（フロー量上限）は，\\(1(=5-4)\\)に変更される．\nこの観察を用いて，下限制約付きの最小費用流を求めよ．\n\n#export\nG = nx.DiGraph()\nG.add_node(0, demand=-10)\nG.add_node(4, demand=10)\ncapacity = {(0, 1): 5, (0, 2): 8, (1, 4): 8, (2, 1): 2, (2, 3): 5, (3, 4): 6}\nG.add_weighted_edges_from(\n    [(0, 1, 10), (0, 2, 5), (1, 4, 1), (2, 1, 3), (2, 3, 1), (3, 4, 6)]\n)\nfor (i, j) in G.edges():\n    G[i][j][\"capacity\"] = capacity[i, j]\npos = {0: (0, 1), 1: (1, 2), 2: (1, 0), 3: (2, 0), 4: (2, 2)}\nedge_labels = {}\nfor (i, j) in G.edges():\n    edge_labels[i, j] = f\"{ G[i][j]['weight'] }({ G[i][j]['capacity']})\"\nplt.figure()\nnx.draw(G, pos=pos, with_labels=True, node_size=1000)\nnx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\nplt.show()\n\n\n\n\n\n\n問題（ナプキンのクリーニング） （難）\nあなたはホテルの宴会係だ．あなたは1週間に使用するナプキンを手配する必要がある． 各日の綺麗なナプキンの需要量は平日は \\(100\\)枚，土曜日と日曜日は \\(125\\)枚だ． 新しいナプキンを購入するには \\(100\\)円かかる． 使用したナプキンはクリーニング店で洗濯して綺麗なナプキンにすることができるが， 早いクリーニング店だと1日で1枚あたり \\(30\\)円かかり， 遅いクリーニング店だと2日で1枚あたり \\(10\\)円かかる． 月曜の朝のナプキンの在庫が \\(0\\) としたとき，需要を満たす最適なナプキンの購入ならびにクリーニング計画をたてよ．\nヒント： この問題は下限付きの最小費用流問題に帰着できる．\nさらに、上のナプキンのクリーニング問題において， 日曜末の在庫を月曜の朝に使うことができると仮定したときの最適なナプキンのクリーニング計画をたてよ．\n\n# export\n# G=nx.DiGraph()\n\n# Demand=[100,100,100,100,100,125,125]\n# U=sum(Demand)\n# T=len(Demand)\n# G.add_edge(\"t\",\"s\")\n# for t in range(T):\n#     G.add_node((\"clean\",t),demand=Demand[t])\n#     G.add_node((\"dirty\",t),demand=-Demand[t])\n#     G.add_edge(\"s\",(\"clean\",t),weight=10)         #buy new napkins\n#     G.add_edge((\"clean\",t),(\"dirty\",t),capacity=U-Demand[t]) #use napkins\n#     G.add_edge((\"dirty\",t),\"t\")         #discard napkins\n\n# for t in range(T-1):\n#     G.add_edge((\"clean\",t),(\"clean\",t+1)) #invenory of clean napkins\n#     G.add_edge((\"dirty\",t),(\"clean\",t+1),weight=3) #clean using fast laundry\n\n# for t in range(T-2):\n#     G.add_edge((\"dirty\",t),(\"clean\",t+2),weight=1) #clean using slow laundry\n\n# cost,flow = nx.network_simplex(G)\n\n# print(\"cost=\",cost)\n# for i in G.nodes():\n#     for j in flow[i]:\n#         if flow[i][j]&gt;0:\n#             print(i,j,flow[i][j])\n\n# G=nx.DiGraph()\n\n# Demand=[100,100,100,100,100,125,125]\n# U=sum(Demand)\n# T=len(Demand)\n# G.add_edge(\"t\",\"s\")\n# for t in range(T):\n#     G.add_node((\"clean\",t),demand=Demand[t])\n#     G.add_node((\"dirty\",t),demand=-Demand[t])\n#     G.add_edge(\"s\",(\"clean\",t),weight=10)         #buy new napkins\n#     G.add_edge((\"clean\",t),(\"dirty\",t),capacity=U-Demand[t]) #use napkins\n#     G.add_edge((\"dirty\",t),\"t\")         #discard napkins\n\n# for t in range(T):\n#     G.add_edge((\"clean\",t),(\"clean\",(t+1) % T )) #invenory of clean napkins\n#     G.add_edge((\"dirty\",t),(\"clean\", (t+1)% T ),weight=3) #clean using fast laundry\n\n# for t in range(T):\n#     G.add_edge((\"dirty\",t),(\"clean\",(t+2) % T),weight=1) #clean using slow laundry\n\n# cost,flow = nx.network_simplex(G)\n\n# print(\"cost=\",cost)\n# for i in G.nodes():\n#     for j in flow[i]:\n#         if flow[i][j]&gt;0:\n#             print(i,j,flow[i][j])"
  },
  {
    "objectID": "11networkx.html#最大安定集合問題と最大クリーク問題",
    "href": "11networkx.html#最大安定集合問題と最大クリーク問題",
    "title": "グラフ・ネットワーク解析パッケージ NetworkX",
    "section": "最大安定集合問題と最大クリーク問題",
    "text": "最大安定集合問題と最大クリーク問題\n最大安定集合問題(maximum stable set problem)は，以下のように定義される問題である．\n点数 \\(n\\) の無向グラフ \\(G=(V,E)\\) が与えられたとき，点の部分集合 \\(S (\\subseteq V)\\) は， すべての \\(S\\) 内の点の間に枝がないとき安定集合（stable set）とよばれる． 最大安定集合問題とは，集合に含まれる要素数（位数）\\(|S|\\) が最大になる安定集合 \\(S\\) を求める問題である.\nこの問題のグラフの補グラフ（枝の有無を反転させたグラフ）を考えると， 以下に定義される最大クリーク問題（maximum clique problem）になる．\n無向グラフ \\(G=(V,E)\\) が与えられたとき，点の部分集合 \\(C (\\subseteq V)\\)は， \\(C\\) によって導かれた誘導部分グラフが完全グラフになるときクリーク（clique）とよばれる （完全グラフとは，すべての点の間に枝があるグラフである）． 最大クリーク問題とは，位数 \\(|C|\\) が最大になるクリーク \\(C\\) を求める問題である．\nこれらの2つの問題は（お互いに簡単な変換によって帰着されるという意味で）同値である．\n最大安定集合問題と最大クリーク問題の詳細については，以下のサイト（もしくは本）を参照されたい．\n\nPythonによる実務で役立つ最適化問題100+ (1) ―グラフ理論と組合せ最適化への招待― 第11章\n\nhttps://scmopt.github.io/opt100/18clique.html\n\n問題 （\\(8\\)-クイーン問題)\n\\(8 \\times 8\\) のチェス盤に \\(8\\)個のクイーンを置くことを考える． チェスのクイーンとは，将棋の飛車と角の両方の動きができる最強の駒である． クイーンがお互いに取り合わないように置く配置を1つ求めよ．\n将棋を知らない人のために言い換えると，\\(8 \\times 8\\) のマス目に，同じ行（列）には高々1つのクイーンを置き， 左下（右下）斜めにも高々1つのクイーンを置くような配置を求める問題である （ヒント： 実は，この問題は安定集合問題の特殊形である． グラフは \\(i\\) 行，\\(j\\) 列のマス目を点とみなして，クイーンが取り合うとき点の間に枝をはれば良い）．\nちなみに斜めでクイーンが取り合うかどうかを判定するのは，\\(i-j\\) が同じ（右下の斜め）か \\(i+j\\) が同じか（左下の斜め）で判定すれば良い．\n\n# export\nfrom networkx.algorithms import approximation\n\nG = nx.Graph()\nn = 8  # クイーン数\nfor i in range(n):\n    for j in range(n):\n        G.add_node((i, j))\nfor n1 in G.nodes():\n    for n2 in G.nodes():\n        if n1 == n2:\n            continue\n        if n1[0] == n2[0]:\n            G.add_edge(n1, n2)\n        if n1[1] == n2[1]:\n            G.add_edge(n1, n2)\n        if n1[0] - n1[1] == n2[0] - n2[1]:\n            G.add_edge(n1, n2)\n        if n1[0] + n1[1] == n2[0] + n2[1]:\n            G.add_edge(n1, n2)\nS = approximation.max_clique(nx.complement(G))\nprint(S)\n\n{(2, 4), (1, 2), (0, 0), (3, 1), (7, 6), (6, 3), (4, 7)}"
  }
]