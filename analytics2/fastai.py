# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/16fastai.ipynb.

# %% auto 0
__all__ = []

# %% ../nbs/16fastai.ipynb 87
# spam = pd.read_csv("http://logopt.com/data/spam.csv")
# procs = [Categorify, FillMissing, Normalize] #前処理の種類を準備．
# train_idx, valid_idx = train_test_split(range(len(spam)), test_size=0.3) #検証用データのインデックスを準備．
# dep_var = "is_spam" #従属変数名を準備．
# cont_names, cat_names = cont_cat_split(spam, max_card = 50, dep_var=dep_var)
# dls = TabularDataLoaders.from_df(spam, y_names=dep_var, procs = procs, cont_names=cont_names, cat_names=cat_names)
# learn = tabular_learner(dls, metrics=accuracy)
# learn.fit_one_cycle(30,1e-3)

# %% ../nbs/16fastai.ipynb 90
# mashroom = pd.read_csv("http://logopt.com/data/mashroom.csv", dtype = {"shape":"category", "surface":"category", "color":"category"})
# procs = [Categorify, FillMissing, Normalize] #前処理の種類を準備．
# train_idx, valid_idx = train_test_split(range(len(mashroom)), test_size=0.3) #検証用データのインデックスを準備．
# dep_var = "target" #従属変数名を準備．
# cont_names, cat_names = cont_cat_split(mashroom, max_card = 50, dep_var=dep_var)
# #print(cat_names, cont_names)
# dls = TabularDataLoaders.from_df(mashroom, y_names=dep_var, procs = procs, cont_names=cont_names, cat_names=cat_names)
# learn = tabular_learner(dls, metrics=accuracy)
# learn.fit_one_cycle(30,1e-3)

# %% ../nbs/16fastai.ipynb 93
# titanic = pd.read_csv("http://logopt.com/data/titanic.csv")
# train_idx, valid_idx = train_test_split(range(len(titanic)), test_size=0.2) #検証用データのインデックスを準備．
# dep_var = "Survived" #従属変数名
# cat_names = ["Pclass","Sex","SibSp","Parch","Cabin","Embarked"] #カテゴリー変数が格納されている列リスト．
# cont_names = ["Age","Fare"] #連続変数名
# procs = [FillMissing, Categorify, Normalize] #前処理の種類を準備．
# dls = TabularDataLoaders.from_df(titanic, y_names=dep_var, procs = procs, cont_names=cont_names, cat_names=cat_names)
# learn = tabular_learner(dls, metrics=accuracy)
# learn.fit_one_cycle(30,1e-3)

# %% ../nbs/16fastai.ipynb 96
# cancer = pd.read_csv("http://logopt.com/data/cancer.csv", index_col=0)
# train_idx, valid_idx = train_test_split(range(len(cancer)), test_size=0.2) #検証用データのインデックスを準備．
# dep_var = "diagnosis" #従属変数名
# procs = [FillMissing, Normalize] #前処理の種類を準備．
# dls = TabularDataLoaders.from_df(cancer, y_names=dep_var, procs = procs)
# learn = tabular_learner(dls, metrics=accuracy)
# learn.fit_one_cycle(30,1e-3)

# %% ../nbs/16fastai.ipynb 99
# occupancy = pd.read_csv("http://logopt.com/data/occupancy.csv")
# occupancy.drop("datetime", axis=1, inplace=True)
# procs = [Categorify, FillMissing, Normalize] #前処理の種類を準備．
# train_idx, valid_idx = train_test_split(range(len(occupancy)), test_size=0.3) #検証用データのインデックスを準備．
# dep_var = "occupancy" #従属変数名を準備．
# cont_names, cat_names = cont_cat_split(occupancy, max_card = 50, dep_var=dep_var)
# print(cat_names, cont_names)
# dls = TabularDataLoaders.from_df(occupancy, y_names=dep_var, procs = procs, cont_names=cont_names, cat_names=cat_names)
# learn = tabular_learner(dls, metrics=accuracy)
# learn.fit_one_cycle(30,1e-3)
