[
  {
    "objectID": "05transformers.html",
    "href": "05transformers.html",
    "title": "Hugging Faceのパイプライン",
    "section": "",
    "text": "文章の分類：レビューの評価、スパムメールの検出、文法的に正しいかどうかの判断、2つの文が論理的に関連しているかどうかの判断\n文の中の単語分類：品詞（名詞、動詞、形容詞）や、固有表現（人、場所、組織）の識別\n文章内容の生成：自動生成されたテキストによる入力テキストの補完、文章の穴埋め\n文章からの情報抽出：質問と文脈が与えられたときの、文脈からの情報に基づいた質問に対する答えの抽出\n文章の変換：ある文章の他の言語への翻訳、文章の要約\n\nHugging Face https://huggingface.co/ のパイプラインを使って色々なNLPの処理ができる。\n\nsentiment-analysis (感情分析)\nzero-shot-classification (ゼロショット分類)\ntext-generation (文章生成)\nfill-mask (空所穴埋め)\nner (named entity recognition) (固有表現認識)\nquestion-answering (質問応答)\nsummarization (要約)\ntranslation (翻訳)\n\n基本的な使い方は簡単であり、pipelineのtask引数にやりたいことを表す上の文字列を入れて、生成されたインスタンスに文字列を入れるだけである。\n\nfrom transformers import pipeline\n\n\n\n与えられた文章が POSITIVEかNEGATIVEかを返す。\n\nclassifier = pipeline(\"sentiment-analysis\")\nclassifier(\"We are very happy to show you the 🤗 Transformers library.\")\n\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nXformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n\n\n[{'label': 'POSITIVE', 'score': 0.9997795224189758}]\n\n\n\n\n\n例を示すことなく、与えられた文章を分類する。分類したいラベルのリストを、引数 candidate_labelsで与える。\n\nclassifier2 = pipeline(\"zero-shot-classification\")\nclassifier2(\n    \"This is a course about the Transformers library\",\n    candidate_labels=[\"education\", \"politics\", \"business\"],\n)\n\nNo model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{'sequence': 'This is a course about the Transformers library',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.8445950150489807, 0.11197729408740997, 0.0434277318418026]}\n\n\n\n\n\n与えた文章の続きを書く。\n\ngenerator = pipeline(\"text-generation\")\ngenerator(\"In this course, we will teach you how to\")\n\nNo model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'In this course, we will teach you how to run a database with Nginx and PHP. We first take a look at how to run PHP and Nginx together. Then we will use an example MySQL database to create a database. In the same'}]\n\n\npipelineのモデル引数modelで、使用するモデルを指定することもできる。 モデルは、https://huggingface.co/models から適当なものを選択する必要がある。\nまた、最大トークン数をmax_length、生成する文章の数をnum_return_sequencesで与えることもできる。\n\ngenerator = pipeline(\"text-generation\", model=\"distilgpt2\")\ngenerator(\n    \"In this course, we will teach you how to\",\n    max_length=30,\n    num_return_sequences=2,\n)\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'In this course, we will teach you how to make mistakes as well as avoid them all because they cost you money, and why it makes good money'},\n {'generated_text': 'In this course, we will teach you how to understand the best, most effective and most effective ways to perform the work of the American people. These'}]\n\n\n\n\n\n与えた文章内の&lt;mask&gt;の部分に単語で埋めて文章にする。引数top_kで埋める単語数を与えることができる。\n\nunmasker = pipeline(\"fill-mask\")\n\nNo model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\nunmasker(\"This course will teach you all about &lt;mask&gt; models.\", top_k=2)\n\n[{'score': 0.1961977630853653,\n  'token': 30412,\n  'token_str': ' mathematical',\n  'sequence': 'This course will teach you all about mathematical models.'},\n {'score': 0.04052729532122612,\n  'token': 38163,\n  'token_str': ' computational',\n  'sequence': 'This course will teach you all about computational models.'}]\n\n\n\n\n\n固有表現認識 ner (named entity recognition) とは、文章内の 人(PER: persons)、場所（LOC: locations)、組織(ORG: organizations)などを抽出するタスクである。\n引数grouped_entitiesをTrueに設定すると固有名詞を結合して出力する。\n\nner = pipeline(\"ner\", grouped_entities=True)\nner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n\nNo model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'entity_group': 'PER',\n  'score': 0.9981694,\n  'word': 'Sylvain',\n  'start': 11,\n  'end': 18},\n {'entity_group': 'ORG',\n  'score': 0.9796021,\n  'word': 'Hugging Face',\n  'start': 33,\n  'end': 45},\n {'entity_group': 'LOC',\n  'score': 0.9932106,\n  'word': 'Brooklyn',\n  'start': 49,\n  'end': 57}]\n\n\n\n\n\n質問をquestion、文章をcontextで与えることによって、質問の答えと、その単語の開始位置と終了位置を返す。\n\nquestion_answerer = pipeline(\"question-answering\")\nquestion_answerer(\n    question=\"Where do I work?\",\n    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n)\n\nNo model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{'score': 0.6949763894081116, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}\n\n\n\n\n\n文章の要約を返す。\n\nsummarizer = pipeline(\"summarization\")\nsummarizer(\n    \"\"\"\n    America has changed dramatically during recent years. Not only has the number of\n    graduates in traditional engineering disciplines such as mechanical, civil,\n    electrical, chemical, and aeronautical engineering declined, but in most of\n    the premier American universities engineering curricula now concentrate on\n    and encourage largely the study of engineering science. As a result, there\n    are declining offerings in engineering subjects dealing with infrastructure,\n    the environment, and related issues, and greater concentration on high\n    technology subjects, largely supporting increasingly complex scientific\n    developments. While the latter is important, it should not be at the expense\n    of more traditional engineering.\n\n    Rapidly developing economies such as China and India, as well as other\n    industrial countries in Europe and Asia, continue to encourage and advance\n    the teaching of engineering. Both China and India, respectively, graduate\n    six and eight times as many traditional engineers as does the United States.\n    Other industrial countries at minimum maintain their output, while America\n    suffers an increasingly serious decline in the number of engineering graduates\n    and a lack of well-educated engineers.\n\"\"\"\n)\n\nNo model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]\n\n\n\n\n\n翻訳した文章を返す。 pipelineのモデル引数modelに翻訳をするためのモデルを入れる。 以下の例では、英語からフランス語への翻訳モデルを指定している。 （ドイツ語への翻訳の場合には、translation_en_to_de をtask引数とする。）\n\ntranslator = pipeline(\"translation_en_to_fr\")\ntranslator(\"This course is produced by Hugging Face.\")\n\nNo model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'translation_text': 'Ce cours est produit par Hugging Face.'}]\n\n\nGoogle Colab.上でモデルを指定して翻訳を行う場合には、以下を実行してsentencepieceをインストールしてから、 カーネルをリスタートする必要がある。\n !pip install sentencepiece\n以下のコードはHelsinki-NLのモデルを用いて、様々な言語間の翻訳を行う。 例として、英語から日本語への翻訳を示す。\n\ndef create_translation_pipeline(source_lang, target_lang):\n    model_name = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'\n    translator = pipeline(\"translation\", model=model_name)\n    return translator\n\ndef translate_text(translator, text):\n    result = translator(text, max_length=500)\n    return result[0]['translation_text']\n\n# Example usage:\nsource_lang_code = \"en\"  # English\ntarget_lang_code = \"jap\"  # Japanese\n\ntranslator = create_translation_pipeline(source_lang_code, target_lang_code)\n\nenglish_text = \"This is a pen.\"\ntranslated_text = translate_text(translator, english_text)\n\nprint(f\"{source_lang_code.capitalize()}: {english_text}\")\nprint(f\"{target_lang_code.capitalize()}: {translated_text}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn: This is a pen.\nJap: これ は 筆 で あ る .\n\n\n\n\n\npipelineの中身は、以下の処理に分解される。\n文字列 =&gt; トークナイザー =&gt; モデル　=&gt; 後処理\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom pprint import pprint\nfrom transformers import AutoModelForSequenceClassification\nimport torch\n\n\n\nまず、入力された文字列をトークン（単語や記号など）に分割し、各トークンを整数に置き換える必要がある。 これには、AutoTokenizer クラスのfrom_pretrainedメソッドを使用する。 引数には、https://huggingface.co/models にあるモデル名 checkpointを与える。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\npprint(tokenizer)\n\nDistilBertTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n\n\n生成したトークナーザーtokenizerに文字列（のリスト）を与えると、変換された数値情報を含んだ辞書が生成される。 辞書のキーは、どのトークンに注意するかを表すattention_maskと入力を数値に変換した多次元配列を表す input_ids である。\nこの際、どの深層学習フレームワークを使うかを表すreturn_tensorsを指定する必要がある。 ここでは、PyTorchを使うので、引数にptを指定する。\n\nraw_inputs = [\n    \"I've been waiting for a HuggingFace course my whole life.\",\n    \"I hate this so much!\",\n]\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\npprint(inputs)\n\n{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n             0,     0,     0,     0,     0,     0]])}\n\n\n\n\n\n続いてモデルクラスのインスタンスを生成する。 ここでは、AutoModelクラスのfrom_pretrainedメソッドを使用する。\nここで生成したモデルは、トランスフォーマーの基本部分だけをもち、出力は入力の特徴を抽出した多次元配列（テンソル）である。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModel.from_pretrained(checkpoint)\n\nSome weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\npprint(model)\n\nDistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (ffn): FFN(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (activation): GELUActivation()\n        )\n        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n)\n\n\nトークナイザーで生成した辞書を展開してモデルに入力すると、PyTorchのテンソルが出力されていることが確認できる。\n\noutputs = model(**inputs)\nprint(outputs.last_hidden_state.shape)\n\ntorch.Size([2, 16, 768])\n\n\n\noutputs\n\nBaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n         ...,\n         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n\n        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n         ...,\n         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n       grad_fn=&lt;NativeLayerNormBackward0&gt;), hidden_states=None, attentions=None)\n\n\n今度は、実際に感情分析を行うための層を含んだモデルを、 AutoModelForSequenceClassificationクラスを用いて生成する。\n出力のlogitsに保管されているテンソルが得られた数値である。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel2 = AutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs2 = model2(**inputs)\n\n\noutputs2\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n        [ 4.1692, -3.3464]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n\n\n得られたテンソルをソフトマック関数を用いて確率に変換する。これが予測値になる。\n\npredictions = torch.nn.functional.softmax(outputs2.logits, dim=-1)\nprint(predictions)\n\ntensor([[4.0195e-02, 9.5981e-01],\n        [9.9946e-01, 5.4418e-04]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n最初の文の予測値は [0.0402, 0.9598]、2番目の文の予測値は[0.9995, 0.0005]である。 これは最初の文は、1である確率が高く、2番目の文は0である確率が高いことを示している。\nモデルで用いられたラベルを得るには、モデルのid2label属性をみる。\n\nmodel2.config.id2label\n\n{0: 'NEGATIVE', 1: 'POSITIVE'}\n\n\nしたがって、最初の文章はPOSITIVE、2番目の文章はNEGATIVEであると判定される。",
    "crumbs": [
      "Hugging Faceのパイプライン"
    ]
  },
  {
    "objectID": "05transformers.html#自然言語処理-nlpnatural-language-processing",
    "href": "05transformers.html#自然言語処理-nlpnatural-language-processing",
    "title": "Hugging Faceのパイプライン",
    "section": "",
    "text": "文章の分類：レビューの評価、スパムメールの検出、文法的に正しいかどうかの判断、2つの文が論理的に関連しているかどうかの判断\n文の中の単語分類：品詞（名詞、動詞、形容詞）や、固有表現（人、場所、組織）の識別\n文章内容の生成：自動生成されたテキストによる入力テキストの補完、文章の穴埋め\n文章からの情報抽出：質問と文脈が与えられたときの、文脈からの情報に基づいた質問に対する答えの抽出\n文章の変換：ある文章の他の言語への翻訳、文章の要約\n\nHugging Face https://huggingface.co/ のパイプラインを使って色々なNLPの処理ができる。\n\nsentiment-analysis (感情分析)\nzero-shot-classification (ゼロショット分類)\ntext-generation (文章生成)\nfill-mask (空所穴埋め)\nner (named entity recognition) (固有表現認識)\nquestion-answering (質問応答)\nsummarization (要約)\ntranslation (翻訳)\n\n基本的な使い方は簡単であり、pipelineのtask引数にやりたいことを表す上の文字列を入れて、生成されたインスタンスに文字列を入れるだけである。\n\nfrom transformers import pipeline\n\n\n\n与えられた文章が POSITIVEかNEGATIVEかを返す。\n\nclassifier = pipeline(\"sentiment-analysis\")\nclassifier(\"We are very happy to show you the 🤗 Transformers library.\")\n\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nXformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n\n\n[{'label': 'POSITIVE', 'score': 0.9997795224189758}]\n\n\n\n\n\n例を示すことなく、与えられた文章を分類する。分類したいラベルのリストを、引数 candidate_labelsで与える。\n\nclassifier2 = pipeline(\"zero-shot-classification\")\nclassifier2(\n    \"This is a course about the Transformers library\",\n    candidate_labels=[\"education\", \"politics\", \"business\"],\n)\n\nNo model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{'sequence': 'This is a course about the Transformers library',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.8445950150489807, 0.11197729408740997, 0.0434277318418026]}\n\n\n\n\n\n与えた文章の続きを書く。\n\ngenerator = pipeline(\"text-generation\")\ngenerator(\"In this course, we will teach you how to\")\n\nNo model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'In this course, we will teach you how to run a database with Nginx and PHP. We first take a look at how to run PHP and Nginx together. Then we will use an example MySQL database to create a database. In the same'}]\n\n\npipelineのモデル引数modelで、使用するモデルを指定することもできる。 モデルは、https://huggingface.co/models から適当なものを選択する必要がある。\nまた、最大トークン数をmax_length、生成する文章の数をnum_return_sequencesで与えることもできる。\n\ngenerator = pipeline(\"text-generation\", model=\"distilgpt2\")\ngenerator(\n    \"In this course, we will teach you how to\",\n    max_length=30,\n    num_return_sequences=2,\n)\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'In this course, we will teach you how to make mistakes as well as avoid them all because they cost you money, and why it makes good money'},\n {'generated_text': 'In this course, we will teach you how to understand the best, most effective and most effective ways to perform the work of the American people. These'}]\n\n\n\n\n\n与えた文章内の&lt;mask&gt;の部分に単語で埋めて文章にする。引数top_kで埋める単語数を与えることができる。\n\nunmasker = pipeline(\"fill-mask\")\n\nNo model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\nunmasker(\"This course will teach you all about &lt;mask&gt; models.\", top_k=2)\n\n[{'score': 0.1961977630853653,\n  'token': 30412,\n  'token_str': ' mathematical',\n  'sequence': 'This course will teach you all about mathematical models.'},\n {'score': 0.04052729532122612,\n  'token': 38163,\n  'token_str': ' computational',\n  'sequence': 'This course will teach you all about computational models.'}]\n\n\n\n\n\n固有表現認識 ner (named entity recognition) とは、文章内の 人(PER: persons)、場所（LOC: locations)、組織(ORG: organizations)などを抽出するタスクである。\n引数grouped_entitiesをTrueに設定すると固有名詞を結合して出力する。\n\nner = pipeline(\"ner\", grouped_entities=True)\nner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n\nNo model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'entity_group': 'PER',\n  'score': 0.9981694,\n  'word': 'Sylvain',\n  'start': 11,\n  'end': 18},\n {'entity_group': 'ORG',\n  'score': 0.9796021,\n  'word': 'Hugging Face',\n  'start': 33,\n  'end': 45},\n {'entity_group': 'LOC',\n  'score': 0.9932106,\n  'word': 'Brooklyn',\n  'start': 49,\n  'end': 57}]\n\n\n\n\n\n質問をquestion、文章をcontextで与えることによって、質問の答えと、その単語の開始位置と終了位置を返す。\n\nquestion_answerer = pipeline(\"question-answering\")\nquestion_answerer(\n    question=\"Where do I work?\",\n    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n)\n\nNo model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n{'score': 0.6949763894081116, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}\n\n\n\n\n\n文章の要約を返す。\n\nsummarizer = pipeline(\"summarization\")\nsummarizer(\n    \"\"\"\n    America has changed dramatically during recent years. Not only has the number of\n    graduates in traditional engineering disciplines such as mechanical, civil,\n    electrical, chemical, and aeronautical engineering declined, but in most of\n    the premier American universities engineering curricula now concentrate on\n    and encourage largely the study of engineering science. As a result, there\n    are declining offerings in engineering subjects dealing with infrastructure,\n    the environment, and related issues, and greater concentration on high\n    technology subjects, largely supporting increasingly complex scientific\n    developments. While the latter is important, it should not be at the expense\n    of more traditional engineering.\n\n    Rapidly developing economies such as China and India, as well as other\n    industrial countries in Europe and Asia, continue to encourage and advance\n    the teaching of engineering. Both China and India, respectively, graduate\n    six and eight times as many traditional engineers as does the United States.\n    Other industrial countries at minimum maintain their output, while America\n    suffers an increasingly serious decline in the number of engineering graduates\n    and a lack of well-educated engineers.\n\"\"\"\n)\n\nNo model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]\n\n\n\n\n\n翻訳した文章を返す。 pipelineのモデル引数modelに翻訳をするためのモデルを入れる。 以下の例では、英語からフランス語への翻訳モデルを指定している。 （ドイツ語への翻訳の場合には、translation_en_to_de をtask引数とする。）\n\ntranslator = pipeline(\"translation_en_to_fr\")\ntranslator(\"This course is produced by Hugging Face.\")\n\nNo model was supplied, defaulted to t5-base and revision 686f1db (https://huggingface.co/t5-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'translation_text': 'Ce cours est produit par Hugging Face.'}]\n\n\nGoogle Colab.上でモデルを指定して翻訳を行う場合には、以下を実行してsentencepieceをインストールしてから、 カーネルをリスタートする必要がある。\n !pip install sentencepiece\n以下のコードはHelsinki-NLのモデルを用いて、様々な言語間の翻訳を行う。 例として、英語から日本語への翻訳を示す。\n\ndef create_translation_pipeline(source_lang, target_lang):\n    model_name = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'\n    translator = pipeline(\"translation\", model=model_name)\n    return translator\n\ndef translate_text(translator, text):\n    result = translator(text, max_length=500)\n    return result[0]['translation_text']\n\n# Example usage:\nsource_lang_code = \"en\"  # English\ntarget_lang_code = \"jap\"  # Japanese\n\ntranslator = create_translation_pipeline(source_lang_code, target_lang_code)\n\nenglish_text = \"This is a pen.\"\ntranslated_text = translate_text(translator, english_text)\n\nprint(f\"{source_lang_code.capitalize()}: {english_text}\")\nprint(f\"{target_lang_code.capitalize()}: {translated_text}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn: This is a pen.\nJap: これ は 筆 で あ る .\n\n\n\n\n\npipelineの中身は、以下の処理に分解される。\n文字列 =&gt; トークナイザー =&gt; モデル　=&gt; 後処理\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom pprint import pprint\nfrom transformers import AutoModelForSequenceClassification\nimport torch\n\n\n\nまず、入力された文字列をトークン（単語や記号など）に分割し、各トークンを整数に置き換える必要がある。 これには、AutoTokenizer クラスのfrom_pretrainedメソッドを使用する。 引数には、https://huggingface.co/models にあるモデル名 checkpointを与える。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n\npprint(tokenizer)\n\nDistilBertTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n\n\n生成したトークナーザーtokenizerに文字列（のリスト）を与えると、変換された数値情報を含んだ辞書が生成される。 辞書のキーは、どのトークンに注意するかを表すattention_maskと入力を数値に変換した多次元配列を表す input_ids である。\nこの際、どの深層学習フレームワークを使うかを表すreturn_tensorsを指定する必要がある。 ここでは、PyTorchを使うので、引数にptを指定する。\n\nraw_inputs = [\n    \"I've been waiting for a HuggingFace course my whole life.\",\n    \"I hate this so much!\",\n]\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\npprint(inputs)\n\n{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n             0,     0,     0,     0,     0,     0]])}\n\n\n\n\n\n続いてモデルクラスのインスタンスを生成する。 ここでは、AutoModelクラスのfrom_pretrainedメソッドを使用する。\nここで生成したモデルは、トランスフォーマーの基本部分だけをもち、出力は入力の特徴を抽出した多次元配列（テンソル）である。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModel.from_pretrained(checkpoint)\n\nSome weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\npprint(model)\n\nDistilBertModel(\n  (embeddings): Embeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer): Transformer(\n    (layer): ModuleList(\n      (0-5): 6 x TransformerBlock(\n        (attention): MultiHeadSelfAttention(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (ffn): FFN(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (activation): GELUActivation()\n        )\n        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n)\n\n\nトークナイザーで生成した辞書を展開してモデルに入力すると、PyTorchのテンソルが出力されていることが確認できる。\n\noutputs = model(**inputs)\nprint(outputs.last_hidden_state.shape)\n\ntorch.Size([2, 16, 768])\n\n\n\noutputs\n\nBaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n         ...,\n         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n\n        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n         ...,\n         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n       grad_fn=&lt;NativeLayerNormBackward0&gt;), hidden_states=None, attentions=None)\n\n\n今度は、実際に感情分析を行うための層を含んだモデルを、 AutoModelForSequenceClassificationクラスを用いて生成する。\n出力のlogitsに保管されているテンソルが得られた数値である。\n\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel2 = AutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs2 = model2(**inputs)\n\n\noutputs2\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n        [ 4.1692, -3.3464]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\n\n\n得られたテンソルをソフトマック関数を用いて確率に変換する。これが予測値になる。\n\npredictions = torch.nn.functional.softmax(outputs2.logits, dim=-1)\nprint(predictions)\n\ntensor([[4.0195e-02, 9.5981e-01],\n        [9.9946e-01, 5.4418e-04]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n最初の文の予測値は [0.0402, 0.9598]、2番目の文の予測値は[0.9995, 0.0005]である。 これは最初の文は、1である確率が高く、2番目の文は0である確率が高いことを示している。\nモデルで用いられたラベルを得るには、モデルのid2label属性をみる。\n\nmodel2.config.id2label\n\n{0: 'NEGATIVE', 1: 'POSITIVE'}\n\n\nしたがって、最初の文章はPOSITIVE、2番目の文章はNEGATIVEであると判定される。",
    "crumbs": [
      "Hugging Faceのパイプライン"
    ]
  },
  {
    "objectID": "05transformers.html#コンピュータビジョン",
    "href": "05transformers.html#コンピュータビジョン",
    "title": "Hugging Faceのパイプライン",
    "section": "コンピュータビジョン",
    "text": "コンピュータビジョン\n\n画像分類\n以下の画像を例として用いる。\n\n\nimage_example1 = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n\n\nvision_classifier = pipeline(task=\"image-classification\")\n\npreds = vision_classifier(images =image_example1)\npreds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\npreds\n\nNo model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n\n\n\n\n\n\n\n\n\n[{'score': 0.4335, 'label': 'lynx, catamount'},\n {'score': 0.0348,\n  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'},\n {'score': 0.0239, 'label': 'Egyptian cat'},\n {'score': 0.0229, 'label': 'tiger cat'}]\n\n\n\n\n物体検出\n以下を実行して追加パッケージをインストールする必要がある。\n!pip install timm\n\nfrom transformers import pipeline\n\ndetector = pipeline(task=\"object-detection\")\npreds = detector(image_example1)\npreds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\npreds\n\nNo model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://huggingface.co/facebook/detr-resnet-50).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nCould not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\nThe `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n\n\n\n\n\n\n\n\n[{'score': 0.9864,\n  'label': 'cat',\n  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]\n\n\n\n\n画像セグメンテーション\n\nsegmenter = pipeline(task=\"image-segmentation\")\npreds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\nprint(*preds, sep=\"\\n\")\n\nNo model was supplied, defaulted to facebook/detr-resnet-50-panoptic and revision fc15262 (https://huggingface.co/facebook/detr-resnet-50-panoptic).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nCould not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n`label_ids_to_fuse` unset. No instance will be fused.\n\n\n\n\n\n\n\n\n\n\n\n{'score': 0.9879, 'label': 'LABEL_184'}\n{'score': 0.9973, 'label': 'snow'}\n{'score': 0.9972, 'label': 'cat'}\n\n\n\n\n深さ推定\n\nestimator = pipeline(task=\"depth-estimation\", model=\"Intel/dpt-large\")\nresult = estimator(images=image_example1)\nresult\n\nSome weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nCould not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n\n\n{'predicted_depth': tensor([[[ 0.7999,  0.8382,  0.8483,  ...,  2.3091,  2.3669,  2.3291],\n          [ 0.8054,  0.8101,  0.8106,  ...,  2.3390,  2.3357,  2.3307],\n          [ 0.8580,  0.8359,  0.8457,  ...,  2.3557,  2.3509,  2.3599],\n          ...,\n          [26.3410, 26.4059, 26.3881,  ..., 17.5088, 17.4768, 17.4148],\n          [26.4727, 26.4515, 26.5042,  ..., 17.4223, 17.3911, 17.4052],\n          [26.5116, 26.5452, 26.5301,  ..., 17.4719, 17.4700, 17.4025]]]),\n 'depth': &lt;PIL.Image.Image image mode=L size=960x686&gt;}",
    "crumbs": [
      "Hugging Faceのパイプライン"
    ]
  },
  {
    "objectID": "05transformers.html#音声",
    "href": "05transformers.html#音声",
    "title": "Hugging Faceのパイプライン",
    "section": "音声",
    "text": "音声\n以下の演説の音声ファイルを用いる。\n\n\n\naudio_example1 = \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n\n\n音声分類\nモデルにsuperb/hubert-base-superb-erを使うと音声の感情を分類し、 MIT/ast-finetuned-audioset-10-10-0.4593を使うと音声の種類を分類する。\n\n# #classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")\nclassifier = pipeline(task=\"audio-classification\", model=\"MIT/ast-finetuned-audioset-10-10-0.4593\")\npreds = classifier(audio_example1)\npreds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\npreds\n\n/usr/local/lib/python3.10/dist-packages/transformers/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py:96: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n  waveform = torch.from_numpy(waveform).unsqueeze(0)\n\n\n[{'score': 0.4208, 'label': 'Speech'},\n {'score': 0.1793, 'label': 'Rain on surface'},\n {'score': 0.1301, 'label': 'Rain'},\n {'score': 0.096, 'label': 'Raindrop'},\n {'score': 0.0578, 'label': 'Music'}]\n\n\n\n\n音声認識\n\ntranscriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")\ntranscriber(audio_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\n\n\n\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}",
    "crumbs": [
      "Hugging Faceのパイプライン"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "データサイエンス練習問題集 II",
    "section": "",
    "text": "このページは、データサイエンス練習問題集 https://scmopt.github.io/analytics の続編であり、主に深層学習と最適化についての最新の話題を紹介する。",
    "crumbs": [
      "データサイエンス練習問題集 II"
    ]
  },
  {
    "objectID": "30chatgpt.html",
    "href": "30chatgpt.html",
    "title": "ChatGPTを用いたプロンプト・エンジニアリング",
    "section": "",
    "text": "openai, python-dotenv (python 3.8.1以上）をインストール\n「command」+「shift」+「.」 で、隠しファイルを表示\nhttps://platform.openai.com/account/api-keys でキーを得る． 3ヶ月で180$を無料で使用できる． .env にOPENAI_API_KEY = &lt;キー&gt; を追加\n.gitignore に .env を追加\n\nimport openai\nimport os\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\n\n\n# text = f\"\"\"\n# You should express what you want a model to do by \\ \n# providing instructions that are as clear and \\ \n# specific as you can possibly make them. \\ \n# This will guide the model towards the desired output, \\ \n# and reduce the chances of receiving irrelevant \\ \n# or incorrect responses. Don't confuse writing a \\ \n# clear prompt with writing a short prompt. \\ \n# In many cases, longer prompts provide more clarity \\ \n# and context for the model, which can lead to \\ \n# more detailed and relevant outputs.\n# \"\"\"\n# prompt = f\"\"\"\n# Summarize the text delimited by triple backticks \\ \n# into a single sentence.\n# ```{text}```\n# \"\"\"\n# response = get_completion(prompt)\n# print(response)",
    "crumbs": [
      "ChatGPTを用いたプロンプト・エンジニアリング"
    ]
  },
  {
    "objectID": "30chatgpt.html#準備",
    "href": "30chatgpt.html#準備",
    "title": "ChatGPTを用いたプロンプト・エンジニアリング",
    "section": "",
    "text": "openai, python-dotenv (python 3.8.1以上）をインストール\n「command」+「shift」+「.」 で、隠しファイルを表示\nhttps://platform.openai.com/account/api-keys でキーを得る． 3ヶ月で180$を無料で使用できる． .env にOPENAI_API_KEY = &lt;キー&gt; を追加\n.gitignore に .env を追加\n\nimport openai\nimport os\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv())\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response.choices[0].message[\"content\"]\n\n\n# text = f\"\"\"\n# You should express what you want a model to do by \\ \n# providing instructions that are as clear and \\ \n# specific as you can possibly make them. \\ \n# This will guide the model towards the desired output, \\ \n# and reduce the chances of receiving irrelevant \\ \n# or incorrect responses. Don't confuse writing a \\ \n# clear prompt with writing a short prompt. \\ \n# In many cases, longer prompts provide more clarity \\ \n# and context for the model, which can lead to \\ \n# more detailed and relevant outputs.\n# \"\"\"\n# prompt = f\"\"\"\n# Summarize the text delimited by triple backticks \\ \n# into a single sentence.\n# ```{text}```\n# \"\"\"\n# response = get_completion(prompt)\n# print(response)",
    "crumbs": [
      "ChatGPTを用いたプロンプト・エンジニアリング"
    ]
  },
  {
    "objectID": "32torchrl.html",
    "href": "32torchrl.html",
    "title": "TorchRLとRL4COによる強化学習",
    "section": "",
    "text": "import torch\nfrom tensordict.nn import TensorDictModule\n\nimport gymnasium as gym\nfrom torchrl.envs.libs.gym import GymEnv, GymWrapper\n\n\n\nPendulum-v1\n\n観測 observation: \\(x,y,\\theta\\)\n行動 action: トルク（回転力）\n\n環境 env を生成し，環境をリセットする． 以下の観測値を含むフィールドをもつ初期状態を表すテンソル辞書が得られる．\n\ndone:\nobservation: 観測値\nterminated:\ntruncated:\n\n\ngym_env = gym.make(\"Pendulum-v1\")\nenv = GymWrapper(gym_env, device=\"cpu\")\n\nreset = env.reset()\nprint(reset)\n\nTensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\nリセットに次いでランダムな行動を rand_action で得る．\nこれもテンソル辞書で，行動 action のフィールドが追加されている．\n\nreset_with_action = env.rand_action(reset)\nprint(reset_with_action)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\nprint(reset_with_action[\"observation\"], reset_with_action[\"action\"])\n\ntensor([ 0.5448, -0.8386,  0.8938]) tensor([0.0090])\n\n\n\n\n\n行動をstepに入れて次のステップに進む． 返値のテンソル辞書には， nextのフィールドが追加されている． nextには次に移る状態を表すテンソル辞書が格納されている．\n\nstepped_data = env.step(reset_with_action)\nprint(stepped_data)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\nprint(stepped_data[\"action\"], stepped_data[\"next\"])\n\ntensor([0.4661]) TensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\n行動をステップに入れたものをstep_mdp関数に入れると次の状態に移る． nextが複数ある場合には，マルコフ決定過程 (MDP: Markov Decision Process)にしたがい，次の状態が選択される．\n\nfrom torchrl.envs import step_mdp\n\ndata = step_mdp(stepped_data)\nprint(data)\n\nTensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\nrolloutを用いると，上の一連の操作を連続で行うことができる． max_stepsの反復の情報を保管したテンソル辞書が返される．\n\nrollout = env.rollout(max_steps=10)\nprint(rollout, \"\\n\", rollout[\"observation\"])\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([10]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=cpu,\n    is_shared=False) \n tensor([[-0.3323,  0.9432, -0.3913],\n        [-0.3438,  0.9390,  0.2434],\n        [-0.3796,  0.9251,  0.7687],\n        [-0.4574,  0.8893,  1.7127],\n        [-0.5562,  0.8310,  2.2960],\n        [-0.6708,  0.7417,  2.9086],\n        [-0.7798,  0.6261,  3.1803],\n        [-0.8825,  0.4704,  3.7365],\n        [-0.9629,  0.2699,  4.3276],\n        [-0.9993,  0.0383,  4.7006]])\n\n\n\n\n\n簡単な1層の線形層をテンソル辞書を用いて生成し， ロールアウトを行う．\n\nfrom tensordict.nn import TensorDictModule\n\nmodule = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\npolicy = TensorDictModule(\n    module,\n    in_keys=[\"observation\"],\n    out_keys=[\"action\"],\n)\n\n\nrollout = env.rollout(max_steps=10, policy=policy)\nprint(rollout)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([10]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=cpu,\n    is_shared=False)",
    "crumbs": [
      "TorchRLとRL4COによる強化学習"
    ]
  },
  {
    "objectID": "32torchrl.html#torchrlによる強化学習の基礎",
    "href": "32torchrl.html#torchrlによる強化学習の基礎",
    "title": "TorchRLとRL4COによる強化学習",
    "section": "",
    "text": "import torch\nfrom tensordict.nn import TensorDictModule\n\nimport gymnasium as gym\nfrom torchrl.envs.libs.gym import GymEnv, GymWrapper\n\n\n\nPendulum-v1\n\n観測 observation: \\(x,y,\\theta\\)\n行動 action: トルク（回転力）\n\n環境 env を生成し，環境をリセットする． 以下の観測値を含むフィールドをもつ初期状態を表すテンソル辞書が得られる．\n\ndone:\nobservation: 観測値\nterminated:\ntruncated:\n\n\ngym_env = gym.make(\"Pendulum-v1\")\nenv = GymWrapper(gym_env, device=\"cpu\")\n\nreset = env.reset()\nprint(reset)\n\nTensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\nリセットに次いでランダムな行動を rand_action で得る．\nこれもテンソル辞書で，行動 action のフィールドが追加されている．\n\nreset_with_action = env.rand_action(reset)\nprint(reset_with_action)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\nprint(reset_with_action[\"observation\"], reset_with_action[\"action\"])\n\ntensor([ 0.5448, -0.8386,  0.8938]) tensor([0.0090])\n\n\n\n\n\n行動をstepに入れて次のステップに進む． 返値のテンソル辞書には， nextのフィールドが追加されている． nextには次に移る状態を表すテンソル辞書が格納されている．\n\nstepped_data = env.step(reset_with_action)\nprint(stepped_data)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\nprint(stepped_data[\"action\"], stepped_data[\"next\"])\n\ntensor([0.4661]) TensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\n行動をステップに入れたものをstep_mdp関数に入れると次の状態に移る． nextが複数ある場合には，マルコフ決定過程 (MDP: Markov Decision Process)にしたがい，次の状態が選択される．\n\nfrom torchrl.envs import step_mdp\n\ndata = step_mdp(stepped_data)\nprint(data)\n\nTensorDict(\n    fields={\n        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        observation: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([]),\n    device=cpu,\n    is_shared=False)\n\n\n\n\n\nrolloutを用いると，上の一連の操作を連続で行うことができる． max_stepsの反復の情報を保管したテンソル辞書が返される．\n\nrollout = env.rollout(max_steps=10)\nprint(rollout, \"\\n\", rollout[\"observation\"])\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([10]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=cpu,\n    is_shared=False) \n tensor([[-0.3323,  0.9432, -0.3913],\n        [-0.3438,  0.9390,  0.2434],\n        [-0.3796,  0.9251,  0.7687],\n        [-0.4574,  0.8893,  1.7127],\n        [-0.5562,  0.8310,  2.2960],\n        [-0.6708,  0.7417,  2.9086],\n        [-0.7798,  0.6261,  3.1803],\n        [-0.8825,  0.4704,  3.7365],\n        [-0.9629,  0.2699,  4.3276],\n        [-0.9993,  0.0383,  4.7006]])\n\n\n\n\n\n簡単な1層の線形層をテンソル辞書を用いて生成し， ロールアウトを行う．\n\nfrom tensordict.nn import TensorDictModule\n\nmodule = torch.nn.LazyLinear(out_features=env.action_spec.shape[-1])\npolicy = TensorDictModule(\n    module,\n    in_keys=[\"observation\"],\n    out_keys=[\"action\"],\n)\n\n\nrollout = env.rollout(max_steps=10, policy=policy)\nprint(rollout)\n\nTensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([10]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=cpu,\n    is_shared=False)",
    "crumbs": [
      "TorchRLとRL4COによる強化学習"
    ]
  },
  {
    "objectID": "32torchrl.html#rl4coによる強化学習で組合せ最適化問題の求解",
    "href": "32torchrl.html#rl4coによる強化学習で組合せ最適化問題の求解",
    "title": "TorchRLとRL4COによる強化学習",
    "section": "RL4COによる強化学習で組合せ最適化問題の求解",
    "text": "RL4COによる強化学習で組合せ最適化問題の求解\n巡回セールスマン問題の環境 TSPEnvを準備する．　点数は \\(50\\) の問題例を生成する．\n方策はトランスフォーマーを用いる．これはエンコーダーとデコーダーから構成される．\n訓練には REINFORCE を用いる．\n\nimport torch\n\nfrom rl4co.envs import TSPEnv\nfrom rl4co.models import AttentionModelPolicy, REINFORCE\nfrom rl4co.utils.trainer import RL4COTrainer\n\n\n# RL4CO env based on TorchRL\nenv = TSPEnv(generator_params={'num_loc': 50})\n\n# Policy: neural network, in this case with encoder-decoder architecture\npolicy = AttentionModelPolicy(env_name=env.name,\n                              embed_dim=128,\n                              num_encoder_layers=3,\n                              num_heads=8,\n                            )\n\n# RL Model: REINFORCE and greedy rollout baseline\nmodel = REINFORCE(env,\n                    policy,\n                    baseline=\"rollout\",\n                    batch_size=512,\n                    train_data_size=100_000,\n                    val_data_size=10_000,\n                    optimizer_kwargs={\"lr\": 1e-4},\n                    )\n\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n\n\n\n訓練していない方策でロールアウト\n\n# Greedy rollouts over untrained policy\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntd_init = env.reset(batch_size=[3]).to(device)\npolicy = policy.to(device)\nout = policy(td_init.clone(), phase=\"test\", decode_type=\"greedy\", return_actions=True)\nactions_untrained = out['actions'].cpu().detach()\nrewards_untrained = out['reward'].cpu().detach()\n\nfor i in range(3):\n    print(f\"Problem {i+1} | Cost: {-rewards_untrained[i]:.3f}\")\n    env.render(td_init[i], actions_untrained[i])\n\nProblem 1 | Cost: 28.789\nProblem 2 | Cost: 21.648\nProblem 3 | Cost: 23.582\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n訓練クラスの生成\nRL4COTrainerクラスのインスタンスを準備し， エポック数 \\(3\\) で訓練を行う．\n\ntrainer = RL4COTrainer(\n    max_epochs=3,\n    accelerator=\"gpu\",\n    devices=1,\n    logger=None,\n)\n\nUsing 16bit Automatic Mixed Precision (AMP)\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n  warnings.warn(\nGPU available: True (mps), used: True\nTPU available: False, using: 0 TPU cores\nHPU available: False, using: 0 HPUs\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n\n\n\ntrainer.fit(model)\n\nval_file not set. Generating dataset instead\ntest_file not set. Generating dataset instead\n\n  | Name     | Type                 | Params | Mode \n----------------------------------------------------------\n0 | env      | TSPEnv               | 0      | train\n1 | policy   | AttentionModelPolicy | 710 K  | train\n2 | baseline | WarmupBaseline       | 710 K  | train\n----------------------------------------------------------\n1.4 M     Trainable params\n0         Non-trainable params\n1.4 M     Total params\n5.681     Total estimated model params size (MB)\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn(\n/Users/mikiokubo/miniconda3/envs/jupyterlab/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n`Trainer.fit` stopped: `max_epochs=3` reached.\n\n\nSanity Checking DataLoader 0:   0%|                                                                               | 0/2 [00:00&lt;?, ?it/s]                                                                                                                                        Epoch 0: 100%|███████████████████████████████████████| 196/196 [12:31&lt;00:00,  0.26it/s, v_num=59, train/reward=-7.30, train/loss=-0.694]\nValidation: |                                                                                                     | 0/? [00:00&lt;?, ?it/s]\nValidation:   0%|                                                                                                | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   0%|                                                                                   | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   5%|███▊                                                                       | 1/20 [00:01&lt;00:34,  0.54it/s]\nValidation DataLoader 0:  10%|███████▌                                                                   | 2/20 [00:04&lt;00:36,  0.49it/s]\nValidation DataLoader 0:  15%|███████████▎                                                               | 3/20 [00:06&lt;00:36,  0.47it/s]\nValidation DataLoader 0:  20%|███████████████                                                            | 4/20 [00:08&lt;00:34,  0.46it/s]\nValidation DataLoader 0:  25%|██████████████████▊                                                        | 5/20 [00:11&lt;00:33,  0.45it/s]\nValidation DataLoader 0:  30%|██████████████████████▌                                                    | 6/20 [00:13&lt;00:31,  0.44it/s]\nValidation DataLoader 0:  35%|██████████████████████████▎                                                | 7/20 [00:15&lt;00:29,  0.44it/s]\nValidation DataLoader 0:  40%|██████████████████████████████                                             | 8/20 [00:18&lt;00:27,  0.44it/s]\nValidation DataLoader 0:  45%|█████████████████████████████████▊                                         | 9/20 [00:20&lt;00:25,  0.44it/s]\nValidation DataLoader 0:  50%|█████████████████████████████████████                                     | 10/20 [00:22&lt;00:22,  0.44it/s]\nValidation DataLoader 0:  55%|████████████████████████████████████████▋                                 | 11/20 [00:25&lt;00:20,  0.44it/s]\nValidation DataLoader 0:  60%|████████████████████████████████████████████▍                             | 12/20 [00:27&lt;00:18,  0.43it/s]\nValidation DataLoader 0:  65%|████████████████████████████████████████████████                          | 13/20 [00:30&lt;00:16,  0.43it/s]\nValidation DataLoader 0:  70%|███████████████████████████████████████████████████▊                      | 14/20 [00:32&lt;00:13,  0.43it/s]\nValidation DataLoader 0:  75%|███████████████████████████████████████████████████████▌                  | 15/20 [00:34&lt;00:11,  0.43it/s]\nValidation DataLoader 0:  80%|███████████████████████████████████████████████████████████▏              | 16/20 [00:37&lt;00:09,  0.43it/s]\nValidation DataLoader 0:  85%|██████████████████████████████████████████████████████████████▉           | 17/20 [00:39&lt;00:06,  0.43it/s]\nValidation DataLoader 0:  90%|██████████████████████████████████████████████████████████████████▌       | 18/20 [00:41&lt;00:04,  0.43it/s]\nValidation DataLoader 0:  95%|██████████████████████████████████████████████████████████████████████▎   | 19/20 [00:44&lt;00:02,  0.43it/s]\nValidation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████| 20/20 [00:46&lt;00:00,  0.43it/s]\nEpoch 1: 100%|██████████████████████| 196/196 [12:19&lt;00:00,  0.27it/s, v_num=59, train/reward=-6.72, train/loss=-1.64, val/reward=-6.63]\nValidation: |                                                                                                     | 0/? [00:00&lt;?, ?it/s]\nValidation:   0%|                                                                                                | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   0%|                                                                                   | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   5%|███▊                                                                       | 1/20 [00:01&lt;00:35,  0.54it/s]\nValidation DataLoader 0:  10%|███████▌                                                                   | 2/20 [00:04&lt;00:37,  0.48it/s]\nValidation DataLoader 0:  15%|███████████▎                                                               | 3/20 [00:07&lt;00:44,  0.38it/s]\nValidation DataLoader 0:  20%|███████████████                                                            | 4/20 [00:10&lt;00:40,  0.39it/s]\nValidation DataLoader 0:  25%|██████████████████▊                                                        | 5/20 [00:12&lt;00:37,  0.40it/s]\nValidation DataLoader 0:  30%|██████████████████████▌                                                    | 6/20 [00:14&lt;00:34,  0.40it/s]\nValidation DataLoader 0:  35%|██████████████████████████▎                                                | 7/20 [00:17&lt;00:31,  0.41it/s]\nValidation DataLoader 0:  40%|██████████████████████████████                                             | 8/20 [00:19&lt;00:29,  0.41it/s]\nValidation DataLoader 0:  45%|█████████████████████████████████▊                                         | 9/20 [00:21&lt;00:26,  0.42it/s]\nValidation DataLoader 0:  50%|█████████████████████████████████████                                     | 10/20 [00:23&lt;00:23,  0.42it/s]\nValidation DataLoader 0:  55%|████████████████████████████████████████▋                                 | 11/20 [00:26&lt;00:21,  0.42it/s]\nValidation DataLoader 0:  60%|████████████████████████████████████████████▍                             | 12/20 [00:28&lt;00:19,  0.42it/s]\nValidation DataLoader 0:  65%|████████████████████████████████████████████████                          | 13/20 [00:30&lt;00:16,  0.42it/s]\nValidation DataLoader 0:  70%|███████████████████████████████████████████████████▊                      | 14/20 [00:33&lt;00:14,  0.42it/s]\nValidation DataLoader 0:  75%|███████████████████████████████████████████████████████▌                  | 15/20 [00:35&lt;00:11,  0.42it/s]\nValidation DataLoader 0:  80%|███████████████████████████████████████████████████████████▏              | 16/20 [00:37&lt;00:09,  0.42it/s]\nValidation DataLoader 0:  85%|██████████████████████████████████████████████████████████████▉           | 17/20 [00:40&lt;00:07,  0.42it/s]\nValidation DataLoader 0:  90%|██████████████████████████████████████████████████████████████████▌       | 18/20 [00:42&lt;00:04,  0.42it/s]\nValidation DataLoader 0:  95%|██████████████████████████████████████████████████████████████████████▎   | 19/20 [00:44&lt;00:02,  0.43it/s]\nValidation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████| 20/20 [00:46&lt;00:00,  0.43it/s]\nEpoch 2: 100%|██████████████████████| 196/196 [12:15&lt;00:00,  0.27it/s, v_num=59, train/reward=-6.60, train/loss=-3.36, val/reward=-6.46]\nValidation: |                                                                                                     | 0/? [00:00&lt;?, ?it/s]\nValidation:   0%|                                                                                                | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   0%|                                                                                   | 0/20 [00:00&lt;?, ?it/s]\nValidation DataLoader 0:   5%|███▊                                                                       | 1/20 [00:01&lt;00:34,  0.54it/s]\nValidation DataLoader 0:  10%|███████▌                                                                   | 2/20 [00:04&lt;00:37,  0.48it/s]\nValidation DataLoader 0:  15%|███████████▎                                                               | 3/20 [00:06&lt;00:37,  0.46it/s]\nValidation DataLoader 0:  20%|███████████████                                                            | 4/20 [00:08&lt;00:35,  0.45it/s]\nValidation DataLoader 0:  25%|██████████████████▊                                                        | 5/20 [00:11&lt;00:33,  0.45it/s]\nValidation DataLoader 0:  30%|██████████████████████▌                                                    | 6/20 [00:13&lt;00:31,  0.44it/s]\nValidation DataLoader 0:  35%|██████████████████████████▎                                                | 7/20 [00:15&lt;00:29,  0.44it/s]\nValidation DataLoader 0:  40%|██████████████████████████████                                             | 8/20 [00:18&lt;00:27,  0.44it/s]\nValidation DataLoader 0:  45%|█████████████████████████████████▊                                         | 9/20 [00:20&lt;00:25,  0.44it/s]\nValidation DataLoader 0:  50%|█████████████████████████████████████                                     | 10/20 [00:22&lt;00:22,  0.44it/s]\nValidation DataLoader 0:  55%|████████████████████████████████████████▋                                 | 11/20 [00:25&lt;00:20,  0.43it/s]\nValidation DataLoader 0:  60%|████████████████████████████████████████████▍                             | 12/20 [00:27&lt;00:18,  0.43it/s]\nValidation DataLoader 0:  65%|████████████████████████████████████████████████                          | 13/20 [00:29&lt;00:16,  0.43it/s]\nValidation DataLoader 0:  70%|███████████████████████████████████████████████████▊                      | 14/20 [00:32&lt;00:13,  0.43it/s]\nValidation DataLoader 0:  75%|███████████████████████████████████████████████████████▌                  | 15/20 [00:34&lt;00:11,  0.43it/s]\nValidation DataLoader 0:  80%|███████████████████████████████████████████████████████████▏              | 16/20 [00:36&lt;00:09,  0.43it/s]\nValidation DataLoader 0:  85%|██████████████████████████████████████████████████████████████▉           | 17/20 [00:39&lt;00:06,  0.43it/s]\nValidation DataLoader 0:  90%|██████████████████████████████████████████████████████████████████▌       | 18/20 [00:41&lt;00:04,  0.43it/s]\nValidation DataLoader 0:  95%|██████████████████████████████████████████████████████████████████████▎   | 19/20 [00:43&lt;00:02,  0.43it/s]\nValidation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████| 20/20 [00:46&lt;00:00,  0.43it/s]\nEpoch 2: 100%|██████████████████████| 196/196 [13:01&lt;00:00,  0.25it/s, v_num=59, train/reward=-6.60, train/loss=-3.36, val/reward=-6.40]Epoch 2: 100%|██████████████████████| 196/196 [14:34&lt;00:00,  0.22it/s, v_num=59, train/reward=-6.60, train/loss=-3.36, val/reward=-6.40]\n\n\n\n\n最適化\n訓練した方策で求解し，可視化する．\n\n# Greedy rollouts over trained model (same states as previous plot)\npolicy = model.policy.to(device)\nout = policy(td_init.clone(), phase=\"test\", decode_type=\"greedy\", return_actions=True)\nactions_trained = out['actions'].cpu().detach()\n\n# Plotting\nimport matplotlib.pyplot as plt\nfor i, td in enumerate(td_init):\n    fig, axs = plt.subplots(1,2, figsize=(11,5))\n    env.render(td, actions_untrained[i], ax=axs[0])\n    env.render(td, actions_trained[i], ax=axs[1])\n    axs[0].set_title(f\"Untrained | Cost = {-rewards_untrained[i].item():.3f}\")\n    axs[1].set_title(r\"Trained $\\pi_\\theta$\" + f\"| Cost = {-out['reward'][i].item():.3f}\")",
    "crumbs": [
      "TorchRLとRL4COによる強化学習"
    ]
  },
  {
    "objectID": "17neuralprophet.html",
    "href": "17neuralprophet.html",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "",
    "text": "NeuralProphet は需要予測のためのパッケージである．\nBayes推論に基づく予測パッケージ prophet と機械（深層）学習の橋渡しのために新たに開発されたもので、深層学習パッケージ PyTorch を用いている。\nvega_datasetsのデータを用いるので，インストールしておく．\n\n# Google Colabで実行する場合は以下を実行しておく。\n# !pip uninstall -y torch notebook notebook_shim tensorflow tensorflow-datasets prophet torchaudio torchdata torchtext torchvision\n# インストールされていない場合には、以下を生かす。\n# !pip install -U neuralprophet\n# !pip install -U vega_datasets\n# !pip install -U ipywidgets",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "17neuralprophet.html#neuralprophetとは",
    "href": "17neuralprophet.html#neuralprophetとは",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "",
    "text": "NeuralProphet は需要予測のためのパッケージである．\nBayes推論に基づく予測パッケージ prophet と機械（深層）学習の橋渡しのために新たに開発されたもので、深層学習パッケージ PyTorch を用いている。\nvega_datasetsのデータを用いるので，インストールしておく．\n\n# Google Colabで実行する場合は以下を実行しておく。\n# !pip uninstall -y torch notebook notebook_shim tensorflow tensorflow-datasets prophet torchaudio torchdata torchtext torchvision\n# インストールされていない場合には、以下を生かす。\n# !pip install -U neuralprophet\n# !pip install -U vega_datasets\n# !pip install -U ipywidgets",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "17neuralprophet.html#諸パッケージのインポート",
    "href": "17neuralprophet.html#諸パッケージのインポート",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "諸パッケージのインポート",
    "text": "諸パッケージのインポート\nNeuralProphetで予測するために必要なパッケージをインポートしておく．\n\nimport pandas as pd\nfrom neuralprophet import NeuralProphet, set_log_level\n\n# エラー以外はログメッセージを抑制\nset_log_level(\"ERROR\")\n\nfrom vega_datasets import data\nimport plotly.express as px\nimport plotly",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "17neuralprophet.html#neuralprophetの基本",
    "href": "17neuralprophet.html#neuralprophetの基本",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "NeuralProphetの基本",
    "text": "NeuralProphetの基本\nNeuralProphetをPythonから呼び出して使う方法は，機械学習パッケージscikit-learnと同じである。\n\nNeuralProphetクラスのインスタンスmodelを生成\nfitメソッドで学習（引数はデータフレーム、返値は評価尺度）\npredictメソッドで予測（引数は予測したい期間を含んだデータフレーム）\n\n\n例題：Wikiアクセス数\n例としてアメリカンフットボールプレーヤのPayton ManningのWikiアクセス数のデータを用いる。\n\ndf = pd.read_csv(\"http://logopt.com/data/peyton_manning.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2007-12-10\n9.590761\n\n\n1\n2007-12-11\n8.519590\n\n\n2\n2007-12-12\n8.183677\n\n\n3\n2007-12-13\n8.072467\n\n\n4\n2007-12-14\n7.893572\n\n\n\n\n\n\n\nProphetモデルのインスタンスを生成し，fitメソッドで学習（パラメータの最適化）を行う．fitメソッドに渡すのは，上で作成したデータフレームである．このとき、ds(datestamp)列に日付（時刻）を、y列に予測したい数値を入れておく必要がある （この例題では，あらかじめそのように変更されている）．\n\nmodel = NeuralProphet()\nmetrics = model.fit(df)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\nmake_future_dataframeメソッドで未来の時刻を表すデータフレームを生成する。 既定値では予測で用いた過去の時刻も含まないので、n_historic_predictions引数をTrueにして、過去の時刻も入れる。 引数は予測をしたい期間数periodsであり，ここでは、１年後（365日分）まで予測することにする。\n\ndf_future = model.make_future_dataframe(df, n_historic_predictions=True, periods=365)\nforecast = model.predict(df_future)\nmodel.set_plotting_backend(\"matplotlib\") #matplotlibで描画する（既定値はplotly）\nmodel.plot(forecast)\n\n\n\n\n\n\n\n\n\n\n\npredict メソッドに予測したい時刻を含んだデータフレームfuture を渡すと、予測値を入れたデータフレームforecastを返す。\n\nforecast.tail()\n\n\n\n\n\n\n\n\nds\ny\nyhat1\ntrend\nseason_yearly\nseason_weekly\n\n\n\n\n3265\n2017-01-15\nNaN\n8.216602\n7.137280\n1.036658\n0.042665\n\n\n3266\n2017-01-16\nNaN\n8.550267\n7.136175\n1.049828\n0.364264\n\n\n3267\n2017-01-17\nNaN\n8.316690\n7.135070\n1.060175\n0.121446\n\n\n3268\n2017-01-18\nNaN\n8.133187\n7.133965\n1.067564\n-0.068342\n\n\n3269\n2017-01-19\nNaN\n8.133450\n7.132861\n1.071885\n-0.071296\n\n\n\n\n\n\n\n\n\n一般化加法モデル\nNeuralProphetにおける予測は一般化加法モデルを用いて行われる． これは，傾向変動，季節変動，イベント情報などの様々な因子の和として予測を行う方法である．\n\\[\ny_t =g_t + s_t + h_t + f_t + a_t + \\ell_t + \\epsilon_t\n\\]\n\n\\(y_t\\) : 予測値\n\\(g_t\\) : 傾向変動(trend)；傾向変化点ありの区分的線形（アフィン）関数\n\\(s_t\\) : 季節変動；年次，週次，日次の季節変動をsin, cosの組み合わせ（フーリエ級数）で表現\n\\(h_t\\) : 休日などのイベント項\n\\(f_t\\): 外生変数に対する回帰項\n\\(a_t\\): 自己回帰項（時間遅れ（ラグ）を指定する）\n\\(\\ell_t\\): 時間遅れ（ラグ）付きの外生変数に対する回帰項\n\\(\\epsilon_t\\) : 誤差項\n\n因子ごとに予測値の描画を行うには，plot_componentsメソッドを用いる．既定では，以下のように，上から順に傾向変動，年次の季節変動、週次の季節変動が描画される．また，傾向変動の図（一番上）には，予測の誤差範囲が示される．季節変動の誤差範囲を得る方法については，後述する．\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n\n\n対話形式に，拡大縮小や範囲指定ができる動的な図も，Plotlyライブラリを用いて得ることができる．\n\nmodel.set_plotting_backend(\"plotly\") \nfig = model.plot(forecast)\n#plotly.offline.plot(fig);\n\n\n\n\n\n\n\n\n\n\n\n\n例題： \\(CO_2\\) 排出量のデータ\nデータライブラリから二酸化炭素排出量のデータを読み込み，Plotly Expressで描画する．\n\nco2 = data.co2_concentration()\nco2.head()\n\n\n\n\n\n\n\n\nDate\nCO2\n\n\n\n\n0\n1958-03-01\n315.70\n\n\n1\n1958-04-01\n317.46\n\n\n2\n1958-05-01\n317.51\n\n\n3\n1958-07-01\n315.86\n\n\n4\n1958-08-01\n314.93\n\n\n\n\n\n\n\n\nfig = px.line(co2,x=\"Date\",y=\"CO2\")\n#plotly.offline.plot(fig);\n\n\n\n\n\n\n\n\n\n\n列名の変更には，データフレームのrenameメソッドを用いる．引数はcolumnsで，元の列名をキーとし，変更後の列名を値とした辞書を与える．また，元のデータフレームに上書きするために，inplace引数をTrueに設定しておく．\n\nco2.rename(columns={\"Date\":\"ds\",\"CO2\":\"y\"},inplace=True)\nco2.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1958-03-01\n315.70\n\n\n1\n1958-04-01\n317.46\n\n\n2\n1958-05-01\n317.51\n\n\n3\n1958-07-01\n315.86\n\n\n4\n1958-08-01\n314.93\n\n\n\n\n\n\n\nmake_future_dataframeメソッドで未来の時刻を表すデータフレームを生成する。既定値では、（予測で用いた）過去の時刻も含む。 ここでは、200ヶ月先まで予測することにする。\nそのために，引数 periods を200に設定しておく\npredict メソッドに予測したい時刻を含んだデータフレームfuture を渡すと、予測値を入れたデータフレームforecastを返す。\n最後にplotメソッドで表示する．\n\nmodel = NeuralProphet()\nmetrics = model.fit(co2)\nfuture = model.make_future_dataframe(co2, n_historic_predictions=True, periods=200)\nforecast = model.predict(future)\nmodel.set_plotting_backend(\"plotly\")\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n予測は一般化加法モデルを用いて行われる．\nこれは，傾向変動，季節変動，イベント情報などの様々な因子の和として予測を行う方法である．\n上に表示されているように，週次と日次の季節変動は無視され，年次の季節変動のみ考慮して予測している．\n因子ごとに予測値の描画を行うには，plot_componentsメソッドを用いる．既定では，以下のように，上から順に傾向変動，年次の季節変動が描画される．\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n\n\n\n\n例題：航空機乗客数のデータ\nProphetの既定値では季節変動は加法的モデルであるが、問題によっては乗法的季節変動の方が良い場合もある。 例として、航空機の乗客数を予測してみよう。最初に既定値の加法的季節変動モデルで予測し，次いで乗法的モデルで予測する．\n\npassengers = pd.read_csv(\"http://logopt.com/data/AirPassengers.csv\")\npassengers.head()\n\n\n\n\n\n\n\n\nMonth\n#Passengers\n\n\n\n\n0\n1949-01\n112\n\n\n1\n1949-02\n118\n\n\n2\n1949-03\n132\n\n\n3\n1949-04\n129\n\n\n4\n1949-05\n121\n\n\n\n\n\n\n\n\nfig = px.line(passengers,x=\"Month\",y=\"#Passengers\")\n#plotly.offline.plot(fig);\n\n\n\n\n\n\n\n\n\n\n\npassengers.rename(inplace=True,columns={\"Month\":\"ds\",\"#Passengers\":\"y\"})\npassengers.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1949-01\n112\n\n\n1\n1949-02\n118\n\n\n2\n1949-03\n132\n\n\n3\n1949-04\n129\n\n\n4\n1949-05\n121\n\n\n\n\n\n\n\n季節変動を乗法的に変更するには， モデルの seasonality_mode 引数を乗法的を表す multiplicative に設定する．\nまた、モデルを作成するときに、引数quantilesで不確実性の幅を表示するようにする。以下では、5%と95%の幅を表示させている。\n\nmodel = NeuralProphet(quantiles=[0.05, 0.95])\nmetrics = model.fit(passengers)\nfuture = model.make_future_dataframe(passengers, periods=20, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.set_plotting_backend(\"plotly\")\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n\nmodel = NeuralProphet(quantiles=[0.05, 0.95], seasonality_mode=\"multiplicative\")\nmetrics = model.fit(passengers)\nfuture = model.make_future_dataframe(passengers, periods=20, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.set_plotting_backend(\"plotly\")\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n結果から，乗法的季節変動の方が，良い予測になっていることが確認できる．\n\n\n問題（小売りの需要データ）\n以下の，小売りの需要データを描画し，予測を行え． ただし，モデルは乗法的季節変動で，月次で予測せよ．\n\nretail = pd.read_csv(`http://logopt.com/data/retail_sales.csv`)\nretail.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n1992-01-01\n146376\n\n\n1\n1992-02-01\n147079\n\n\n2\n1992-03-01\n159336\n\n\n3\n1992-04-01\n163669\n\n\n4\n1992-05-01\n170068\n\n\n\n\n\n\n\n\n\n例題： 1時間ごとの気温データ\nここではシアトルの気温の予測を行う．\n\nclimate = data.seattle_temps()\nclimate.head()\n\n\n\n\n\n\n\n\ndate\ntemp\n\n\n\n\n0\n2010-01-01 00:00:00\n39.4\n\n\n1\n2010-01-01 01:00:00\n39.2\n\n\n2\n2010-01-01 02:00:00\n39.0\n\n\n3\n2010-01-01 03:00:00\n38.9\n\n\n4\n2010-01-01 04:00:00\n38.8\n\n\n\n\n\n\n\nこのデータは， date 列に日付と1時間ごとの時刻が， temp 列に気温データが入っている．\nNeuralProphetは， 日別でないデータも扱うことができる。 date列のデータ形式は、日付を表すYYYY-MM-DDの後に時刻を表すHH:MM:SSが追加されている。 未来の時刻を表すデータフレームは、make_future_dataframeメソッドで生成する。\n\nclimate[\"Date\"] = pd.to_datetime(climate.date)\n\n\nclimate.rename(columns={\"Date\":\"ds\",\"temp\":\"y\"},inplace=True)\n\n\nclimate = climate[[\"ds\",\"y\"]] #余分な列を削除する\n\n\nmodel = NeuralProphet(daily_seasonality=True)\nmetrics = model.fit(climate)\nfuture = model.make_future_dataframe(climate, periods=200, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.set_plotting_backend(\"plotly\")\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                \n\n\n因子ごとに予測値を描画すると，傾向変動と週次の季節変動の他に，日次の季節変動（1日の気温の変化）も出力される．\n\nmodel.plot_components(forecast)\n\n                                                \n\n\n\n\n問題（サンフランシスコの気温データ）\n以下のサンフランシスコの気温データを描画し，時間単位で予測を行え．\n\nsf = data.sf_temps()\nsf.head()\n\n\n\n\n\n\n\n\ntemp\ndate\n\n\n\n\n0\n47.8\n2010-01-01 00:00:00\n\n\n1\n47.4\n2010-01-01 01:00:00\n\n\n2\n46.9\n2010-01-01 02:00:00\n\n\n3\n46.5\n2010-01-01 03:00:00\n\n\n4\n46.0\n2010-01-01 04:00:00\n\n\n\n\n\n\n\n\n\n傾向変化点\n「上昇トレンドの株価が，下降トレンドに移った」というニュースをよく耳にするだろう．このように，傾向変動は，時々変化すると仮定した方が自然なのだ．NeuralProphetでは，これを傾向変化点として処理する．再び，Peyton Manningのデータを使う．\n傾向変化点の数はn_changepointsで指定する。既定値は \\(10\\) である。以下では、傾向変化点を \\(5\\) に設定する。\n\ndf = pd.read_csv(\"http://logopt.com/data/peyton_manning.csv\")\nmodel = NeuralProphet(n_changepoints=5)\nmodel.fit(df)\nfuture = model.make_future_dataframe(df, periods=365, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n  rank_zero_warn(\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_components(forecast)\n\n\n\n\n傾向変化点のリストをchangepoints引数で与えることもできる。以下の例では、1つの日だけで変化するように設定している。\n\nmodel = NeuralProphet(changepoints=[\"2014-01-01\"])\nmodel.fit(df)\nfuture = model.make_future_dataframe(df, periods=365, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n例題 SP500データ\n株価の予測を行う．\n傾向変化点の候補は自動的に設定される。既定値では時系列の最初の80%の部分に均等に設定される。これは、モデルのchangepoint_range引数で設定する． この例では，期間の終わりで変化点を設定したいので，0.95に変更する．\n年次の季節変動の変化の度合いは、yearly_seasonality（既定値は \\(10\\)) で制御できる。この例では，このパラメータを \\(5\\) に変更することによって年間の季節変動を抑制して予測を行う．\n\nsp500 = data.sp500()\nsp500.tail()\n\n\n\n\n\n\n\n\ndate\nprice\n\n\n\n\n118\n2009-11-01\n1095.63\n\n\n119\n2009-12-01\n1115.10\n\n\n120\n2010-01-01\n1073.87\n\n\n121\n2010-02-01\n1104.49\n\n\n122\n2010-03-01\n1140.45\n\n\n\n\n\n\n\n\nsp500.rename(inplace=True,columns={\"date\":\"ds\",\"price\":\"y\"})\n\n\nmodel = NeuralProphet(changepoints_range=0.95, yearly_seasonality=5)\nmodel.fit(sp500)\nfuture = model.make_future_dataframe(sp500, periods=20, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n例題： 個別銘柄の株価の予測\nstocksデータでは，symbol列に企業コードが入っている．\n\nAAPL アップル\nAMZN アマゾン\nIBM IBM\nGOOG グーグル\nMSFT マイクロソフト\n\nまずは可視化を行う。\n\nstocks = data.stocks()\nstocks.tail()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n555\nAAPL\n2009-11-01\n199.91\n\n\n556\nAAPL\n2009-12-01\n210.73\n\n\n557\nAAPL\n2010-01-01\n192.06\n\n\n558\nAAPL\n2010-02-01\n204.62\n\n\n559\nAAPL\n2010-03-01\n223.02\n\n\n\n\n\n\n\n\nfig = px.line(stocks,x=\"date\",y=\"price\",color=\"symbol\")\n#plotly.offline.plot(fig);\n\n\n\n\n\n\n\n\n\n\n以下では，マイクロソフトの株価を予測してみる．\n\nmsft = stocks[stocks.symbol == \"MSFT\"]\nmsft.head()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n0\nMSFT\n2000-01-01\n39.81\n\n\n1\nMSFT\n2000-02-01\n36.35\n\n\n2\nMSFT\n2000-03-01\n43.22\n\n\n3\nMSFT\n2000-04-01\n28.37\n\n\n4\nMSFT\n2000-05-01\n25.45\n\n\n\n\n\n\n\n\nmsft = msft.rename(columns={\"date\":\"ds\",\"price\":\"y\"})\nmsft = msft[[\"ds\",\"y\"]]\nmsft.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2000-01-01\n39.81\n\n\n1\n2000-02-01\n36.35\n\n\n2\n2000-03-01\n43.22\n\n\n3\n2000-04-01\n28.37\n\n\n4\n2000-05-01\n25.45\n\n\n\n\n\n\n\n\nmodel = NeuralProphet(changepoints_range=0.95,yearly_seasonality=5)\nmodel.fit(msft)\nfuture = model.make_future_dataframe(msft, periods=20, n_historic_predictions=True)\nforecast = model.predict(future)\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#model.plot_components(forecast)\nmodel.plot_parameters(forecast)\n\n\n\n\n\n\n問題（株価）\n上の株価データのマイクロソフト以外の銘柄を1つ選択し，予測を行え．\n\nstocks = data.stocks()\nstocks.head()\n\n\n\n\n\n\n\n\nsymbol\ndate\nprice\n\n\n\n\n0\nMSFT\n2000-01-01\n39.81\n\n\n1\nMSFT\n2000-02-01\n36.35\n\n\n2\nMSFT\n2000-03-01\n43.22\n\n\n3\nMSFT\n2000-04-01\n28.37\n\n\n4\nMSFT\n2000-05-01\n25.45",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "17neuralprophet.html#発展編",
    "href": "17neuralprophet.html#発展編",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "発展編",
    "text": "発展編\n以下では，NeuralProphetの高度な使用法を解説する．\n\n自己回帰による予測\n以下の例は、スペインの4年間のエネルギー価格である。 直近の \\(p\\) 日前までのデータの重み付きの和の項を追加するのが、自己回帰モデルである。 \\(p\\) を表すn_legs引数を設定すると、自己回帰項が追加される。\n\ndf = pd.read_csv(\"https://github.com/ourownstory/neuralprophet-data/raw/main/kaggle-energy/datasets/tutorial01.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2014-12-31\n65.41\n\n\n1\n2015-01-01\n62.09\n\n\n2\n2015-01-02\n69.44\n\n\n3\n2015-01-03\n65.22\n\n\n4\n2015-01-04\n58.91\n\n\n\n\n\n\n\n\nmodel = NeuralProphet(\n    yearly_seasonality=True,\n    weekly_seasonality=True,\n    daily_seasonality=True,\n    n_lags=10\n)\nmodel.set_plotting_backend(\"matplotlib\")\nmetrics = model.fit(df)\nforecast = model.predict(df)\nmodel.plot(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_parameters()\n\n\n\n\n\n\n\n\n\n\n休日（特別なイベント）を考慮した予測\n休日や特別なイベントをモデルに追加することを考える。\nモデルインスタンスのadd_country_holidaysメソッドを用いて，各国（州）の休日データを追加することができる。 引数は python-holidays にある文字列で、 たとえば米国の場合にはUS、スペインの場合にはESを指定する。\n\ndf = pd.read_csv(\"https://github.com/ourownstory/neuralprophet-data/raw/main/kaggle-energy/datasets/tutorial01.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\n\n\n\n\n0\n2014-12-31\n65.41\n\n\n1\n2015-01-01\n62.09\n\n\n2\n2015-01-02\n69.44\n\n\n3\n2015-01-03\n65.22\n\n\n4\n2015-01-04\n58.91\n\n\n\n\n\n\n\n\nmodel = NeuralProphet()\nmodel.set_plotting_backend(\"matplotlib\")\nmodel = model.add_country_holidays(\"US\")\nmetrics = model.fit(df)\nforecast = model.predict(df)\nmodel.plot(forecast)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_components(forecast)\n\n\n\n\n\n\n\n\n悪天候(extreme_weather)を表すデータフレームを与えることによって、特別なイベントを考慮した予測を行うことができる。 データフレームはeventとdsの列をもち、それをadd_eventsメソッドで追加する。 その後、create_df_with_eventsでイベントが追加されたデータフレームを生成する。\n\ndf_events = pd.DataFrame(\n    {\n        \"event\": \"extreme_weather\",\n        \"ds\": pd.to_datetime(\n            [\n                \"2018-11-23\",\n                \"2018-11-17\",\n                \"2018-10-28\",\n                \"2018-10-18\",\n                \"2018-10-14\",\n            ]\n        ),\n    }\n)\ndf_events.head()\n\n\n\n\n\n\n\n\nevent\nds\n\n\n\n\n0\nextreme_weather\n2018-11-23\n\n\n1\nextreme_weather\n2018-11-17\n\n\n2\nextreme_weather\n2018-10-28\n\n\n3\nextreme_weather\n2018-10-18\n\n\n4\nextreme_weather\n2018-10-14\n\n\n\n\n\n\n\n\nmodel = NeuralProphet()\nmodel.set_plotting_backend(\"matplotlib\")\nmodel.add_events(\"extreme_weather\")\ndf_all = model.create_df_with_events(df, df_events)\ndf_all.head()\n\n\n\n\n\n\n\n\nds\ny\nextreme_weather\n\n\n\n\n0\n2014-12-31\n65.41\n0.0\n\n\n1\n2015-01-01\n62.09\n0.0\n\n\n2\n2015-01-02\n69.44\n0.0\n\n\n3\n2015-01-03\n65.22\n0.0\n\n\n4\n2015-01-04\n58.91\n0.0\n\n\n\n\n\n\n\n\nmetrics = model.fit(df_all)\nforecast = model.predict(df_all)\nmodel.plot(forecast)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n外生変数の追加\n外生変数である気温temperatureを利用してエネルギー価格の予測を行う。\nここでは、\\(q\\) 日前までの気温がエネルギー価格に影響を与える時間遅れ（ラグ）モデルを用いる。 モデルインスタンスのaddd_lagged_regressorメソッドを用いる。 引数は列名もしくは列名のリストである。時間遅れのパラメータ \\(q\\) は引数n_lagsで与える。\nまた、未来の気温が既知であると仮定した場合には、気温を外生変数とした回帰項を追加する。 これには、モデルインスタンスの add_future_regressorを用いる。 引数は列名もしくは列名のリストである。\n\ndf = pd.read_csv(\"https://github.com/ourownstory/neuralprophet-data/raw/main/kaggle-energy/datasets/tutorial04.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nds\ny\ntemperature\n\n\n\n\n0\n2015-01-01\n64.92\n277.00\n\n\n1\n2015-01-02\n58.46\n277.95\n\n\n2\n2015-01-03\n63.35\n278.83\n\n\n3\n2015-01-04\n50.54\n279.64\n\n\n4\n2015-01-05\n64.89\n279.05\n\n\n\n\n\n\n\n\nmodel = NeuralProphet(\n    yearly_seasonality=True,\n    weekly_seasonality=True,\n    daily_seasonality=True,\n    n_lags=10\n)\nmodel.set_plotting_backend(\"matplotlib\")\n#model.add_lagged_regressor(\"temperature\", n_lags=5)\nmodel.add_future_regressor(\"temperature\")\nmetrics = model.fit(df)\nforecast = model.predict(df)\nmodel.plot(forecast)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.plot_parameters()\n\n\n\n\n\n\n\n\n\n\nユーザーが設定した季節変動\nProphetでは既定値の年次(yearly)や週次(weekly)や日次(daily)の季節変動だけでなく、ユーザー自身で季節変動を定義・追加できる。 以下では、週次の季節変動を除き，かわりに周期が30.5日の月次変動をフーリエ次数（seasonalityの別名）5として追加している。\n\ndf = pd.read_csv(\"http://logopt.com/data/peyton_manning.csv\")\n\nmodel = NeuralProphet(weekly_seasonality=False)\nmodel.add_seasonality(name=\"monthly\", period=30.5, fourier_order=5)\nmodel.fit(df)\nfuture = model.make_future_dataframe(df, n_historic_predictions=True, periods=365)\nforecast = model.predict(future)\nmodel.plot_components(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n他の要因に依存した季節変動\n他の要因に依存した季節変動も定義・追加することができる。以下の例では、オンシーズンとオフシーズンごと週次変動を定義し、追加してみる。\n\ndf[\"ds\"] = pd.to_datetime(df[\"ds\"])\ndf[\"on_season\"] = df[\"ds\"].apply(lambda x: x.month in [9, 10, 11, 12, 1])\ndf[\"off_season\"] = df[\"ds\"].apply(lambda x: x.month not in [9, 10, 11, 12, 1])\n\n\nmodel = NeuralProphet(weekly_seasonality=False)\nmodel.add_seasonality(name=\"weekly_on_season\", period=7, fourier_order=3, condition_name=\"on_season\")\nmodel.add_seasonality(name=\"weekly_off_season\", period=7, fourier_order=3, condition_name=\"off_season\")\nmetrics = model.fit(df, freq=\"D\")\nfuture = model.make_future_dataframe(df, n_historic_predictions=True, periods=365)\nforecast = model.predict(future)\nmodel.plot_components(forecast)\n\nWARNING - (py.warnings._showwarnmsg) - /Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning:\n\nMPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "17neuralprophet.html#主なパラメータと既定値",
    "href": "17neuralprophet.html#主なパラメータと既定値",
    "title": "NeuralProphetによる時系列データの予測",
    "section": "主なパラメータと既定値",
    "text": "主なパラメータと既定値\n以下にNeuralProphetの主要なパラメータ（引数）とその既定値を示す．\n\nchangepoints=None : 傾向変更点のリスト\nchangepoint_range = \\(0.8\\) : 傾向変化点の候補の幅（先頭から何割を候補とするか）\nn_changepoints= \\(10\\) : 傾向変更点の数\ntrend_reg = \\(0\\) : 傾向変動の正則化パラメータ\nyearly_seasonality=auto : 年次の季節変動を考慮するか否か\nweekly_seasonality=auto : 週次の季節変動を考慮するか否か\ndaily_seasonality=auto : 日次の季節変動を考慮するか否か\nseasonality_mode = additive : 季節変動が加法的(additive)か乗法的(multiplicative)か\nseasonality_reg= \\(0\\) : 季節変動の正則化パラメータ\nn_forecasts = \\(1\\) : 予測数\nn_lags = \\(0\\): 時間ずれ（ラグ）\nar_reg = \\(0\\): 自己回帰の正則化パラメータ\nquantile= \\([]\\) : 不確実性を表示するための分位数のリスト",
    "crumbs": [
      "NeuralProphetによる時系列データの予測"
    ]
  },
  {
    "objectID": "16fastai.html#深層学習とは",
    "href": "16fastai.html#深層学習とは",
    "title": "fastaiによる深層学習",
    "section": "深層学習とは",
    "text": "深層学習とは\n深層学習とは多くの隠れ層（後で説明する）をもつニューラルネットである． ニューラルネットとは（機械学習のところで簡単に触れたように），\n\n訓練データを複数の階層から構成されるモデルに入力，\n上層からの重み付き和（線形変換）に活性化関数を適用して，下層に流す，\n最下層では損出関数によって誤差を評価，\n誤差の情報から勾配を計算，\n勾配の情報を用いて，重み（パラメータ）の更新，\n\nを繰り返すだけである．これは単に，入力を出力に変換する関数とも考えられるが， できるだけ与えられたデータに適合するように近似することを目標としている点が特徴である．\n1ニューロンのニューラルネットは単なる古典的な線形回帰（もしくは分類問題の場合にはロジスティック回帰）である．\n以下で用いる用語を整理しておこう．\n\n人工知能: 機械に知能を持たせるための技術．\n機械学習：（教師ありに限定だが）入力データと出力データから，モデルのパラメータを調整する方法．\nニューラルネット：単なる関数近似器．\n深層学習：単なる多次元分散型関数近似器．\nfastai：PyTorchのラッパー",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#深層学習の歴史",
    "href": "16fastai.html#深層学習の歴史",
    "title": "fastaiによる深層学習",
    "section": "深層学習の歴史",
    "text": "深層学習の歴史\nいま流行の深層学習(deep learning)はニューラルネットから生まれ，そのニューラルネットはパーセプトロンから生まれた．起源であるパーセプトロンまで遡ろう．\n1958年に，コーネル大学の心理学者であったFrank Rosenblattがパーセプトロンの概念を提案した．これは1層からなるニューラルネットであり，極めて単純な構成をもつが，当時は部屋いっぱいのパンチカード式の計算機が必要であった．\n隠れ層のない2層のニューラルネットでの出力誤差からの確率的勾配降下法は1960年にB. Widrow と M.E. Hoff, Jr. らが Widrow-Hoff 法（デルタルール）という名称で発表した． 隠れ層のある3層以上のニューラルネットは、1967年に甘利俊一が発表した．\n1969年に，MITのMarvin Minsky（人工知能の巨人として知られる）が，ニューラルネットの限界についての論文を発表した．彼の名声による影響のためか，その後ニューラルネットの研究は徐々に下火になっていく．\n2006年に，トロント大学のGeoffrey Hinton（ニューラルネットの父として知られる）は，多階層のニューラルネットでも効率よく学習できるような方法に関する論文を発表する． この手法はオートエンコーダーと呼ばれ，その後の深層学習の爆発的な研究のもとになったものである．\n2011年にマイクロソフト社は，言語認識のためにニューラルネットを使うようになる．その後も言語認識や機械翻訳は，画像認識ととともに，深層学習の応用分野として定着している．\n2012年の7月にGoogle社は猫を認識するためのニューラルネットであるGoogle Brainを開始し，8月には言語認識に用いるようになる．同年の10月には，Hintonの2人の学生が，ImageNetコンテストで断トツの成績で1位になる．これをきっかけに，深層学習が様々な応用に使われるようになる．\n2015年の12月には，マイクロソフト社のチームが，ImageNetコンテストで人間を超える結果を出し，2016年3月には，AlphaGoが碁の世界チャンピオンでLee Sedolを打ち負かす（ただしこれは深層学習というより強化学習の成果とも言える）．\n最近では，拡散モデル(diffusion model)を用いた高精度の画像の生成や， ChatGPT(Generative Pre-trained Transformer)に代表される自己アテンション(self attention)を用いた自然言語処理への応用が進み，技術の民主化が進んでいる．",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#なぜ深層学習がうまくいくようになったのか",
    "href": "16fastai.html#なぜ深層学習がうまくいくようになったのか",
    "title": "fastaiによる深層学習",
    "section": "なぜ深層学習がうまくいくようになったのか？",
    "text": "なぜ深層学習がうまくいくようになったのか？\nデータ量の増大に伴い，それをうまく利用できる手法である深層学習が有効になってきている．層の数を増やしても大丈夫なようなアーキテクチャ（モデル）が開発されたことも，重要な要因である．つまり，データと新しいモデルが両輪となって，様々な分野への応用を後押ししているのである．小さなデータしかないときには，ニューラルネットは線形回帰やサポートベクトル機械(SVM)と同じ程度の性能である．しかし，データが大規模になると，ニューラルネットはSVMより高性能になり，小規模なニューラルネットより大規模なニューラルネットの方が良い性能を出すようになる．\nさらには，GPUの低価格化によって単純な計算の反復が必要な深層学習が高速に実行できるようになったことも普及を後押ししている．深層学習がうまく動くことが知られるにつれて，研究も加速している．古典的なシグモイド関数からReLU（ならびにその亜種）への移行，ドロップアウト，バッチ正規化など，実際にうまく動くアルゴリズムの開発も重要な要因である．さらに，応用に応じた様々なモデル（アーキテクチャ）が提案され，問題に応じて適切なモデルを使い分けることができるようになってきたのも，理由の1つである．\n多くの人材が深層学習の分野に参入したことも重要な要因であるように感じている．ハイパーパラメータの適正化は，最適化における実験的解析と同様に，膨大な系統的な実験と，それを解析するマンパワーが必要となる．データを公開し，開発したソフトウェアをオープンソースにして配布するといったこの分野の風土も研究を加速している．\nデータやソフトウェアを非公開にする風土をもつ他の研究分野は，深層学習をお手本にする必要があるだろう．特に，日本の企業との共同研究では，データや開発したソフトウェアは非公開にしがちである．深層学習を牽引するコミュニティーのパワーは，そういった秘密主義がないことに起因している．",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#fastaiとは",
    "href": "16fastai.html#fastaiとは",
    "title": "fastaiによる深層学習",
    "section": "fastaiとは",
    "text": "fastaiとは\n深層学習のためのパッケージとしては， tensorflow (+Keras), PyTorchなどが有名であるが，ここではfastai https://www.fast.ai を用いる．\nfastaiは、最先端の深層学習を実務家が気軽に適用できるようにするためのパッケージである．\n開発者が「AIをもう一度uncoolに」を標語にしているように，専門家でなくても（Pythonを知っていれば）ある程度（というか数年前の世界新記録程度）の深層学習を使うことができる．\n特徴は以下の通り。\n\nコードが短くかける（Kerasよりも短い）．\n速い．\n最新の工夫が取り入れられている．\nPyTorchの足りない部分を補完してくれる．\n無料の（広告なしの）講義ビデオがある．\nテキストのソースも無料公開されている． https://github.com/fastai/fastbook",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#fastaiのインストール",
    "href": "16fastai.html#fastaiのインストール",
    "title": "fastaiによる深層学習",
    "section": "fastaiのインストール",
    "text": "fastaiのインストール\n自分のマシンへのfastaiのインストールは本家サイトを参照されたい．\nGoogle Colab上にはすでにインストールされているので，以下の操作だけを行えば良い．\n\n上部メニューのランタイム/ランタイプの種類を変更でGPUをオンにする．\n\n割り当てられたGPUを，以下のコマンドで確認しておく．\n\n!nvidia-smi\n\nTue Aug 23 01:10:22 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   65C    P0    31W /  70W |   2084MiB / 15109MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#mnist_sample",
    "href": "16fastai.html#mnist_sample",
    "title": "fastaiによる深層学習",
    "section": "MNIST_SAMPLE",
    "text": "MNIST_SAMPLE\n深層学習における ”Hello World” は、MNISTの手書き文字認識である。ここでは、さらに簡単なMNISTの一部（\\(３\\)と\\(７\\)だけの画像）を認識するためのニューラルネットを作成する。 これは、2値分類問題と呼ばれ、似た例をあげると，与えられた写真に猫が写っているか否か，受け取ったメイルがスパムか否か，などを判定することがあげられる。 2値分類問題は、独立変数（ニューラルネットの入力，特徴ベクトル）に対する従属変数（ターゲット）が \\(0\\)か\\(1\\)の値をとる問題であると言える．\nこの簡単な例を用いて、fastaiを用いた訓練 (training) のコツを伝授する．\nまず、fastaiで準備されているMNIST_SAMPLEのデータを読み込む．\npathはデータを展開するフォルダ（ディレクトリ）名であり、dlsはデータローダーと名付けられた画像用データローダー (ImageDataLoader)のインスタンスである。\nデータローダーには，様々なファクトリメソッド（インスタンスを生成するためのメソッド）がある．ここでは，フォルダから生成するfrom_folderメソッドを用いる．\n\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.MNIST_SAMPLE)\ndls = ImageDataLoaders.from_folder(path)\n\ndoc()でドキュメントをみることができる．\n\ndoc(ImageDataLoaders)\n\n\nImageDataLoaders\nImageDataLoaders(*loaders, path:str|Path='.', device=None)Basic wrapper around several `DataLoader`s with factory methods for computer vision problems\nShow in docs\n\n\n読み込んだデータの1バッチ分は，データローダーのshow_batchメソッドでみることができる．\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n畳み込みニューラルネットモデルのインスタンスを生成し，データとあわせて学習器 learn を生成する．メトリクス（評価尺度）はerror_rateを指定しておく．\n学習器はresnet34を用い，学習済みのデータを用いた転移学習を行う．\n\nResNet\nResNetは残差ブロックとよばれる層の固まりを，何層にも重ねたものである．残差ブロックでは，ブロックへの入力，線形層，ReLU(rectified linear unit; \\(\\max (0,x)\\))，線形層の流れに，入力そのものを加えたものに，ReLUを行うことによって出力を得る． 入力をそのまま最終の活性化関数の前に繋げることによって，必要のないブロックを跳ばして計算することができるようになり，これによって多層のニューラルネットで発生する勾配消失や勾配爆発を避けることが可能になる． 残差ブロックは，畳み込み層の間に「近道（ショートカット）」を入れたものに他ならない．この「近道」を入れることによって，最適化が楽になることが知られている．局所解が減少し， 滑らかな空間（ランドスケープ）での最適化になるのだ．\n残差ネットワークの学習器learnを作成してからlearn.summaryをみると、その構造がわかる。 以下で用いるresnet34は34層の大規模な畳み込みニューラルネットである。実行すると、学習済みの重みが読み込まれ，この重みをもとに転移学習を行うことができる．\n\n\n転移学習\n通常の訓練においては，初期のパラメータ（重み）はランダムに設定される．しかし，ランダムな初期パラメータからの学習は，アーキテクチャが大規模になると膨大な時間がかかることがある．そこで，特定のアーキテクチャに対して，事前に訓練されたパラメータ（重み）を用いることが行われるようになってきた．これが転移学習 (transfer learning) である．\n多層の畳み込みニューラルネットで発生を用いて画像の分類をするケースを考えよう．学習が進むにつれて，最初の方の層では線や角などの簡単な形状を抽出するようになり，層が深まるにつれて徐々に複雑な形状を学習するようになる．たとえば，猫のふわふわした毛に反応するニューロンや，猫の目に反応するニューロンが出てくる．最終層の直前では，分類したい物の特徴を抽出するニューロンがある．転移学習では，他の目的のために訓練されたパラメータを用い，判別を行う最終層だけに対して訓練（パラメータの調整）を行う．線や角の判別は共通であるが，最終的な分類は，対象とするものに依存して再訓練をしなければならないからだ．\n最終層のパラメータが十分に訓練されたら，上層のパラメータに対しても訓練を行う方が良い．fine_tuneメソッドは，これを自動的にしてくれる．\n\n\n学習率の調整\n深層学習で最も重要なパラメータは，学習率(learning rate: lrと略される）である．深層学習では，重み（パラメータ）調整のために非線形最適化を行う．\nつまり，勾配に適当なステップサイズを乗じて現在の値から減じる操作を繰り返す．この非線形最適化におけるステップサイズのことを，学習率と呼んでいる．\nこれをチューニングするために，fastaiでは学習器オブジェクトにlr_find() というメソッドを準備している．\n評価尺度(metrics）に誤差率を指定した学習器learnを作成してlearn.lr_find()とする．\nlr_findは，学習率を小さな値から1反復ごとに2倍にしたときの損出関数（目的関数のこと）をプロットしてくれる． 目安だが，最小値をもつ谷に入るあたりの学習率が良いと言われている．\n\nlearn = vision_learner(dls,resnet34, metrics=error_rate, cbs=ShowGraphCallback())\nlearn.lr_find()\n\n/Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/Users/mikiokubo/Library/Caches/pypoetry/virtualenvs/analytics2-0ZiTWol9-py3.9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /Users/mikiokubo/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|███████████████████████████████████████████████████████████████████| 83.3M/83.3M [00:02&lt;00:00, 40.8MB/s]\n\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0020892962347716093)\n\n\n\n\n\n\n\n\n\n損出関数が最小になるのは，学習率が0.2あたりだが，最も大きな谷の下り坂に入るあたりが良いとされている．ここでは，学習率を1e-2 (0.01)に設定して訓練してみる．\nこれには学習器インスタンスのfit_tuneメソッドを用いる．引数はエポック数（最適化の反復回数；データ全体を何回使うかを表す）と学習率である．\nなお，実際の反復ごとの学習率は，学習器のcbs引数をShowGraphCallback()とすると，見ることができる．\n\ndoc(learn.fine_tune)\n\nLearner.fine_tune(epochs, base_lr=0.002, freeze_epochs=1, lr_mult=100, pct_start=0.3, div=5.0, *, lr_max=None, div_final=100000.0, wd=None, moms=None, cbs=None, reset_opt=False, start_epoch=0)\nFine tune with `Learner.freeze` for `freeze_epochs`, then with `Learner.unfreeze` for `epochs`, using discriminative LR.\n\nTo get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev\n\n\n\nlearn.fine_tune(2, base_lr=0.01)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.200721\n0.140300\n0.038273\n00:14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.034825\n0.004138\n0.001472\n00:24\n\n\n1\n0.005775\n0.003441\n0.000981\n00:21\n\n\n\n\n\n\n\n\n\n\n\n\n評価尺度の誤差率は非常に小さく、図から訓練はうまく行われているようだ。 結果を表示してみる。大体当たっているようだ。\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfine_tuneでは、最終層以外を固定して（既定値では１回）訓練を行い、その後、fit_one_cycleを用いて、指定したエポック数だけ訓練する。 fit_one_cycleは，学習率を小さな値から最大学習率まで増やし，その後徐々に減少させていく．同時に，慣性項を徐々に下げて，その後増加させていく最適化法で，これを使うと収束が速くなると言われている．\nfine_tuneメソッドの引数はエポック数と基本学習率 base_lr である．\n分類モデルの結果を解釈は、ClassificationInterpretation()クラスのfrom_learnerメソッドを用いてできる。 plot_top_lossesを用いると，損出関数が悪かったデータを描画してくれる． 引数は画像数と画像のサイズである．\n\ninterp = ClassificationInterpretation.from_learner(learn)\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(9, figsize=(7,7))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n正解と外れを表す表（混同行列とよばれる）を出力するには，plot_confusion_matrixを使う．\n\ninterp.plot_confusion_matrix()",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#cifar10",
    "href": "16fastai.html#cifar10",
    "title": "fastaiによる深層学習",
    "section": "Cifar10",
    "text": "Cifar10\nCifar10は粗い画像から，10種類の物体を当てるデータセットである．\nImageDataLoaderのfrom_forder()メソッドでデータローダーを生成する． 検証（テスト）データは10%に設定する．\n\n\npath = untar_data(URLs.CIFAR)\n\n\n\n\n\n\n    \n      \n      100.00% [168173568/168168549 00:01&lt;00:00]\n    \n    \n\n\n\ndls = ImageDataLoaders.from_folder(path,valid_pct=0.1)\ndls.show_batch()\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet50, metrics=[error_rate,accuracy])\nlr= learn.lr_find() \nprint(lr)\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n\n\n\n\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.001737800776027143)\n\n\n\n\n\n\n\n\n\nデータとアーキテクチャ（モデル：RESNET）をあわせて学習器を生成する．\nメトリクスは正解率(accuracy)とする．\n\nlearn.fine_tune(10, base_lr=1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\naccuracy\ntime\n\n\n\n\n0\n1.720446\n1.487195\n0.504833\n0.495167\n01:36\n\n\n\n\n\n\n\n\n\n\n    \n      \n      10.00% [1/10 01:36&lt;14:28]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\naccuracy\ntime\n\n\n\n\n0\n1.095862\n0.945130\n0.328167\n0.671833\n01:36\n\n\n\n\n\n    \n      \n      56.35% [475/843 00:49&lt;00:38 0.8759]\n    \n    \n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\naccuracy\ntime\n\n\n\n\n0\n1.095862\n0.945130\n0.328167\n0.671833\n01:36\n\n\n1\n0.819684\n0.715804\n0.244000\n0.756000\n01:33\n\n\n2\n0.614426\n0.609761\n0.205833\n0.794167\n01:33\n\n\n3\n0.429096\n0.574650\n0.193333\n0.806667\n01:34\n\n\n4\n0.293377\n0.609565\n0.186167\n0.813833\n01:34\n\n\n5\n0.157066\n0.681249\n0.180667\n0.819333\n01:34\n\n\n6\n0.088063\n0.761130\n0.183500\n0.816500\n01:34\n\n\n7\n0.047697\n0.804281\n0.181500\n0.818500\n01:34\n\n\n8\n0.023899\n0.817061\n0.181333\n0.818667\n01:34\n\n\n9\n0.026840\n0.833239\n0.180333\n0.819667\n01:33\n\n\n\n\n\n損出関数の大きい順に5つのデータを出力する．\n\ninterp = Interpretation.from_learner(learn)\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5)",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#pets",
    "href": "16fastai.html#pets",
    "title": "fastaiによる深層学習",
    "section": "PETS",
    "text": "PETS\n画像ファイルから犬か猫かを判別する．\nモデル（アーキテキクチャ）は画像ファイルなのでResNetを用いる．\n\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.PETS)\npath\n\nPath('/Users/mikiokubo/.fastai/data/oxford-iiit-pet')\n\n\n\npath.ls()\n\n(#2) [Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images'),Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/annotations')]\n\n\n\npath_anno = path/\"annotations\"\npath_img = path/\"images\"\n\n\nfnames = get_image_files(path_img)\nfnames[:5]\n\n(#5) [Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_167.jpg'),Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images/pug_52.jpg'),Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images/basset_hound_112.jpg'),Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images/Siamese_193.jpg'),Path('/Users/mikiokubo/.fastai/data/oxford-iiit-pet/images/shiba_inu_122.jpg')]\n\n\n\nfiles = get_image_files(path/\"images\")\nlen(files)\n\n7390\n\n\n犬か猫かはファイル名の最初の文字が大文字か小文字かで判別できる．\nImageDataLoadersクラスのfrom_name_func()メソッドを用いてデータローダーを生成する．\n引数は順に，\n\nデータセットのパス path\nファイル名のリスト files\nラベル名を判定する関数 label_func\nデータ変換（ここでは画像ファイルのサイズの変更） item_tfms\n\nである．\n\ndef label_func(f): return f[0].isupper() #犬猫の判定\ndls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.156178\n0.016154\n0.004060\n00:52\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.054338\n0.005073\n0.001353\n00:54\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n今度は，同じデータセットを用いて，\\(37\\)種類のPETの種類を判別する．\nデータの読み込みには正規表現を用いる．\nImageDataLoaderクラスのfrom_name_re()メソッドは，正規表現を用いてデータを生成する．\n引数は順に，\n\nデータセットのパス path\nファイル名のリスト files\nクラス名をファイル名から抽出するための正規表現 pat\nデータ変換（ここでは画像ファイルのサイズの変更） item_tfms\naug_transformsによるデータ増大 batch_tfms\n\nである．\n\npat = r\"^(.*)_\\d+.jpg\"\ndls = ImageDataLoaders.from_name_re(path, files, pat, item_tfms=Resize(460),\n                                    batch_tfms=aug_transforms(size=224))\ndls.show_batch()\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0010000000474974513)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(4, 0.001)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.070160\n0.406866\n0.123139\n01:07\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.576859\n0.279217\n0.085250\n01:10\n\n\n1\n0.409450\n0.238351\n0.067659\n01:10\n\n\n2\n0.260191\n0.211842\n0.070365\n01:10\n\n\n3\n0.193102\n0.204086\n0.064953\n01:10\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp = Interpretation.from_learner(learn)\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(9, figsize=(15,10))",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#表形式データ",
    "href": "16fastai.html#表形式データ",
    "title": "fastaiによる深層学習",
    "section": "表形式データ",
    "text": "表形式データ\n\nfrom fastai.tabular.all import *\n\n\n例題： サラリーの分類\nADULT_SAMPLEは，小規模な表形式データであり，$50k以上の収入があるかどうかを当てるのが目的だ．\n\npath = untar_data(URLs.ADULT_SAMPLE)\npath\n\nPath('/Users/mikiokubo/.fastai/data/adult_sample')\n\n\n\ndf = pd.read_csv(path / \"adult.csv\")\ndf.head().T\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\nage\n49\n44\n38\n38\n42\n\n\nworkclass\nPrivate\nPrivate\nPrivate\nSelf-emp-inc\nSelf-emp-not-inc\n\n\nfnlwgt\n101320\n236746\n96185\n112847\n82297\n\n\neducation\nAssoc-acdm\nMasters\nHS-grad\nProf-school\n7th-8th\n\n\neducation-num\n12.0\n14.0\nNaN\n15.0\nNaN\n\n\nmarital-status\nMarried-civ-spouse\nDivorced\nDivorced\nMarried-civ-spouse\nMarried-civ-spouse\n\n\noccupation\nNaN\nExec-managerial\nNaN\nProf-specialty\nOther-service\n\n\nrelationship\nWife\nNot-in-family\nUnmarried\nHusband\nWife\n\n\nrace\nWhite\nWhite\nBlack\nAsian-Pac-Islander\nBlack\n\n\nsex\nFemale\nMale\nFemale\nMale\nFemale\n\n\ncapital-gain\n0\n10520\n0\n0\n0\n\n\ncapital-loss\n1902\n0\n0\n0\n0\n\n\nhours-per-week\n40\n45\n32\n40\n50\n\n\nnative-country\nUnited-States\nUnited-States\nUnited-States\nUnited-States\nUnited-States\n\n\nsalary\n&gt;=50k\n&gt;=50k\n&lt;50k\n&gt;=50k\n&lt;50k\n\n\n\n\n\n\n\n表形式データの基本クラスは TabularDataLoaders であり，これはfrom_csvメソッドやfrom_dfを用いて作ることができる．\nfrom_csvの主な引数の意味は以下の通り．\n\ncsv: csvファイル\npath: ファイルの置き場所\ny_names: 従属変数（ターゲット）の列名（のリスト）\nvalid_idx: 検証用データのインデックス\nproc: 前処理の方法を入れたリスト\ncat_names: カテゴリーデータの列名のリスト\ncont_names: 連続量データの列名のリスト\nカテゴリーデータと連続量データを自動的に分けてくれる以下の関数も準備されている．\n\ncont_names, cat_names = cont_cat_split(df=データフレーム, dep_var=従属変数の列名)\n\nprocs: 前処理の指定\n\n前処理には以下のものがある．\n\nCategorify: cat_names引数で与えた列リストをカテゴリー変数とする．\nFillMissing： cont_namesに含まれる連続変数に対して欠損値処理を行う．\n\n引数のFillStrategyには[MEDIAN, COMMON, CONSTANT]があり，順にメディアン，最頻値，定数（fill_valで指定）である． また，add_col引数がTrueのときには，欠損値であることを表す列を追加する．\n\nNormalize: cont_namesに含まれる連続変数の正規化を行う．(平均を引いて標準偏差+微少量で割る．）\n\n時刻型の列を自動的に幾つかの変数に変換する以下の関数が準備されている．\nadd_datepart(df, fldname, drop=True, time=False)\nfldnameは時刻型が含まれている列名であり，dropがTrueのとき元の列を削除する．またtimeがTrueのときには，日付だけでなく時，分，秒の列も追加する．\n\ndls = TabularDataLoaders.from_csv(\n    path / \"adult.csv\",\n    path=path,\n    y_names= \"salary\",\n    cat_names=[\n        \"workclass\",\n        \"education\",\n        \"marital-status\",\n        \"occupation\",\n        \"relationship\",\n        \"race\",\n    ],\n    cont_names=[\"age\", \"fnlwgt\", \"education-num\"],\n    procs=[Categorify, FillMissing, Normalize],\n)\n\n\ndls.show_batch()\n\n\n\n\n\nworkclass\neducation\nmarital-status\noccupation\nrelationship\nrace\neducation-num_na\nage\nfnlwgt\neducation-num\nsalary\n\n\n\n\n0\nState-gov\nHS-grad\nMarried-civ-spouse\nCraft-repair\nHusband\nWhite\nFalse\n58.000001\n200315.999803\n9.0\n&lt;50k\n\n\n1\nPrivate\nAssoc-voc\nNever-married\nTransport-moving\nOwn-child\nWhite\nFalse\n34.000000\n124827.001701\n11.0\n&lt;50k\n\n\n2\nPrivate\nBachelors\nMarried-civ-spouse\nTech-support\nHusband\nWhite\nFalse\n54.000000\n171924.000267\n13.0\n&lt;50k\n\n\n3\nPrivate\nHS-grad\nMarried-civ-spouse\nTransport-moving\nHusband\nBlack\nFalse\n50.000000\n378746.998755\n9.0\n&lt;50k\n\n\n4\nPrivate\nSome-college\nNever-married\nAdm-clerical\nOwn-child\nWhite\nFalse\n25.000000\n60485.001827\n10.0\n&lt;50k\n\n\n5\nState-gov\n11th\nMarried-civ-spouse\nTransport-moving\nHusband\nWhite\nFalse\n30.000000\n54318.006147\n7.0\n&lt;50k\n\n\n6\n?\nSome-college\nMarried-civ-spouse\n?\nHusband\nWhite\nFalse\n56.999999\n296516.003827\n10.0\n&lt;50k\n\n\n7\nPrivate\nHS-grad\nDivorced\nExec-managerial\nNot-in-family\nWhite\nFalse\n39.000000\n188540.000017\n9.0\n&lt;50k\n\n\n8\nPrivate\nBachelors\nNever-married\nAdm-clerical\nNot-in-family\nWhite\nFalse\n26.000000\n391349.005619\n13.0\n&lt;50k\n\n\n9\nPrivate\nHS-grad\nMarried-civ-spouse\nAdm-clerical\nWife\nWhite\nFalse\n25.000000\n303430.997391\n9.0\n&lt;50k\n\n\n\n\n\n\ncont_names, cat_names = cont_cat_split(df, max_card=50, dep_var=\"salary\")\ncat_names\n\n['workclass',\n 'education',\n 'marital-status',\n 'occupation',\n 'relationship',\n 'race',\n 'sex',\n 'native-country']\n\n\ntabular_learner関数で表形式データの深層学習器を作ることができる．\n主な引数の意味は以下の通り． - dls: データローダー - layers: レイヤの数を指定したリスト - emb_szs: カテゴリーデータの列名をキー，埋め込みサイズを値とした辞書 - metrics: 評価尺度(accuracyなど） - emb_drop: 埋め込みレイヤのdrop out率\n\n# 深層学習(PyTorch)の学習器インスタンスlearnを生成し，fitメソッドで訓練．引数はエポック数と学習率．\nlearn = tabular_learner(dls, metrics=[accuracy])\n\n\nlearn.fit_one_cycle(3, 1e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.387215\n0.363688\n0.833077\n00:10\n\n\n1\n0.356962\n0.358292\n0.835534\n00:05\n\n\n2\n0.352825\n0.355646\n0.834613\n00:05\n\n\n\n\n\nsummary属性をみると，学習器は，埋め込み層に続いて2つの線形層を配置したニューラルネットになっていることが確認できる．\n\nlearn.summary()\n\n\n\n\n\n\n\n\nTabularModel (Input shape: 64 x 7)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 6              \nEmbedding                                 60         True      \n____________________________________________________________________________\n                     64 x 8              \nEmbedding                                 136        True      \n____________________________________________________________________________\n                     64 x 5              \nEmbedding                                 40         True      \n____________________________________________________________________________\n                     64 x 8              \nEmbedding                                 128        True      \n____________________________________________________________________________\n                     64 x 5              \nEmbedding                                 35         True      \n____________________________________________________________________________\n                     64 x 4              \nEmbedding                                 24         True      \n____________________________________________________________________________\n                     64 x 3              \nEmbedding                                 9          True      \nDropout                                                        \nBatchNorm1d                               6          True      \n____________________________________________________________________________\n                     64 x 200            \nLinear                                    8400       True      \nReLU                                                           \nBatchNorm1d                               400        True      \n____________________________________________________________________________\n                     64 x 100            \nLinear                                    20000      True      \nReLU                                                           \nBatchNorm1d                               200        True      \n____________________________________________________________________________\n                     64 x 2              \nLinear                                    202        True      \n____________________________________________________________________________\n\nTotal params: 29,640\nTotal trainable params: 29,640\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam&gt;\nLoss function: FlattenedLoss of CrossEntropyLoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - Recorder\n  - ProgressCallback\n\n\n\n\n例題：住宅価格の予測\nBostonの住宅価格の予測を深層学習を用いた回帰分析で行う．\nmedvが住宅の価格で，他のデータ（犯罪率や人口などの数値データ）から予測する．\nただし，訓練データとテストデータのインデックス（train_idx,valid_idx）を生成するには， 以下に示すように，scikit-learnのtrain_test_splitを用いる．\n連続データとカテゴリーデータの列は， cont_cat_split関数を用いる． 引数の max_card \\(=50\\) は \\(50\\)以下の種類しかもたない列はカテゴリー変数とみなすことを意味する． また，引数の dep_varは従属変数名である．\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n\nboston = pd.read_csv(\"http://logopt.com/data/Boston.csv\",index_col=0)\nprocs = [Categorify, FillMissing, Normalize] #前処理の種類を準備．\ntrain_idx, valid_idx = train_test_split(range(len(boston)), test_size=0.3) #検証用データのインデックスを準備．\ndep_var = \"medv\" #従属変数名を準備．\n\ncont_names, cat_names = cont_cat_split(boston, max_card = 50, dep_var=dep_var)\nprint(cat_names, cont_names)\n\n['chas', 'rad'] ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'tax', 'ptratio', 'black', 'lstat']\n\n\n準備ができたので， TabularDataLoadersのfrom_dfメソッドでデータローダーを生成し，それをもとにtabular_learner関数で学習器 learn を作る． 評価尺度(metrics)には rmse （rooted mean square error)を用いる．\nfit_one_cycle法を用いて， 30エポック，最大学習率0.001で訓練する．\n\ndls = TabularDataLoaders.from_df(boston, y_names=dep_var, procs = procs, cont_names=cont_names, cat_names=cat_names)\nlearn = tabular_learner(dls, metrics=rmse)\nlearn.fit_one_cycle(30,1e-3)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\n_rmse\ntime\n\n\n\n\n0\n583.483521\n612.155334\n24.741774\n00:00\n\n\n1\n581.810120\n611.932373\n24.737268\n00:00\n\n\n2\n578.824707\n608.098999\n24.659664\n00:00\n\n\n3\n574.245300\n598.170288\n24.457520\n00:00\n\n\n4\n567.828918\n579.099182\n24.064480\n00:00\n\n\n5\n556.611816\n545.330933\n23.352322\n00:00\n\n\n6\n537.237671\n484.291077\n22.006615\n00:00\n\n\n7\n508.969635\n396.657959\n19.916273\n00:00\n\n\n8\n469.514343\n293.581970\n17.134233\n00:00\n\n\n9\n424.950714\n204.514008\n14.300838\n00:00\n\n\n10\n377.579315\n132.951584\n11.530462\n00:00\n\n\n11\n334.218781\n91.368095\n9.558666\n00:00\n\n\n12\n295.503296\n62.303730\n7.893271\n00:00\n\n\n13\n261.120300\n45.621571\n6.754374\n00:00\n\n\n14\n231.821823\n36.233948\n6.019464\n00:00\n\n\n15\n205.355896\n31.576481\n5.619295\n00:00\n\n\n16\n182.979019\n28.494129\n5.337989\n00:00\n\n\n17\n163.683594\n26.984529\n5.194664\n00:00\n\n\n18\n146.885498\n25.802696\n5.079636\n00:00\n\n\n19\n132.069229\n23.790033\n4.877503\n00:00\n\n\n20\n119.163567\n23.443287\n4.841827\n00:00\n\n\n21\n107.618279\n22.275869\n4.719732\n00:00\n\n\n22\n97.619194\n21.489685\n4.635697\n00:00\n\n\n23\n88.492821\n20.707258\n4.550523\n00:00\n\n\n24\n80.453087\n20.948822\n4.576989\n00:00\n\n\n25\n73.967003\n20.161036\n4.490104\n00:00\n\n\n26\n68.017082\n20.298531\n4.505389\n00:00\n\n\n27\n62.846817\n20.439318\n4.520987\n00:00\n\n\n28\n58.536152\n20.634672\n4.542541\n00:00\n\n\n29\n53.941723\n20.251295\n4.500144\n00:00\n\n\n\n\n\n\n\n問題（スパム）\nメールがスパム（spam；迷惑メイル）か否かを，深層学習を用いて判定せよ．\nデータは，様々な数値情報から，is_spam列が1 （スパム）か，0（スパムでない）かを判定するデータである．\n評価尺度はaccuracyとする．\n\nspam = pd.read_csv(\"http://logopt.com/data/spam.csv\")\nspam.head()\n\n\n\n\n\n\n\n\nword_freq_make\nword_freq_address\nword_freq_all\nword_freq_3d\nword_freq_our\nword_freq_over\nword_freq_remove\nword_freq_internet\nword_freq_order\nword_freq_mail\n...\nchar_freq_;\nchar_freq_(\nchar_freq_[\nchar_freq_!\nchar_freq_$\nchar_freq_#\ncapital_run_length_average\ncapital_run_length_longest\ncapital_run_length_total\nis_spam\n\n\n\n\n0\n0.21\n0.28\n0.50\n0.0\n0.14\n0.28\n0.21\n0.07\n0.00\n0.94\n...\n0.00\n0.132\n0.0\n0.372\n0.180\n0.048\n5.114\n101\n1028\n1\n\n\n1\n0.06\n0.00\n0.71\n0.0\n1.23\n0.19\n0.19\n0.12\n0.64\n0.25\n...\n0.01\n0.143\n0.0\n0.276\n0.184\n0.010\n9.821\n485\n2259\n1\n\n\n2\n0.00\n0.00\n0.00\n0.0\n0.63\n0.00\n0.31\n0.63\n0.31\n0.63\n...\n0.00\n0.137\n0.0\n0.137\n0.000\n0.000\n3.537\n40\n191\n1\n\n\n3\n0.00\n0.00\n0.00\n0.0\n0.63\n0.00\n0.31\n0.63\n0.31\n0.63\n...\n0.00\n0.135\n0.0\n0.135\n0.000\n0.000\n3.537\n40\n191\n1\n\n\n4\n0.00\n0.00\n0.00\n0.0\n1.85\n0.00\n0.00\n1.85\n0.00\n0.00\n...\n0.00\n0.223\n0.0\n0.000\n0.000\n0.000\n3.000\n15\n54\n1\n\n\n\n\n5 rows × 58 columns\n\n\n\n\n\n問題（毒キノコ）\nデータから毒キノコか否かを，深層学習を用いて判定せよ．\ntarget列がターゲット（従属変数）であり，edibleが食用，poisonousが毒である．\n評価尺度はaccuracyとする．\n\nmashroom = pd.read_csv(\n    \"http://logopt.com/data/mashroom.csv\",\n    dtype={\"shape\": \"category\", \"surface\": \"category\", \"color\": \"category\"},\n)\nmashroom.head()\n\n\n\n\n\n\n\n\ntarget\nshape\nsurface\ncolor\n\n\n\n\n0\nedible\nconvex\nsmooth\nyellow\n\n\n1\nedible\nbell\nsmooth\nwhite\n\n\n2\npoisonous\nconvex\nscaly\nwhite\n\n\n3\nedible\nconvex\nsmooth\ngray\n\n\n4\nedible\nconvex\nscaly\nyellow\n\n\n\n\n\n\n\n\n\n問題（タイタニック）\ntitanicデータに対して深層学習を行い，死亡確率の推定を行え．\n\ntitanic = pd.read_csv(\"http://logopt.com/data/titanic.csv\")\ntitanic.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\n\n問題（胸部癌）\nhttp://logopt.com/data/cancer.csv にある胸部癌か否かを判定するデータセットを用いて，深層学習による分類を行え．\n最初の列diagnosisが癌か否かを表すものであり，“M”が悪性（malignant），“B”が良性（benign）を表す．\n\ncancer = pd.read_csv(\"http://logopt.com/data/cancer.csv\", index_col=0)\ncancer.head()\n\n\n\n\n\n\n\n\ndiagnosis\nradius_mean\ntexture_mean\nperimeter_mean\narea_mean\nsmoothness_mean\ncompactness_mean\nconcavity_mean\nconcave points_mean\nsymmetry_mean\n...\nradius_worst\ntexture_worst\nperimeter_worst\narea_worst\nsmoothness_worst\ncompactness_worst\nconcavity_worst\nconcave points_worst\nsymmetry_worst\nfractal_dimension_worst\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n842302\nM\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n...\n25.38\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n\n\n842517\nM\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n...\n24.99\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n\n\n84300903\nM\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n...\n23.57\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n\n\n84348301\nM\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n...\n14.91\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n\n\n84358402\nM\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n...\n22.54\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n\n\n\n\n5 rows × 31 columns\n\n\n\n\n\n問題（部屋）\n以下の部屋が使われているか否かを判定するデータに対して，深層学習による分類を行え．\noccupancy列が部屋が使われているか否かを表す情報であり，これをdatetime列以外の情報から分類せよ．\n\noccupancy = pd.read_csv(\"http://logopt.com/data/occupancy.csv\")\noccupancy.head()\n\n\n\n\n\n\n\n\ndatetime\ntemperature\nrelative humidity\nlight\nCO2\nhumidity\noccupancy\n\n\n\n\n0\n2015-02-04 17:51:00\n23.18\n27.2720\n426.0\n721.25\n0.004793\n1\n\n\n1\n2015-02-04 17:51:59\n23.15\n27.2675\n429.5\n714.00\n0.004783\n1\n\n\n2\n2015-02-04 17:53:00\n23.15\n27.2450\n426.0\n713.50\n0.004779\n1\n\n\n3\n2015-02-04 17:54:00\n23.15\n27.2000\n426.0\n708.25\n0.004772\n1\n\n\n4\n2015-02-04 17:55:00\n23.10\n27.2000\n426.0\n704.50\n0.004757\n1",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#画像データ",
    "href": "16fastai.html#画像データ",
    "title": "fastaiによる深層学習",
    "section": "画像データ",
    "text": "画像データ\nデータ一覧は Data Externalにある．\nhttp://docs.fast.ai/data.external#download_url\n\nfrom fastai.vision import *\n\n\n複数のラベルを生成する分類\nPASCAL_2007データを読み込み，複数のラベルの予測を行う．\n\nfrom fastai.vision.all import *\n\n\npath = untar_data(URLs.PASCAL_2007)\n\n\n\n\n\ndf = pd.read_csv(path/\"train.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nfname\nlabels\nis_valid\n\n\n\n\n0\n000005.jpg\nchair\nTrue\n\n\n1\n000007.jpg\ncar\nTrue\n\n\n2\n000009.jpg\nhorse person\nTrue\n\n\n3\n000012.jpg\ncar\nFalse\n\n\n4\n000016.jpg\nbicycle\nTrue\n\n\n\n\n\n\n\nデータブロック DataBlockを始めに生成して，それからデータローダーを作る．\nデータブロックは，以下の引数をもつ．\n\nblocks: データブロックを構成するブロックのタプル； 画像ブロックと（複数の）カテゴリーブロック\nsplitter: 訓練データと検証データのインデックスを返す関数\nget_x: 独立変数（特徴ベクトル）を返す関数\nget_y: 従属変数（ターゲット）を返す関数\nitem_tfms: 個々のデータの変換の指示\nbatch_tfms: バッチに対する変換の指示\n\n\ndef get_x(r): return path/\"train\"/r[\"fname\"]\ndef get_y(r): return r[\"labels\"].split(\" \")\ndef splitter(df):\n    train = df.index[df[\"is_valid\"]].tolist()\n    valid = df.index[df[\"is_valid\"]].tolist()\n    return train,valid\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter,\n                   get_x=get_x, \n                   get_y=get_y,\n                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\ndls = dblock.dataloaders(df)\ndls.show_batch(nrows=1, ncols=3)\n\n\n\n\n\n\n\n\n評価尺度には多ラベル用の正解率 accuracy_multiを用いる． また，関数partialで，引数の閾値（thresh)を0.2に固定して渡す． partialは標準モジュールのfunctoolsに含まれているが，fastaiではすでにimportした状態になっている．\nfine_tuneで訓練をするが，最終層以外を固定して（freezeして）４エポック訓練し，その後，最終層以外も自由にして3エポック訓練する．\n\nlearn = vision_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))\nlearn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)\n\nDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.939143\n0.686238\n0.235538\n00:28\n\n\n1\n0.824816\n0.574355\n0.280578\n00:27\n\n\n2\n0.605865\n0.203421\n0.807829\n00:28\n\n\n3\n0.359789\n0.127288\n0.937928\n00:28\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.138787\n0.124408\n0.941434\n00:29\n\n\n1\n0.118910\n0.108459\n0.948426\n00:29\n\n\n2\n0.097468\n0.105211\n0.952430\n00:29\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n画像から人の頭の中心を当てる回帰\n画像データは分類だけでなく，回帰を行うこともできる． BIWIデータを読み込み，サンプル画像を表示する．\n\npath = untar_data(URLs.BIWI_HEAD_POSE)\n\n\n\n\n\nimg_files = get_image_files(path)\ndef img2pose(x): return Path(f\"{str(x)[:-7]}pose.txt\")\nimg2pose(img_files[0])\n\nPath('/root/.fastai/data/biwi_head_pose/06/frame_00079_pose.txt')\n\n\n\ncal = np.genfromtxt(path/\"01\"/\"rgb.cal\", skip_footer=6)\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n    return tensor([c1,c2])\n\n\nbiwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    get_y=get_ctr,\n    splitter=FuncSplitter(lambda o: o.parent.name==\"13\"),\n    batch_tfms=[*aug_transforms(size=(240,320)), \n                Normalize.from_stats(*imagenet_stats)]\n)\n\n\ndls = biwi.dataloaders(path)\ndls.show_batch(max_n=9, figsize=(8,6))\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet18, y_range=(-1,1))\nlearn.lr_find()\n\nDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n\n\n\n\n\n\n\n\n\n\n\nSuggestedLRs(lr_min=0.004786301031708717, lr_steep=1.3182567499825382e-06)\n\n\n\n\n\n\n\n\n\n\nlearn.fine_tune(4, 5e-3)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.052732\n0.005105\n02:07\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.005605\n0.001754\n02:17\n\n\n1\n0.003696\n0.001718\n02:17\n\n\n2\n0.002149\n0.000066\n02:16\n\n\n3\n0.001374\n0.000060\n02:18\n\n\n\n\n\n正解と予測を表示\n\nlearn.show_results()",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#協調フィルタリング",
    "href": "16fastai.html#協調フィルタリング",
    "title": "fastaiによる深層学習",
    "section": "協調フィルタリング",
    "text": "協調フィルタリング\n\nfrom fastai.tabular.all import *\nfrom fastai.collab import *\n\n協調フィルタリング(collaborative filtering)とは，推奨システム(recommender system)の一種で，ユーザーとアイテムの両方の潜在因子を考慮して，レーティングを決める手法だ．\n推奨システムでよく見かけるのは，「この商品を買った人はこの商品も買っています」とか「最も良く売れているのはこの商品です」などの猿でもできるタイプのものだ．このような単純なものではなく，あなたに似た潜在因子をもつ人が，高いレーティングをつけている（もしくは良く購入する）商品に近い潜在因子をもった商品を紹介するのが，協調フィルタリングである．\n機械学習の中で（Andrew Ngが実務家から聞いた話だが）実務で最も役に立つ，もしくは期待されているのがこれだ． 背景にある理論を簡単に紹介しよう．\nいま，顧客と商品の集合とともに，商品 \\(i\\) に対して顧客 \\(j\\) が評価を行ったデータが与えられているものとする． ただし，顧客が評価をつけた商品は通常は少なく，データは極めて疎な行列として与えられている． 商品 \\(i\\) に対して顧客 \\(j\\) が評価を行っているとき \\(1\\)，それ以外のとき \\(0\\) のパラメータを \\(r(i,j)\\) とする． \\(r(i,j)=1\\) の場合には，顧客 \\(j\\) は商品 \\(i\\) に対して離散値の（たとえば \\(1\\) から \\(5\\) の整数などで）評価点をつける． この評価点を表すデータを \\(y^{(i,j)}\\) とする．これがトレーニングデータになる． これをもとに，評価点がつけられていない（\\(r(i,j)=0\\) の）場所の評価点を推定することが問題の目的となる．\n推奨システム設計のための手法は， コンテンツベース推奨(contents based recommendation)と協調フィルタリング推奨(collaborative filtering recommendation)の2つに分類できる．\nコンテンツベース推奨では，商品 \\(i\\) に対する特徴ベクトル \\(x^{(i)}  \\in R^n\\) が与えられていると仮定する． たとえば，商品を映画としたときに，特徴ベクトルは映画の種別（アクション，SF，ホラー，恋愛もの，スリラー ，ファンタジーなど）の度合いを表す． たとえば，スターウォーズはSF度 \\(0.8\\)，恋愛度 \\(0.1\\)，アクション度 \\(0.1\\) と採点される．\n顧客 \\(j\\) の特徴に対する重みベクトルを \\(w^{(j)}  \\in R^n\\) とする．これは顧客がどういった映画の種別を好むのかを表す． これを線形回帰を用いて求めることを考えると仮説関数は， \\[\n  h_w (x)=w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n  \n\\] となる． 最適な重みを計算するには，以下に定義される費用関数を最小にする重みベクトル \\(w^{(j)}\\) を求めればよい． \\[\n\\frac{1}{2} \\sum_{i: r(i,j) = 1 } \\left(  (w^{(j)})^T (x^{(i)}) -y^{(i,j)} \\right)^2\n\\]\n映画ごとに特徴を見積もることは実際には難しい． そこで，協調フィルタリング推奨では，商品ごとの特徴ベクトル \\(x^{(i)}  \\in R^n\\) を定数として与えるのではなく， 変数とみなして顧客ごとの重みと同時に最適化を行う． すべての顧客と商品に対するトレーニングデータとの誤差の2乗和を最小化する問題は，以下のように書ける． \\[\n\\min_{w, x} \\frac{1}{2} \\sum_{(i,j): r(i,j) = 1 } \\left(  (w^{(j)})^T (x^{(i)}) -y^{(i,j)} \\right)^2\n\\]\nこの問題を直接最適化してもよいが，\\(x\\) と \\(w\\) を交互に線形回帰を用いて解く簡便法も考えられる． すなわち，適当な特徴ベクトルの推定値 \\(x^{(i)}\\) を用いて顧客 \\(j\\) に対する重みベクトル \\(w^{(j)}\\) を求めた後に， 今度は \\(w^{(j)}\\) を用いて \\(x^{(i)}\\) を求めるのである．この操作を収束するまで繰り返せばよい．\n上のアルゴリズムを用いて得られた商品 \\(i\\) の特徴ベクトル \\(x^{(i)}\\) を用いると， 類似の商品を抽出することができる． たとえば，\\(x^{(i)}\\) を \\(n\\)次元空間内の点とみなしてクラスタリングを行うことによって， 商品のクラスタリングができる．同様に顧客 \\(j\\) の重みベクトル \\(w^{(j)}\\) を用いることによって顧客のクラスタリングができる．\n有名な例題（映画の評価値を当てる）であるMovieLensのデータを読み込む．\nデータにはtimestamp列がついているが，とりあえずこれは無視してレーティング(rating)を予測してみる．\n\npath = untar_data(URLs.ML_100k)\nratings = pd.read_csv(path/\"u.data\", delimiter=\"\\t\", header=None,\n                      usecols=(0,1,2), names=[\"user\",\"movie\",\"rating\"])\nratings.head()\n\n\n\n\n\n\n\n\n\n\n\nuser\nmovie\nrating\n\n\n\n\n0\n196\n242\n3\n\n\n1\n186\n302\n3\n\n\n2\n22\n377\n1\n\n\n3\n244\n51\n2\n\n\n4\n166\n346\n1\n\n\n\n\n\n\n\n\nmovies = pd.read_csv(path/\"u.item\",  delimiter=\"|\", encoding=\"latin-1\",\n                     usecols=(0,1), names=(\"movie\",\"title\"), header=None)\nmovies.head()\n\n\n\n\n\n\n\n\nmovie\ntitle\n\n\n\n\n0\n1\nToy Story (1995)\n\n\n1\n2\nGoldenEye (1995)\n\n\n2\n3\nFour Rooms (1995)\n\n\n3\n4\nGet Shorty (1995)\n\n\n4\n5\nCopycat (1995)\n\n\n\n\n\n\n\n\nratings = ratings.merge(movies)\nratings.head()\n\n\n\n\n\n\n\n\nuser\nmovie\nrating\ntitle\n\n\n\n\n0\n196\n242\n3\nKolya (1996)\n\n\n1\n63\n242\n3\nKolya (1996)\n\n\n2\n226\n242\n5\nKolya (1996)\n\n\n3\n154\n242\n3\nKolya (1996)\n\n\n4\n306\n242\n5\nKolya (1996)\n\n\n\n\n\n\n\nCollabDataLoadersクラスのfrom_dfメソッドにデータフレームを入れるとデータオブジェクトを作成してくれる．\n引数はデータフレーム(ratings)，検証データの比率(pct_val)，ユーザー，アイテム，レーティングを表す列名だ．\n\ndls = CollabDataLoaders.from_df(ratings, item_name=\"title\", bs=64)\n\n作成したデータオブジェクトをcollab_learner関数に入れると学習器（誤差を最小にする潜在因子行列の重みの最適化が目的）を作ってくれる．予測したいレーティングは，星５つまでなので，y_rangeで指定する．\nデータオブジェクト(data)，潜在因子の数(n_factors)を指定しているが，他にもmetricsは評価尺度，wdはweight decayで正則化のためのパラメータなどを指定できる．\ndef collab_learner(data, n_factors:int=None, use_nn:bool=False, metrics=None,\n                  emb_szs:Dict[str,int]=None, wd:float=0.01, **kwargs)-&gt;Learner\n\ndls.show_batch()\n\n\n\n\n\nuser\ntitle\nrating\n\n\n\n\n0\n348\nJack (1996)\n4\n\n\n1\n346\nTwelve Monkeys (1995)\n2\n\n\n2\n110\nSimple Twist of Fate, A (1994)\n2\n\n\n3\n72\nConan the Barbarian (1981)\n2\n\n\n4\n864\nDeath and the Maiden (1994)\n4\n\n\n5\n347\nTwelve Monkeys (1995)\n4\n\n\n6\n731\nSabrina (1954)\n4\n\n\n7\n751\nRaising Arizona (1987)\n3\n\n\n8\n344\nLeaving Las Vegas (1995)\n4\n\n\n9\n577\nDevil in a Blue Dress (1995)\n4\n\n\n\n\n\n\nlearn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n\n\nlearn.fit_one_cycle(5, 5e-3)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.935071\n0.929474\n00:06\n\n\n1\n0.812040\n0.860315\n00:06\n\n\n2\n0.631619\n0.864089\n00:06\n\n\n3\n0.400996\n0.885280\n00:06\n\n\n4\n0.289997\n0.891847\n00:06\n\n\n\n\n\n検証の損出関数をみると、過剰適合しているようだ（途中まで下がっているが、最後は上昇している）。\nL2正則化関数を入れてみよう。fastaiでは、重み減衰 (weight decay: wd) という引数で指定する。\n\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.952608\n0.940679\n00:06\n\n\n1\n0.839875\n0.867949\n00:06\n\n\n2\n0.742433\n0.825799\n00:06\n\n\n3\n0.591568\n0.814826\n00:06\n\n\n4\n0.479914\n0.816404\n00:06\n\n\n\n\n\n訓練ロスは悪化しているが、検証ロスは改善していることが確認できる。\nトップ1000の映画を抽出し、埋め込み層の重みを主成分分析で2次元に落として描画してみる。\nニューラルネットが、自動的に映画の特徴を抽出していることが確認できる。\n\ng = ratings.groupby(\"title\")[\"rating\"].count()\ntop_movies = g.sort_values(ascending=False).index.values[:1000]\ntop_idxs = tensor([learn.dls.classes[\"title\"].o2i[m] for m in top_movies])\nmovie_w = learn.model.i_weight.weight[top_idxs].cpu().detach()\nmovie_pca = movie_w.pca(3)\nfac0,fac1,fac2 = movie_pca.t()\nidxs = np.random.choice(len(top_movies), 50, replace=False)\nidxs = list(range(100))\nX = fac0[idxs]\nY = fac2[idxs]\nplt.figure(figsize=(12,12))\nplt.scatter(X, Y)\nfor i, x, y in zip(top_movies[idxs], X, Y):\n    plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#意味分割",
    "href": "16fastai.html#意味分割",
    "title": "fastaiによる深層学習",
    "section": "意味分割",
    "text": "意味分割\n以下のデータセットは、与えられた画像の分割（各ピクセルがどの物体に属するのかを分類すること；これを意味分割(semantic segmentation)と呼ぶ）に用いられる。\n\nCamvid: Motion-based Segmentation and Recognition Dataset (CAMVID, CAMVID_TINY)\n\n\npath = untar_data(URLs.CAMVID_TINY)\ndls = SegmentationDataLoaders.from_label_func(\n    path, bs=8, fnames = get_image_files(path/\"images\"),\n    label_func = lambda o: path/\"labels\"/f\"{o.stem}_P{o.suffix}\",\n    codes = np.loadtxt(path/\"codes.txt\", dtype=str)\n)\n\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(8)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.760665\n5.930563\n01:09\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n2.219755\n1.865447\n01:15\n\n\n1\n1.819075\n1.280244\n01:20\n\n\n2\n1.559273\n1.177241\n01:17\n\n\n3\n1.374030\n0.868488\n01:16\n\n\n4\n1.210444\n0.832017\n01:16\n\n\n5\n1.082514\n0.755146\n01:16\n\n\n6\n0.980371\n0.728570\n01:15\n\n\n7\n0.902825\n0.727522\n01:16\n\n\n\n\n\n\nlearn.show_results(max_n=6, figsize=(7,8))",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#テキストデータ",
    "href": "16fastai.html#テキストデータ",
    "title": "fastaiによる深層学習",
    "section": "テキストデータ",
    "text": "テキストデータ\nfastaiでは，Wikipediaの膨大なテキストデータを用いた学習済みの言語モデルであるAWD_LSTMを準備している． 映画の批評データを用いて，fastaiの自然言語処理を試してみる．\n\nfrom fastai.text.all import *\n\n\npath = untar_data(URLs.IMDB)\n\nget_imdb = partial(get_text_files, folders=[\"train\", \"test\", \"unsup\"])\n\n\ndls_lm = DataBlock(\n    blocks=TextBlock.from_folder(path, is_lm=True),\n    get_items=get_imdb, splitter=RandomSplitter(0.1)\n).dataloaders(path, path=path, bs=128, seq_len=80)\n\n\n\n\n\n\n\n言語モデルのデータブロック dls_lm をもとに，学習済のパラメータAWD_LSTMを読み込んで学習器をつくる．\n\nlearn = language_model_learner(\n    dls_lm, AWD_LSTM, drop_mult=0.3, \n    metrics=[accuracy, Perplexity()]).to_fp16()\n\n\n\n\n適当な文章TEXT を入れて，その後の文章を作らせる．tempertureは文章にランダム性を付与するために用いられる．\n\nTEXT = \"This is a pen. That is an\"\nN_WORDS = 40\nN_SENTENCES = 2\npreds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n         for _ in range(N_SENTENCES)]\nprint(preds)\n\n\n\n\n\n\n\n[\"This is a pen . That is an allusion to what i ' ve known as The Radio Times . BBC Radio 1 ! is an example of how a different composer can work with an orchestra and which contains over half a\",\n 'This is a pen . That is an especially unusual phrase for an artist who has been ascribed to the term , and is sometimes referred to as the \" Artist Generation \" . The term is sometimes defined as defining the evolution of the']\n\n\n言語モデルを用いて，映画の批評のテキストが，ネガティブかパシティブかを判別する学習器をつくる．\n映画批評のデータセットIMDBを読み込んで，言語モデル AWD_LSTM を用いて訓練する．\n\nfrom fastai.text.all import *\n\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid=\"test\")\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(4, 1e-2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.598281\n0.404613\n0.822120\n04:11\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.318746\n0.245778\n0.898840\n07:56\n\n\n1\n0.249433\n0.221797\n0.908000\n08:07\n\n\n2\n0.183325\n0.190910\n0.926360\n08:19\n\n\n3\n0.153639\n0.194017\n0.926240\n08:11\n\n\n\n\n\n予測してみる．\n\nprint( learn.predict(\"I really liked that movie!\") )\n\n\n\n\n('pos', tensor(1), tensor([3.4028e-04, 9.9966e-01]))",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#画像生成",
    "href": "16fastai.html#画像生成",
    "title": "fastaiによる深層学習",
    "section": "画像生成",
    "text": "画像生成\nちょっと前までは GAN (generative adversarial network; 敵対的生成ネットワーク)が流行していたが， 最近では 拡散モデル (diffusion model)を用いて，高精度な画像を高速に生成することができるようになってきた．\n\n問題（DALL・E 2）\nDALL・E2 https://openai.com/dall-e-2/ に登録して，オリジナルの画像を生成せよ．\n（注意： 生成できる画像数に制限がある（毎月リセットされる）\n\n\n問題（Hugging Face Diffusers）\nDiffusers https://github.com/huggingface/diffusers/ のQuickstartにある Getting started with Diffusers をGoogle Colab で開いて，ドライブにコピーを保存してから，最初の画像生成までを実行せよ．\n（注意： ランタイムでGPUをオンにしてから実行する． 有料版のColab Pro(+)に登録する必要はない）\n\n\n問題 （Hugging Face)\nHugging Face のモデル https://huggingface.co/models のTasks（+22 Taskを押すとたくさん出てくる)から好きなものを選び，試してみよ． また，どのようなモデルが使われているか解説を読み， （できれば） Google Colabで動かしてみよ．\n（注意： しばらくはloginなしで使えるが，時間制限を超えるとloginが必要になる）",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#深層学習の基礎を図で解説",
    "href": "16fastai.html#深層学習の基礎を図で解説",
    "title": "fastaiによる深層学習",
    "section": "深層学習の基礎を図で解説",
    "text": "深層学習の基礎を図で解説\n通常の（完全結合層から成る）ニューラルネットについては，scikit-learn を用いた機械学習の章で述べた． 以下では，本章で紹介した幾つかのアーキテクチャについて解説する．\n\n畳み込みニューラルネット\n画像データに対して完全結合層だけのニューラルネットを使うことは，膨大な量のパラメータを必要とするので，適当な選択ではない． 完全結合層のかわりに畳み込み(convolusion)を用いた層を用いる方法が，畳み込みニューラルネットである．\n畳み込みニューラルネットでは，以下の図に示すように，畳み込み（一種のパラメータ行列の乗算）を行った後に，活性化関数としてLeLUを用い，さらにマックスプールでデータを小さくする操作を繰り返していく． そして，最後の層だけを完全結合層とし，分類もしくは回帰を行う．\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n回帰型ニューラルネット\n文字列や音声などの時系列データを扱うためのニューラルネットとして，回帰型ニューラルネット(recurrent neural nettwork)がある．\n長さ \\(T\\) の時系列データ \\(x^{&lt;1&gt;},x^{&lt;2&gt;},\\ldots,x^{&lt;T&gt;}\\) が与えられたとき， 回帰型ニューラルネットは，初期状態 \\(a^{&lt;0&gt;}\\) から状態の列 \\(a^{&lt;1&gt;},a^{&lt;2&gt;},\\ldots,a^{&lt;T&gt;}\\) を順次生成していく．\n各時刻 \\(t=1,2,\\ldots,T\\) において，データ \\(x^{&lt;t&gt;}\\) と前の状態 \\(a^{&lt;t-1&gt;}\\) を結合したものを入力とし活性化関数（通常は\\(\\tanh\\)）を用いて，次の状態 \\(a^{&lt;t&gt;}\\) を生成していく．\n\n\n\n\n\n\n\n\n\n\n\n\n長短期記憶\n回帰型ニューラルネットは，誤差逆伝播の際に勾配が無限大に発散したり消失してしまうという弱点をもっている． その弱点を克服するためのアーキテクチャとして，長短期記憶(long short-term memory: LSTM)がある．\nLSTMの特徴は，長期の記憶のためのセル(cell) \\(c^{&lt;t&gt;}\\) と，通常の状態（短期記憶に相当する） \\(a^{&lt;t&gt;}\\) の両者を保持することである． この2種類の記憶情報を，シグモイド関数 \\(\\sigma\\) の出力（\\(0\\) と \\(1\\) の間になる）と乗じることによって， そのまま保持するかリセットするかを決め， 勾配発散（消失）を避けることができる．\n\n\n\n\n\n\n\n\n\n\n\n\n埋め込みニューラルネット\nカテゴリーデータをより次元の低い特徴に写像するために埋め込み層(embedding layer)が使われる．以下の例では，10のカテゴリーをもつデータを，\\(10\\times5\\)の重み行列を用いて5次元の特徴に埋め込んでいる．\n\n\n\n\n\n\n\n\n\n\n\n\n自己アテンション\n自己アテンション(self attention)は，最近注目を浴びているトランスフォーマーの基礎となるアーキテクチャであり， 自然言語処理に大きな進歩をもたらした．\n自己アテンションでは，入力された文章をLSTMのように順番に入力するのではなく，一度に読み込む． まず，入力された文字の埋め込みに，文字の位置情報を正弦・余弦曲線を用いて付加し， それに対してクエリー，キー，値を表す3つの全結合層を適用し，3つの行列（テンソル） \\(Q,K,V\\) を得る． 次に，クエリ行列 \\(Q\\) とキー行列 \\(K\\) の内積をとり，それにスケーリングとソフトマックスを適用することによって，入力された文字同士の関係を表すアテンションを得る． 最後に，アテンションに値行列 \\(V\\) を乗じることによって出力を得る．",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "16fastai.html#実践的な深層学習のレシピと背景にある理論",
    "href": "16fastai.html#実践的な深層学習のレシピと背景にある理論",
    "title": "fastaiによる深層学習",
    "section": "実践的な深層学習のレシピと背景にある理論",
    "text": "実践的な深層学習のレシピと背景にある理論\n上では例を示すことによって深層学習の「雰囲気」を学んだが、実際問題を解くためには、プロジェクトの進めるためのコツや、背景にある理論も理解する必要がある。 以下では、それらについて簡単に述べる。\n\n訓練、検証、テスト集合\n今までの例題では，データセットをトレーニング（訓練）集合とテスト集合の2つに分けていた． 研究や勉強のためには，この2つに分けるだけで十分であるが， 実際問題に適用する際には，訓練集合(training set)，検証集合(validation set)（開発集合(development set)とよばれることもある），テスト集合(test set)の3つにデータを分けて実験を行う必要がある． 訓練集合でパラメータ（重み）をチューニングし，検証集合で実際のデータでうまく動くようにハイパーパラメータをチューニングし，最後にテスト集合で評価する． テスト集合は実験では使用できないように隠しておく．検証集合は訓練集合から適当な割合で抽出しても良い．\n昔は訓練集合は\\(6\\)割、検証集合は \\(2\\)割、テスト集合は \\(2\\) 割と言われていた。しかし、最近はデータセットが大規模化しており、 検証とテストには一定数のデータセットがあれば十分である。例えば、超大規模データセットに対しては、 \\(98\\)%を訓練、検証とテストには残りの\\(1\\)%ずつとしても良い。\n\n\nバイアスとバリアンス / 過剰適合と不足適合\n深層学習の例題（MNISTとかCifarとか）では，現在の世界記録がどのあたりなのかが分かるが，実際問題においてどこまで学習を進めればよいのかは，一般には分からない．より一般的な最適化理論では，適当な緩和問題を用いた限界値（最小化の場合には下界）を得ることができるので，誤差を評価することができる．しかし，深層学習では，それが難しい場合が多い．そのような場合に，人でテストをしてみることによって，可能な誤差を推測することが推奨される．\n人間がどんなに頑張っても出ないくらいの誤差（エラー率）をBayes最適誤差(Bayes” optimal error)とよぶ．\nバイアス  = 訓練誤差 - Bays最適誤差（もしくは人間水準誤差）\nバリアンス = 検証誤差 - 訓練誤差\nバリアンスが大きい状態を過剰適合(overfit)とよぶ．バイアスが大きい状態を過小適合(underfit)とよび，これは訓練データに対する最適化が十分でないことを表す．\nまずは訓練集合での正解率を上げることを目標に実験をするのだが，訓練データでの性能がいまいちな状態を「高バイアス」とよぶ．これを改善するには，ネットワークの規模を大きくして学習容量を大きくしたり，訓練時間を長くしたり，最適化の方法を変えたりすることが考えられる．\n訓練データでそこそこの成績をあげられたら，今度は検証集合に対して性能を評価する．これがいまいちな状態が「高バリアンス」である． これを改善するには，データの量を増やしたり，正則化・正規化を行ったりすることが考えられる．これには色々な方法が考えられるが，深層学習で手軽なのはドロップアウトを追加したり，（確率的降下法の場合にはL2ノルムのかけ具合を表す）重み減衰パラメータを大きくしたり，バッチ正規化を行うことである．\n\n\n深層学習のレシピ\n深層学習プロジェクトを正しい方向に導くためには，多少のコツがある．ここでは，そのようなコツを伝授する．\n検証集合におけるメトリクスが不十分なときに何をすれば良いだろうか？以下のような様々な方法が思いつく．\n\nより多くのデータを集める．\nより多くの訓練集合を集める．\n訓練により多くの時間をかける．\n様々な最適化アルゴリズムを試す．\nより大きなアーキテキクチャにしてみる．\nアーキテキクチャを変更してみる．\nドロップアウト層を追加してみる．\nL2正則化(regularization；重み減衰(weight decay)と同義語)を追加する．\nバッチ正規化(batch normalization)を追加する．\n\nしかし，これらを場当たり的に適用しても時間がかかるばかりで，効果は上がらない．重要なのはアーキテクチャの選択とハイパーパラメータ（ニューラルネットでは調整する重みのことをパラメータとよび，それ以外のパラメータをハイパーパラメータとよぶ）の設定である．これには，以下の手順が推奨される．\n\n画像の場合には解像度を落とした小さなデータから始めて、徐々に解像度を上げていく。\n訓練集合に対して損出関数を最小化する．できれば下限（人間の水準）に近づくようにする．これがうまくいかない場合には，学習率を適正な値に設定する。学習率が小さすぎると過少適合になり、大きすぎる最適化の探索が発散する。学習率を適正な値にしても、損出関数の値が想定よりも大きい場合には、より大規模なアーキテキクチャを試すか，異なる最適化手法を試す．バッチ正規化をアーキテクチャに追加し、最適化しやすいアーキテクチャ（残差ネットワークなど）を選択することも忘れてはならない。 メモリや計算速度が十分でないときには、単精度計算をするか、より大きなメモリをもつGPUに変更することを検討する。\n転移学習を行っている場合には、固定していたパラメータを自由に変更できるようにしてから、再び訓練を行う。\n（上の手順と並行して）検証集合に対して目的とする評価尺度（メトリクス）を達成するように訓練を行う．これがうまくいかない（過剰適合している）場合には，ドロップアウトを追加するか，重み減衰のパラメータを増やすか，訓練集合を増やすか，データ増大を行う．\nテスト集合に対して良い結果が出るように訓練を行う．これがうまくいかない場合には，検証集合を増やすか，データ増大を行う．\n実問題に対する性能評価を行う．これがうまくいかない場合には，検証集合やテスト集合が実問題を反映しているかどうかを調べ，適宜増やす．\n\n上ではいささか抽象的に手順を紹介したが，具体的なパラメータの適正化は以下の手順が推奨されている．\n\nモデル（アーキテキクチャ）を選択する際には，解きたい問題に似た問題のベンチマークでの成績を https://dawn.cs.stanford.edu/benchmark/ やhttps://benchmarks.ai/ で調べて，そこで上位の（かつ簡単な）ものを選択する．たとえば，画像から物体を当てたい場合には，画像によるクラス分けならResNet（メモリに余裕があるならDenseNetやWide ResNet）をベースにしたもの，画像分類（セグメンテーション）ならUNETを選ぶ．\nただし競技会で上位のものは大規模なモデルを使用している場合が多い．モデルの規模が増大するにしたがい誤差は小さくなる（精度が上がる）が，その一方で計算時間が増加する．解くべき問題の複雑さを考慮してなるべく小さなモデルから始めて，十分な精度が得られなかったときに，大きめのモデルを試すという方法が推奨される．\nすでに学習済みの重みがあるモデル（たとえばresnet34）を用い，転移学習を行う場合には，最終層以外の重みを変えないような状態で訓練を行う．学習率をlr_find()で可視化し，損出関数が下降している途中の範囲を求める．\n得られた適正な学習率を用いて，最終層だけを数エポック訓練する．損出関数や精度の推移を可視化し，正しく訓練されていることを確認する．\n上層も訓練できるように設定し，再びlr_find()で適切な学習率を探索する．\n最下層を上で求めた学習率とし，上層の固まりは下層の固まりよりやや（画像の場合には10分の1，テキストの場合には0.26倍）小さめになるように設定し，過剰適合になるまで訓練する．（fastaiでは層のブロックを3層になるようにまとめている．）\nすぐに過剰適合になっている場合には，それを抑止する方法を取り入れる必要がある．以下の順に試す.\n\nもっとデータを集める．\nデータ増大を行う．\nアーキテクチャ（モデル）にドロップアウト層やバッチ正規化を追加する．\n正則化のためのハイパーパラメータ（重み減衰率: weight decay(wd)）を大きめにする．\nアーキテクチャを単純化する．\n\n画像データの場合には，上の手順を解像度を下げて行い，徐々に解像度を上げて繰り返す．他の形式のデータの場合には，データの一部を用いて上の手順を行い，適切な結果が出たら大きなデータを入れて本実験を行う．\n\n\n\nL2正則化（重み減衰）が過剰適合を削減する直感的な理由\n\n重み減衰率が大きくなると，重み \\(w\\) は小さくなり，0になるものが増える．それによってニューラルネットがより疎になり，（ドロップアウトと同様に）過剰適合を削減する．\ntanhなどの非線形な活性化関数を使っている場合，重み減衰率 lambda が大きくなると \\(w\\) が小さくなるので，ニューロンへの入力も小さくなる（0に近くなる）．tanhなどの活性化関数を可視化すると分かるように0付近では線形関数に近い形をしている．したがって，非線形な活性化関数も線形関数と同じような働きをするようになり，これによって過剰適合が削減できる．\n\n\n\nハイパーパラメータのチューニング\nハイパーパラメータは、以下の順で重要である。\n\n学習率 (learning rate: lr)\n慣性項（モーメント）(momentum)\nミニバッチの大きさ\n隠れ層のユニット数\n層の数\n学習率の減らし方\n正則化パラメータ (weight decay: wd)\n活性化関数\nAdamのパラメータ\n\n\n\n評価尺度（メトリクス）\nここではfastaiで使われる代表的な評価尺度（メトリクス）について解説する．\n\n正解率 (accuracy)\n\n入力の中で最大値のクラスが正解クラスと一致している割合．正答率，精度と訳されることもある． 正解が1つのクラスに属しているとき（これを1ラベル問題とよぶ）に用いられる．\n例： 入力として3つのクラスから成る5つのデータを与える．正解はすべてクラス1とする．入力の中で値が最大のものは，上のコードの中にあるようにargmaxメソッドで求めることができる．得られた(1,0,1,0,0)が正解(1,1,1,1,1)と一致している割合は 0.4 と計算できる．\n    from fastai.metrics import *\n    in_ = torch.Tensor([ [0.3,0.5,0.2],\n                         [0.6,0.2,0.2],\n                         [0.1,0.6,0.3],\n                         [0.9,0.0,0.1],\n                         [0.8,0.1,0.1],\n                        ])\n    targs = torch.Tensor([1,1,1,1,1]).long()\n    print(in_.argmax(dim=-1).view(5,-1))\n    print(accuracy(in_, targs))\n\n&gt;&gt;&gt;\n    tensor([[1],\n            [0],\n            [1],\n            [0],\n            [0]])\n    tensor(0.4000)\n2値分類の場合には， 正解か否か(true/false)と陽性と予測したか否か(positive/negative)があるので，以下の4通りの場合がある．\n\nTN : 真陰性 (true negative)\nFP : 偽陽性 (false positive)\nFN : 偽陰性 (false negative)\nTP : 真陽性 (true positive)\n\n正解率は以下のように定義される．\n\\[\n\\mathrm{accuracy} = \\frac{\\mathrm{TP}+\\mathrm{TN}}{\\mathrm{TP}+\\mathrm{FN}+\\mathrm{FP}+\\mathrm{TN}}\n\\]\n\n閾値付き正解率\n\n予測値に対するシグモイド関数の値が，与えた閾値（規定値は0.5）より大きいときに1，それ以外のとき0と計算し，その結果と正解を比較したときの正解率．\n例： ランダムな標準正規分布として与えた5つの予測値に対してシグモイド関数で[0,1]の値に変換し，閾値0.5 より大きいものと正解を比較することによって，閾値付き正解率0.6を得る．\n    y_pred = torch.randn(5)\n    y_true = torch.Tensor([1,1,1,1,1]).long()\n    print(\"y_pred = \", y_pred)\n    print(\"sigmoid = \", y_pred.sigmoid())\n    print(accuracy_thresh(y_pred, y_true))\n\n&gt;&gt;&gt;\n    y_pred =  tensor([ 0.8596,  0.3210, -0.1176,  1.0431, -0.7974])\n    sigmoid =  tensor([0.7026, 0.5796, 0.4706, 0.7394, 0.3106])\n    tensor(0.6000)\n\nトップ \\(k\\) 正解率\n\n入力値が大きいものからk個選択し，それらを正解と比較したときの正解率．\n例： 正解率と同じ例題を用いる．トップ2のクラスを出力すると，正解の1は2番目には入っていないので，トップ1の正解率と同じ0.4を得る．\n    print(in_.topk(k=2, dim=-1)[1])\n    print(top_k_accuracy(in_,targs,k=2))\n\n&gt;&gt;&gt;\n    tensor([[1, 0],\n            [0, 2],\n            [1, 2],\n            [0, 2],\n            [0, 2]])\n    tensor(0.4000)\n\nダイス係数(dice coefficient)\n\n分割問題で用いられる集合の類似度を表す評価尺度であり，引数 iou (intersection over union) が真のときには，以下のように計算する．\n\\[DICE(A,B)=\\frac{|A \\cap B|}{|A|+|B|-|A \\cap B| + 1 }\\]\n引数iouが偽（既定値）のときには，以下のように計算する．\n\\[DICE(A,B)=\\frac{2|A \\cap B|}{|A|+|B|}\\]\n例：\n    print(\"iou=False:\", dice(in_,targs,iou=False))\n    print(\"iou=True:\",dice(in_,targs,iou=True))\n\n&gt;&gt;&gt;\n    iou=False: tensor(0.5714)\n    iou=True: tensor(0.3333)\n\n誤差率 (error rate)\n\n\\(1-\\)正解率であり，上の例題では\\(1-0.4=0.6\\)となる．\n\n決定係数(coefficient of determination) \\(R^2\\)\n\n回帰モデルによって実データをどれくらい説明できているか（回帰分析の精度）を表す指標であり，1に近いほど精度が良いと解釈できる．\n\\[R^2 = 1 - {\\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\over \\sum_{i=1}^n (y_i-\\bar{y})^2 }\\]\nこの定義だと（記号が\\(R^2\\)であるにもかかわらず）負になる場合もあるので，注意を要する．最大値は1で誤差が0の状態である．\\(R^2\\)が0とは，平均で予測をした場合と同じ精度という意味であり，負の場合は平均値より悪い予測を意味する．\n\n平均自乗誤差 (mean squared error)\n\n誤差の自乗の平均値であり，\\(i\\)番目のデータの正解（目標値）を\\(y_i\\)，予測値を\\(\\hat{y}_{i}\\) としたとき，以下のように定義される．\n\\[MSE = \\frac{\\sum_{i=1}^n (\\hat y_i - y_i)^2}{n}\\]\nこれの平方根をとったものがroot_mean_squared_error (RMSE) である．\n\\[RMSE =\\sqrt{\\frac{\\sum_{i=1}^n (\\hat y_i - y_i)^2}{n}}\\]\n\n平均絶対誤差 (mean absolute error)\n\n誤差の絶対値の平均値である．\n\\[MAE = \\frac{\\sum_{i=1}^n |\\hat y_i - y_i|}{n}\\]\n\n平均自乗対数誤差 (mean squared logarithmic error)\n\n予測値，正解ともに対数をとったもので評価した平均自乗誤差である．\nこれの平方根をとったものがroot mean squared logarithmic error (RMSLE) である．\n\nMAPE 平均絶対パーセント誤差 (mean absolute percentage error)\n\n\\[MAPE = \\frac{\\sum_{i=1}^n | (\\hat y_i - y_i)/y_i) |}{n}\\]\n\n適合率 (precision)：正と予測したデータのうち，実際に正であるものの割合\n\n\\[\n     \\mathrm{precision} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}\n\\]\n\n再現率 (recall)：実際に正であるもののうち，正であると予測されたものの割合\n\n\\[\n\\mathrm{recall} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}\n\\]\n\n\\(f\\)ベータ\n\n適合率と再現率をパラメータ \\(\\beta\\) で調整した評価尺度であり，主に2値分類で用いられる．\n\\[f_\\beta = (1 + \\beta^2)  \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\mathrm{precision}) + \\mathrm{recall}}\\]\n\n寄与率(explained variance)\n\n「\\(1 -\\)誤差の分散/正解の分散」と定義される．\n\n自分で新しい評価尺度を作る方法\n他の評価尺度から新たに評価尺度を生成するには，標準モジュールのfunctoolsにあるpartialを使うと簡単にできる．fastaiではすでにimportした状態にあるので，以下のように呼び出せば良い．\n    acc_02 = partial(accuracy_thresh, thresh=0.2)\n    f_05 = partial(fbeta, beta=0.5)\n最初の行では，閾値付き正解率に対して，閾値を0.2に固定した評価尺度acc_02を生成し，次の行ではfベータ のパラメータ（beta) を0.5に固定した評価尺度f_05を生成している．",
    "crumbs": [
      "fastaiによる深層学習"
    ]
  },
  {
    "objectID": "18pydantic.html",
    "href": "18pydantic.html",
    "title": "Pydanticによるデータ検証",
    "section": "",
    "text": "Pydantic はデータ検証のためのパッケージである．\nPythonは，動的に型付けを行うのが特徴であり，それは利点でもあり弱点でもある．たとえば，以下のようなコードが書ける．\n\nx = 1 #整数型 int に型付け\ntype(x)\n\nint\n\n\n\nx = \"Hello\"\ntype(x)\n\nstr\n\n\n型（タイプ）を気にする必要がないので，初学者が気楽にプログラムを書けるというは利点であるが， ちゃんとしたプログラムを書きたい人にとっては，この仕様は嬉しくない．\nそのため，最近のPythonでは型ヒントを与えることができるようになった．たとえば，以下のように整数を2倍した整数を返す関数を定義できる．\n\ndef multiple2( x:int ) -&gt; int:\n    return x*2\nmultiple2(100)\n\n200\n\n\nこれは，引数のxを整数型 int で，返値も整数型であるように型ヒントを与えたものであるが， これは単にコードを読みやすくするためのヒント（飾り）であるため，実際には文字列を引数として与えてもエラーしない．\n\nmultiple2(\"Hello\")\n\n'HelloHello'\n\n\nこういった予期しない結果を出さないようにするための手段がデータ検証 (data validiation) である． Pydanticを使うと，データ検証が容易になるだけでなく，クラスを設計するのが楽になる．\n早速使ってみよう．まずは，PydanticのBaseModelクラスから派生させてUserクラスを作ってみる． このクラスは，整数値をとるインデックス id と文字列の名前 name の2つの属性（フィールド）をもつ．\n\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str = \"Mikio Kubo\"\n\nidは必須であり省略できない．一方，nameは既定値が指定されているので省略できる． 以下では，文字列 ‘123’ でidを指定しているが，型指定機能で自動的に整数値に変換される． また，nameは省略すると既定値が代入される．\n\nuser = User(id='123')\nuser\n\nUser(id=123, name='Mikio Kubo')\n\n\n\n\n\nidなしでUserクラスを使うとどうなるか？\nname引数に自分の名前を入れるとどうなるか？\n\nPydanticで作ったクラスのインスタンスは，辞書に変換できる． 変換にはmodel_dumpメソッドを用いる．辞書のキーはフィールド名になる．\n\ndumped_user = user.model_dump()\nprint(type(dumped_user))\ndumped_user\n\n&lt;class 'dict'&gt;\n\n\n{'id': 123, 'name': 'Mikio Kubo'}\n\n\nデータのWeb経由での交換の際には，JSON (JavaScript Object Notation) 形式のテキストファイルが便利である． 変換にはmodel_dump_jsonメソッドを用いる．\n\njson_user = user.model_dump_json()\nprint(type(json_user))\njson_user\n\n&lt;class 'str'&gt;\n\n\n'{\"id\":123,\"name\":\"Mikio Kubo\"}'\n\n\nクラスから作られた辞書やJSONから，クラスを再現することもできる． 辞書からはmodel_validateメソッド，JSONからはmodel_validate_jsonメソッドを用いる．\n\nprint( user.model_validate(dumped_user) )\nprint( user.model_validate_json(json_user) )\n\nid=123 name='Mikio Kubo'\nid=123 name='Mikio Kubo'\n\n\n\n\n\n\n自分の名前をnameに設定したUserインスタンスを作り，それを辞書に変換せよ．\n今度はJSON形式のテキストに変換せよ．\n変換した辞書とJSONから，元のクラスインスタンスを生成せよ．\n\nFieldクラスでフィールドの値の既定値や範囲の指定など様々な情報を付加することができる． 以下の例では，idはge(greater than equal)を用いて1以上の値に制限し， 名前の既定値 (default value) はNoneとしている．\n\nfrom pydantic import Field\n\nclass User(BaseModel):\n    id: int   = Field(ge=1)\n    name: str = Field(default=None)\n\nuser = User(id=1)\nprint(user)\n\nid=1 name=None\n\n\n上のクラスのidに0を入れるとエラーする．この検証エラーをtry…except構文でとらえて，エラーを表示するには， ValidationErrorを用いる．\n\nfrom pydantic import ValidationError\n\ntry:\n    user = User(id=0)\nexcept ValueError as e:\n    print(e)\n\n1 validation error for User\nid\n  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.1.2/v/greater_than_equal\n\n\n\n\n\n\nnameフィールドの既定値を自分の名前にし，0以上，120以下の値をとるフィールド age を追加したクラス Userを作れ．\n上で作ったクラスに age = 150 を入れるとエラーする．エラーメッセージを出すようなコードに直せ．\n\n標準のint, str, float, boolの型だけでなく，様々な型を指定することができる． 型クラスは，typingパッケージからインポートしておく．\n\nfrom typing import Tuple, List, Dict, Set, Union, Optional\n\nclass User(BaseModel):\n    id: int\n    height: Union[int, float]         # 整数か浮動小数点数のいずれか（型の和集合）\n    name: Optional[str]       = None  # 省略可能 （ただし既定値は必要）\n    friends: List[str]                # 友人の名前を入れ文字列のリスト\n    fruits: Dict[str,int]             # 好きなフルーツ名をキー，購入数を値とした辞書\n\nUser(id = 123, \n     height = 178.0, \n     friends = [\"Kitty\", \"Mickey\", \"Donald\"],\n     fruits = {\"apple\":10, \"melon\":3}\n    )\n\nUser(id=123, height=178.0, name=None, friends=['Kitty', 'Mickey', 'Donald'], fruits={'apple': 10, 'melon': 3})\n\n\n\n\n\n以下のフィールドをもつクラスCustomerをPydanticのBaseModelから派生させて作れ． また，適当なデータを用いて\n\n整数か文字列のid\n文字列のname\n緯度・経度を表す浮動小数点数のタプルのlocation\n扱う商品の名前を文字列とした集合のproducts",
    "crumbs": [
      "Pydanticによるデータ検証"
    ]
  },
  {
    "objectID": "18pydantic.html#pydanticとは",
    "href": "18pydantic.html#pydanticとは",
    "title": "Pydanticによるデータ検証",
    "section": "",
    "text": "Pydantic はデータ検証のためのパッケージである．\nPythonは，動的に型付けを行うのが特徴であり，それは利点でもあり弱点でもある．たとえば，以下のようなコードが書ける．\n\nx = 1 #整数型 int に型付け\ntype(x)\n\nint\n\n\n\nx = \"Hello\"\ntype(x)\n\nstr\n\n\n型（タイプ）を気にする必要がないので，初学者が気楽にプログラムを書けるというは利点であるが， ちゃんとしたプログラムを書きたい人にとっては，この仕様は嬉しくない．\nそのため，最近のPythonでは型ヒントを与えることができるようになった．たとえば，以下のように整数を2倍した整数を返す関数を定義できる．\n\ndef multiple2( x:int ) -&gt; int:\n    return x*2\nmultiple2(100)\n\n200\n\n\nこれは，引数のxを整数型 int で，返値も整数型であるように型ヒントを与えたものであるが， これは単にコードを読みやすくするためのヒント（飾り）であるため，実際には文字列を引数として与えてもエラーしない．\n\nmultiple2(\"Hello\")\n\n'HelloHello'\n\n\nこういった予期しない結果を出さないようにするための手段がデータ検証 (data validiation) である． Pydanticを使うと，データ検証が容易になるだけでなく，クラスを設計するのが楽になる．\n早速使ってみよう．まずは，PydanticのBaseModelクラスから派生させてUserクラスを作ってみる． このクラスは，整数値をとるインデックス id と文字列の名前 name の2つの属性（フィールド）をもつ．\n\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str = \"Mikio Kubo\"\n\nidは必須であり省略できない．一方，nameは既定値が指定されているので省略できる． 以下では，文字列 ‘123’ でidを指定しているが，型指定機能で自動的に整数値に変換される． また，nameは省略すると既定値が代入される．\n\nuser = User(id='123')\nuser\n\nUser(id=123, name='Mikio Kubo')\n\n\n\n\n\nidなしでUserクラスを使うとどうなるか？\nname引数に自分の名前を入れるとどうなるか？\n\nPydanticで作ったクラスのインスタンスは，辞書に変換できる． 変換にはmodel_dumpメソッドを用いる．辞書のキーはフィールド名になる．\n\ndumped_user = user.model_dump()\nprint(type(dumped_user))\ndumped_user\n\n&lt;class 'dict'&gt;\n\n\n{'id': 123, 'name': 'Mikio Kubo'}\n\n\nデータのWeb経由での交換の際には，JSON (JavaScript Object Notation) 形式のテキストファイルが便利である． 変換にはmodel_dump_jsonメソッドを用いる．\n\njson_user = user.model_dump_json()\nprint(type(json_user))\njson_user\n\n&lt;class 'str'&gt;\n\n\n'{\"id\":123,\"name\":\"Mikio Kubo\"}'\n\n\nクラスから作られた辞書やJSONから，クラスを再現することもできる． 辞書からはmodel_validateメソッド，JSONからはmodel_validate_jsonメソッドを用いる．\n\nprint( user.model_validate(dumped_user) )\nprint( user.model_validate_json(json_user) )\n\nid=123 name='Mikio Kubo'\nid=123 name='Mikio Kubo'\n\n\n\n\n\n\n自分の名前をnameに設定したUserインスタンスを作り，それを辞書に変換せよ．\n今度はJSON形式のテキストに変換せよ．\n変換した辞書とJSONから，元のクラスインスタンスを生成せよ．\n\nFieldクラスでフィールドの値の既定値や範囲の指定など様々な情報を付加することができる． 以下の例では，idはge(greater than equal)を用いて1以上の値に制限し， 名前の既定値 (default value) はNoneとしている．\n\nfrom pydantic import Field\n\nclass User(BaseModel):\n    id: int   = Field(ge=1)\n    name: str = Field(default=None)\n\nuser = User(id=1)\nprint(user)\n\nid=1 name=None\n\n\n上のクラスのidに0を入れるとエラーする．この検証エラーをtry…except構文でとらえて，エラーを表示するには， ValidationErrorを用いる．\n\nfrom pydantic import ValidationError\n\ntry:\n    user = User(id=0)\nexcept ValueError as e:\n    print(e)\n\n1 validation error for User\nid\n  Input should be greater than or equal to 1 [type=greater_than_equal, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.1.2/v/greater_than_equal\n\n\n\n\n\n\nnameフィールドの既定値を自分の名前にし，0以上，120以下の値をとるフィールド age を追加したクラス Userを作れ．\n上で作ったクラスに age = 150 を入れるとエラーする．エラーメッセージを出すようなコードに直せ．\n\n標準のint, str, float, boolの型だけでなく，様々な型を指定することができる． 型クラスは，typingパッケージからインポートしておく．\n\nfrom typing import Tuple, List, Dict, Set, Union, Optional\n\nclass User(BaseModel):\n    id: int\n    height: Union[int, float]         # 整数か浮動小数点数のいずれか（型の和集合）\n    name: Optional[str]       = None  # 省略可能 （ただし既定値は必要）\n    friends: List[str]                # 友人の名前を入れ文字列のリスト\n    fruits: Dict[str,int]             # 好きなフルーツ名をキー，購入数を値とした辞書\n\nUser(id = 123, \n     height = 178.0, \n     friends = [\"Kitty\", \"Mickey\", \"Donald\"],\n     fruits = {\"apple\":10, \"melon\":3}\n    )\n\nUser(id=123, height=178.0, name=None, friends=['Kitty', 'Mickey', 'Donald'], fruits={'apple': 10, 'melon': 3})\n\n\n\n\n\n以下のフィールドをもつクラスCustomerをPydanticのBaseModelから派生させて作れ． また，適当なデータを用いて\n\n整数か文字列のid\n文字列のname\n緯度・経度を表す浮動小数点数のタプルのlocation\n扱う商品の名前を文字列とした集合のproducts",
    "crumbs": [
      "Pydanticによるデータ検証"
    ]
  },
  {
    "objectID": "31pytorch.html",
    "href": "31pytorch.html",
    "title": "PyTorchによる深層学習",
    "section": "",
    "text": "PyTorchパッケージを用いて \\(N\\) 行 \\(D\\) 列のランダムな行列 \\(x,y,z\\) を作り， \\(c = \\sum x*y + z\\) を計算をする． 最後に， 計算された \\(c\\) の \\(x\\) に対する勾配（微分値）をbackwardで計算する．\nrandでランダムな行列をを生成する際に， 引数 requires_grad を True に設定しておくことによって， 勾配が計算される．　\n変数に対しては，　dataで値が， 勾配を計算するように指定した変数に対しては gradで勾配が得られる．\n\nimport torch\n\n\nN, D = 3,4 #3行4列のランダムなテンソルを生成し， 勾配を計算する\nx = torch.rand( (N, D), requires_grad=True)\ny = torch.rand( (N, D), requires_grad=True)\nz = torch.rand( (N, D), requires_grad=True)\n\na = x*y\nb = a+z\nc = torch.sum(b)\n\nc.backward()\n\nc.data\n\ntensor(7.9498)\n\n\n\nprint(x.data)\n\ntensor([[0.1379, 0.2976, 0.8908, 0.8022],\n        [0.2833, 0.0333, 0.8762, 0.2876],\n        [0.3688, 0.8043, 0.9437, 0.0616]])\n\n\n\nprint(x.grad)\n\ntensor([[0.7403, 0.0179, 0.0335, 0.0769],\n        [0.5766, 0.5749, 0.5347, 0.4289],\n        [0.7062, 0.0719, 0.6709, 0.1248]])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  },
  {
    "objectID": "31pytorch.html#簡単な計算",
    "href": "31pytorch.html#簡単な計算",
    "title": "PyTorchによる深層学習",
    "section": "",
    "text": "PyTorchパッケージを用いて \\(N\\) 行 \\(D\\) 列のランダムな行列 \\(x,y,z\\) を作り， \\(c = \\sum x*y + z\\) を計算をする． 最後に， 計算された \\(c\\) の \\(x\\) に対する勾配（微分値）をbackwardで計算する．\nrandでランダムな行列をを生成する際に， 引数 requires_grad を True に設定しておくことによって， 勾配が計算される．　\n変数に対しては，　dataで値が， 勾配を計算するように指定した変数に対しては gradで勾配が得られる．\n\nimport torch\n\n\nN, D = 3,4 #3行4列のランダムなテンソルを生成し， 勾配を計算する\nx = torch.rand( (N, D), requires_grad=True)\ny = torch.rand( (N, D), requires_grad=True)\nz = torch.rand( (N, D), requires_grad=True)\n\na = x*y\nb = a+z\nc = torch.sum(b)\n\nc.backward()\n\nc.data\n\ntensor(7.9498)\n\n\n\nprint(x.data)\n\ntensor([[0.1379, 0.2976, 0.8908, 0.8022],\n        [0.2833, 0.0333, 0.8762, 0.2876],\n        [0.3688, 0.8043, 0.9437, 0.0616]])\n\n\n\nprint(x.grad)\n\ntensor([[0.7403, 0.0179, 0.0335, 0.0769],\n        [0.5766, 0.5749, 0.5347, 0.4289],\n        [0.7062, 0.0719, 0.6709, 0.1248]])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  },
  {
    "objectID": "31pytorch.html#最小2乗法",
    "href": "31pytorch.html#最小2乗法",
    "title": "PyTorchによる深層学習",
    "section": "最小2乗法",
    "text": "最小2乗法\n\\(y = a x\\) のパラメータ \\(a\\) の最適化を最小2乗法によって行う．\nfrom_numpyでNumPyの配列をPyTorchのテンソルに変換できる．　\nパラメータ \\(a\\) をランダムに設定し，勾配を計算するように指示する．\n予測値 yhat を計算した後で， 損出関数 loss を誤差の2乗平均として計算し， backward で勾配を計算する．\n勾配の逆方向に学習率 lr (learning rate) だけ移動させたものを新しい \\(a\\) とし， それをn_epochs回繰り返す．\nここで，反復ごとに勾配を \\(0\\) に初期化する a.grad.zero_ を呼び出すことに注意されたい．\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\n\n\nx_numpy = np.array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=np.float32)\ny_numpy = np.array([15.0, 20.0, 34.0, 42.0, 58.0], dtype=np.float32)\n\nx = torch.from_numpy(x_numpy)\ny = torch.from_numpy(y_numpy)\n\na = torch.rand(1, requires_grad=True) #スカラーを定義\n\nn_epochs = 10  #反復回数（エポック数）\nlr = 0.01      #学習率\nfor epoch in range(n_epochs):\n    yhat = a*x \n    error = y - yhat\n    loss =(error**2).mean()\n    \n    loss.backward()\n    \n    with torch.no_grad():\n        a -= lr*a.grad\n\n    print(loss.data, a.data)\n    \n    a.grad.zero_()\n\ntensor(1317.2814) tensor([2.6670])\ntensor(803.9544) tensor([4.5403])\ntensor(491.6464) tensor([6.0014])\ntensor(301.6381) tensor([7.1411])\ntensor(186.0371) tensor([8.0301])\ntensor(115.7055) tensor([8.7234])\ntensor(72.9157) tensor([9.2643])\ntensor(46.8824) tensor([9.6861])\ntensor(31.0437) tensor([10.0152])\ntensor(21.4075) tensor([10.2719])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  },
  {
    "objectID": "31pytorch.html#線形回帰",
    "href": "31pytorch.html#線形回帰",
    "title": "PyTorchによる深層学習",
    "section": "線形回帰",
    "text": "線形回帰\n\nクラス\nnn.Moduleクラスから派生させて線形回帰を行うクラス LinearRegression を作る．\nコンストラクタ init で親クラスを呼び出した後でパラメータ \\(a\\) を定義する．\n与えられた \\(x\\) に対して予測値 \\(y=ax\\) を計算するための関数 forward を定義する．\nモデルのインスタンス model のstate_dicメソッドでパラメータ \\(a\\) の現在の値の辞書を得ることができる．\n\nclass LinearRegression(nn.Module):\n    #コンストラクタ\n    def __init__(self):\n        super().__init__() #親クラスのコンストラクタを呼ぶ\n        self.a = nn.Parameter(torch.rand(1, requires_grad=True)) #モデルのパラメータを準備\n        \n    #予測値の計算\n    def forward(self, x):\n        return self.a*x\n        \nmodel = LinearRegression()\n\nmodel.state_dict()  #パラメータと現在の値の辞書\n\nOrderedDict([('a', tensor([0.5324]))])\n\n\n\n\n訓練\n損出関数を計算する関数 loss_fn を最小2乗誤差 nn.MSELoss とし， 最適化は率的勾配降下法 (SGD: Stochastic Fradient Descent) optim.SDG とする． 引数はモデルのパラメータ model.parameters() と学習率 lr である．\noptimizerのstepで勾配降下法の1反復を行い， 反復ごとに zero_grad で勾配を \\(0\\) に初期化する．\n\nloss_fn = nn.MSELoss()  #損出関数（最小2乗誤差）\noptimizer = optim.SGD(model.parameters(), lr)  # 最適化（確率的勾配降下法）を準備； model.parameters()はパラメータを返すジェネレータ\n\nfor epoch in range(n_epochs):\n    model.train()           #モデルを訓練モードにする\n    yhat = model(x)         #forwardメソッドで予測値を計算する\n    loss = loss_fn(y, yhat) #損出関数\n    loss.backward()         #誤差逆伝播で勾配を計算\n    \n    optimizer.step()        #最適化の１反復\n    optimizer.zero_grad()   #勾配を０にリセット\n    \n    print(loss.data, model.state_dict())\n\ntensor(1253.9412) OrderedDict([('a', tensor([2.8753]))])\ntensor(765.4183) OrderedDict([('a', tensor([4.7027]))])\ntensor(468.2010) OrderedDict([('a', tensor([6.1281]))])\ntensor(287.3740) OrderedDict([('a', tensor([7.2399]))])\ntensor(177.3588) OrderedDict([('a', tensor([8.1072]))])\ntensor(110.4256) OrderedDict([('a', tensor([8.7836]))])\ntensor(69.7034) OrderedDict([('a', tensor([9.3112]))])\ntensor(44.9280) OrderedDict([('a', tensor([9.7227]))])\ntensor(29.8547) OrderedDict([('a', tensor([10.0437]))])\ntensor(20.6841) OrderedDict([('a', tensor([10.2941]))])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  },
  {
    "objectID": "31pytorch.html#線形層の追加",
    "href": "31pytorch.html#線形層の追加",
    "title": "PyTorchによる深層学習",
    "section": "線形層の追加",
    "text": "線形層の追加\nnn.Linear(入力数, 出力数)で線形層をモデルに追加する． モデルは \\(y = w_0 + w_1 x\\) となる．\nデータの \\(x,y\\) は縦ベクトル（shapeは (5,1)　）になおしておく．\n\nclass LayerLinearRegression(nn.Module):\n    #コンストラクタ\n    def __init__(self):\n        super().__init__() #親クラスのコンストラクタを呼ぶ\n        self.linear = nn.Linear(1,1, dtype=torch.float32) #1入力・１出力の線形層\n        #self.linear =nn.Sequential(nn.Linear(1,2), nn.ReLU(), nn.Linear(2,1)) #多層のモデルもSequentialを用いて作れる\n    #予測値の計算\n    def forward(self, x):\n        return self.linear(x)\n        \nmodel = LayerLinearRegression()\n\nmodel.state_dict()  #パラメータと現在の値の辞書\n\nOrderedDict([('linear.weight', tensor([[-0.9852]])),\n             ('linear.bias', tensor([0.3170]))])\n\n\n\nx = x.reshape(-1,1)\ny = y.reshape(-1,1)\n\n\nloss_fn = nn.MSELoss()  #損出関数（最小2乗誤差）\noptimizer = optim.SGD(model.parameters(), lr)  # 最適化（確率的勾配降下法）を準備； model.parameters()はパラメータを返すジェネレータ\n\nn_epochs=10\nfor epoch in range(n_epochs):\n    model.train()           #モデルを訓練モードにする\n    yhat = model(x)         #forwardメソッドで予測値を計算する\n    loss = loss_fn(y, yhat) #損出関数\n    loss.backward()         #誤差逆伝播で勾配を計算\n    \n    optimizer.step()        #最適化の１反復\n    optimizer.zero_grad()   #勾配を０にリセット\n    \n    print(loss.data, model.state_dict())\n\ntensor(1611.6226) OrderedDict([('linear.weight', tensor([[1.6726]])), ('linear.bias', tensor([1.0458]))])\ntensor(942.0174) OrderedDict([('linear.weight', tensor([[3.7018]])), ('linear.bias', tensor([1.6005]))])\ntensor(551.8026) OrderedDict([('linear.weight', tensor([[5.2514]])), ('linear.bias', tensor([2.0224]))])\ntensor(324.4026) OrderedDict([('linear.weight', tensor([[6.4348]])), ('linear.bias', tensor([2.3428]))])\ntensor(191.8832) OrderedDict([('linear.weight', tensor([[7.3385]])), ('linear.bias', tensor([2.5859]))])\ntensor(114.6554) OrderedDict([('linear.weight', tensor([[8.0289]])), ('linear.bias', tensor([2.7699]))])\ntensor(69.6488) OrderedDict([('linear.weight', tensor([[8.5564]])), ('linear.bias', tensor([2.9087]))])\ntensor(43.4192) OrderedDict([('linear.weight', tensor([[8.9594]])), ('linear.bias', tensor([3.0132]))])\ntensor(28.1319) OrderedDict([('linear.weight', tensor([[9.2676]])), ('linear.bias', tensor([3.0914]))])\ntensor(19.2212) OrderedDict([('linear.weight', tensor([[9.5032]])), ('linear.bias', tensor([3.1495]))])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  },
  {
    "objectID": "31pytorch.html#データセットとデータローダー",
    "href": "31pytorch.html#データセットとデータローダー",
    "title": "PyTorchによる深層学習",
    "section": "データセットとデータローダー",
    "text": "データセットとデータローダー\nデータセットはTensorDatasetで生成されるサプライチェーン．\n1バッチずつデータを出力するデータローダーは DataLoaderクラスに，データセットを入れることによって生成される．\n\nfrom torch.utils.data import TensorDataset, DataLoader\ntrain_data = TensorDataset(x,y)\ntrain_data[0]\n\n(tensor([1.]), tensor([15.]))\n\n\n\ntrain_loader = DataLoader(dataset = train_data, batch_size=2, shuffle=True)\nfor x_batch, y_batch in train_loader:\n    print(x_batch, y_batch)\n\ntensor([[4.],\n        [2.]]) tensor([[42.],\n        [20.]])\ntensor([[3.],\n        [5.]]) tensor([[34.],\n        [58.]])\ntensor([[1.]]) tensor([[15.]])\n\n\n\nloss_fn = nn.MSELoss()  #損出関数（最小2乗誤差）\noptimizer = optim.SGD(model.parameters(), lr)  # 最適化（確率的勾配降下法）を準備； model.parameters()はパラメータを返すジェネレータ\n\nn_epochs=10\nfor epoch in range(n_epochs):\n    for x_batch, y_batch in train_loader:\n        model.train()           #モデルを訓練モードにする\n        yhat = model(x_batch)         #forwardメソッドで予測値を計算する\n        loss = loss_fn(y_batch, yhat) #損出関数\n        loss.backward()         #誤差逆伝播で勾配を計算\n\n        optimizer.step()        #最適化の１反復\n        optimizer.zero_grad()   #勾配を０にリセット\n\n        print(loss.data, model.state_dict())\n\ntensor(5.4948) OrderedDict([('linear.weight', tensor([[9.5969]])), ('linear.bias', tensor([3.1964]))])\ntensor(26.1062) OrderedDict([('linear.weight', tensor([[9.8901]])), ('linear.bias', tensor([3.2406]))])\ntensor(0.6415) OrderedDict([('linear.weight', tensor([[9.8260]])), ('linear.bias', tensor([3.2246]))])\ntensor(2.0398) OrderedDict([('linear.weight', tensor([[9.8243]])), ('linear.bias', tensor([3.2388]))])\ntensor(4.9985) OrderedDict([('linear.weight', tensor([[9.8052]])), ('linear.bias', tensor([3.2228]))])\ntensor(33.0736) OrderedDict([('linear.weight', tensor([[10.3803]])), ('linear.bias', tensor([3.3379]))])\ntensor(12.2090) OrderedDict([('linear.weight', tensor([[10.4364]])), ('linear.bias', tensor([3.3245]))])\ntensor(0.9685) OrderedDict([('linear.weight', tensor([[10.4298]])), ('linear.bias', tensor([3.3305]))])\ntensor(9.3001) OrderedDict([('linear.weight', tensor([[10.1858]])), ('linear.bias', tensor([3.2695]))])\ntensor(8.4185) OrderedDict([('linear.weight', tensor([[10.3913]])), ('linear.bias', tensor([3.3230]))])\ntensor(8.5516) OrderedDict([('linear.weight', tensor([[10.2943]])), ('linear.bias', tensor([3.2770]))])\ntensor(6.0230) OrderedDict([('linear.weight', tensor([[10.0980]])), ('linear.bias', tensor([3.2279]))])\ntensor(5.9756) OrderedDict([('linear.weight', tensor([[10.0438]])), ('linear.bias', tensor([3.1984]))])\ntensor(2.4884) OrderedDict([('linear.weight', tensor([[10.0065]])), ('linear.bias', tensor([3.2023]))])\ntensor(22.7092) OrderedDict([('linear.weight', tensor([[10.4830]])), ('linear.bias', tensor([3.2976]))])\ntensor(2.8948) OrderedDict([('linear.weight', tensor([[10.5750]])), ('linear.bias', tensor([3.3130]))])\ntensor(16.4854) OrderedDict([('linear.weight', tensor([[10.3412]])), ('linear.bias', tensor([3.2322]))])\ntensor(2.0351) OrderedDict([('linear.weight', tensor([[10.3697]])), ('linear.bias', tensor([3.2608]))])\ntensor(8.0694) OrderedDict([('linear.weight', tensor([[10.2786]])), ('linear.bias', tensor([3.2171]))])\ntensor(6.8768) OrderedDict([('linear.weight', tensor([[10.4632]])), ('linear.bias', tensor([3.2660]))])\ntensor(9.7260) OrderedDict([('linear.weight', tensor([[10.2137]])), ('linear.bias', tensor([3.2036]))])\ntensor(1.2645) OrderedDict([('linear.weight', tensor([[10.2342]])), ('linear.bias', tensor([3.2210]))])\ntensor(8.8373) OrderedDict([('linear.weight', tensor([[10.3283]])), ('linear.bias', tensor([3.2355]))])\ntensor(15.1480) OrderedDict([('linear.weight', tensor([[10.1726]])), ('linear.bias', tensor([3.1577]))])\ntensor(14.0528) OrderedDict([('linear.weight', tensor([[10.3015]])), ('linear.bias', tensor([3.1624]))])\ntensor(1.1820) OrderedDict([('linear.weight', tensor([[10.3148]])), ('linear.bias', tensor([3.1771]))])\ntensor(5.9366) OrderedDict([('linear.weight', tensor([[10.1199]])), ('linear.bias', tensor([3.1284]))])\ntensor(7.2067) OrderedDict([('linear.weight', tensor([[10.0701]])), ('linear.bias', tensor([3.1122]))])\ntensor(10.5234) OrderedDict([('linear.weight', tensor([[10.3173]])), ('linear.bias', tensor([3.1644]))])\ntensor(5.9218) OrderedDict([('linear.weight', tensor([[10.1226]])), ('linear.bias', tensor([3.1157]))])",
    "crumbs": [
      "PyTorchによる深層学習"
    ]
  }
]